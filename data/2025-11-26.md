<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 24]
- [cs.AI](#cs.AI) [Total: 21]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Efficient Multi-Hop Question Answering over Knowledge Graphs via LLM Planning and Embedding-Guided Search](https://arxiv.org/abs/2511.19648)
*Manil Shrestha,Edward Kim*

Main category: cs.CL

TL;DR: 本论文提出两种高效且可验证的知识图谱多跳问答方法，方法速度快、效果好，最终显示大模型并非推理必需。


<details>
  <summary>Details</summary>
Motivation: 多跳问答在知识图谱上的推理路径组合爆炸，计算复杂且现有方法依赖大模型推断，成本高、难以落地，且答案可验证性不足。

Method: 提出两种混合算法：1）LLM引导计划，一次调用LLM预测关系序列，通过广度优先搜索执行，确保答案有图谱依托；2）嵌入式神经搜索，彻底去除LLM推断，结合文本和图谱嵌入，通过轻量级边评分模型实现高效搜索。两者再结合知识蒸馏压缩到小模型，实现低成本高性能。

Result: LLM引导方法微F1超过0.90，嵌入式神经搜索在准确性接近的情况下速度提升百倍，4B模型通过知识蒸馏达到了大型模型同等表现。结构化规划比直接生成具有更好的可迁移性和可验证性。

Conclusion: 多跳可验证推理无需大规模模型，关键在于结合符号结构和学习表示的正确归纳偏向，提出方法在准确性、效率和实际性上大幅突破。

Abstract: Multi-hop question answering over knowledge graphs remains computationally challenging due to the combinatorial explosion of possible reasoning paths. Recent approaches rely on expensive Large Language Model (LLM) inference for both entity linking and path ranking, limiting their practical deployment. Additionally, LLM-generated answers often lack verifiable grounding in structured knowledge. We present two complementary hybrid algorithms that address both efficiency and verifiability: (1) LLM-Guided Planning that uses a single LLM call to predict relation sequences executed via breadth-first search, achieving near-perfect accuracy (micro-F1 > 0.90) while ensuring all answers are grounded in the knowledge graph, and (2) Embedding-Guided Neural Search that eliminates LLM calls entirely by fusing text and graph embeddings through a lightweight 6.7M-parameter edge scorer, achieving over 100 times speedup with competitive accuracy. Through knowledge distillation, we compress planning capability into a 4B-parameter model that matches large-model performance at zero API cost. Evaluation on MetaQA demonstrates that grounded reasoning consistently outperforms ungrounded generation, with structured planning proving more transferable than direct answer generation. Our results show that verifiable multi-hop reasoning does not require massive models at inference time, but rather the right architectural inductive biases combining symbolic structure with learned representations.

</details>


### [2] [Can LLMs Faithfully Explain Themselves in Low-Resource Languages? A Case Study on Emotion Detection in Persian](https://arxiv.org/abs/2511.19719)
*Mobina Mehrazar,Mohammad Amin Yousefi,Parisa Abolfath Beygi,Behnam Bahrak*

Main category: cs.CL

TL;DR: 大模型在低资源语言（如波斯语）情感分类中虽表现优异，但生成解释经常无法忠实反映推理过程，呼吁更可靠的解释方法。


<details>
  <summary>Details</summary>
Motivation: 随着LLM生成自我解释的应用增多，模型解释的忠实性尤其在低资源语言场景下引发关注。该研究旨在检验现有LLM在该类任务中的实际表现和局限。

Method: 本文通过比较模型识别出的影响性词汇与人工注释一致性，评估了LLM对波斯语（低资源语言）情感分类任务中生成解释的忠实性。使用了基于token-level对数概率派生的置信分数，并比较了两种解释与预测顺序不同的prompting策略（预测后解释和解释后预测）。

Result: LLM在情感分类上表现优异，但其生成解释在与人类一致性上存在显著差异；不同prompting策略下模型间一致性高于与人工的一致性，显示确实存在解释不忠实问题。

Conclusion: 当前大语言模型（LLM）在生成解释时经常缺乏与人类推理的一致性，尤其在低资源语言中表现出解释的不忠实性。现有方法和评价指标仍有较大局限性，需要更健壮的新方法以保障模型的可靠性。

Abstract: Large language models (LLMs) are increasingly used to generate self-explanations alongside their predictions, a practice that raises concerns about the faithfulness of these explanations, especially in low-resource languages. This study evaluates the faithfulness of LLM-generated explanations in the context of emotion classification in Persian, a low-resource language, by comparing the influential words identified by the model against those identified by human annotators. We assess faithfulness using confidence scores derived from token-level log-probabilities. Two prompting strategies, differing in the order of explanation and prediction (Predict-then-Explain and Explain-then-Predict), are tested for their impact on explanation faithfulness. Our results reveal that while LLMs achieve strong classification performance, their generated explanations often diverge from faithful reasoning, showing greater agreement with each other than with human judgments. These results highlight the limitations of current explanation methods and metrics, emphasizing the need for more robust approaches to ensure LLM reliability in multilingual and low-resource contexts.

</details>


### [3] [Comparative Analysis of LoRA-Adapted Embedding Models for Clinical Cardiology Text Representation](https://arxiv.org/abs/2511.19739)
*Richard J. Young,Alice M. Matthews*

Main category: cs.CL

TL;DR: 本文系统评估了10种心血管领域Transformer嵌入模型，发现编码器模型优于解码器，且高效低耗，相关资源已开源。


<details>
  <summary>Details</summary>
Motivation: 目前领域特定临床文本嵌入方法虽关键，但不同模型结构系统性对比不足，因此本研究旨在填补此空白。

Method: 作者选用10种基于Transformer的嵌入模型，采用LoRA方法在10万余对心血管文本对上进行微调，并系统评估了其表现。

Result: BioLinkBERT等编码器结构在分离分数等指标上显著优于同类和更大规模的解码器模型，同时计算开销更低。所有模型、代码和数据集均已公开。

Conclusion: 本文发现，适用于心脏病领域的编码器结构（如BioLinkBERT）在领域特定文本嵌入任务中表现优于更大规模的解码器模型，且计算资源消耗更少。该结论对临床NLP系统开发具有实际指导意义。

Abstract: Domain-specific text embeddings are critical for clinical natural language processing, yet systematic comparisons across model architectures remain limited. This study evaluates ten transformer-based embedding models adapted for cardiology through Low-Rank Adaptation (LoRA) fine-tuning on 106,535 cardiology text pairs derived from authoritative medical textbooks. Results demonstrate that encoder-only architectures, particularly BioLinkBERT, achieve superior domain-specific performance (separation score: 0.510) compared to larger decoder-based models, while requiring significantly fewer computational resources. The findings challenge the assumption that larger language models necessarily produce better domain-specific embeddings and provide practical guidance for clinical NLP system development. All models, training code, and evaluation datasets are publicly available to support reproducible research in medical informatics.

</details>


### [4] [What does it mean to understand language?](https://arxiv.org/abs/2511.19757)
*Colton Casto,Anna Ivanova,Evelina Fedorenko,Nancy Kanwisher*

Main category: cs.CL

TL;DR: 论文认为理解语言需要将信息从核心语言系统输出到感知、运动和记忆相关区域，并综述了支持该观点的最新认知神经科学证据。


<details>
  <summary>Details</summary>
Motivation: 探讨语言理解为何不止于文字表层意义，揭示需要构建情境的丰富心理模型的神经机制。

Method: 综述现有认知神经科学证据，并提出用新方法直接检测语言理解过程。

Result: 厘清了语言理解涉及的信息输出路径，并指出认知神经科学的发展已能够实证探索相关过程。

Conclusion: 深度的语言理解不仅依赖于核心语言系统，还需要与其他大脑区域协同，如感知、运动表征和记忆系统。

Abstract: Language understanding entails not just extracting the surface-level meaning of the linguistic input, but constructing rich mental models of the situation it describes. Here we propose that because processing within the brain's core language system is fundamentally limited, deeply understanding language requires exporting information from the language system to other brain regions that compute perceptual and motor representations, construct mental models, and store our world knowledge and autobiographical memories. We review the existing evidence for this hypothesis, and argue that recent progress in cognitive neuroscience provides both the conceptual foundation and the methods to directly test it, thus opening up a new strategy to reveal what it means, cognitively and neurally, to understand language.

</details>


### [5] [Gender Bias in Emotion Recognition by Large Language Models](https://arxiv.org/abs/2511.19785)
*Maureen Herbert,Katie Sun,Angelica Lim,Yasaman Etesam*

Main category: cs.CL

TL;DR: 本论文分析了大语言模型在情感推理任务中的性别偏见，并表明只有训练期的干预才能有效去除偏见，单靠推理时调整提示效果有限。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型广泛应用于各类场景，确保其在情感推理方面的公平性显得尤为重要，因此作者关注模型在判定人物情感时是否存在性别偏见，并探索有效的去偏置策略。

Method: 作者提出并评估了多种去偏置策略，包括利用训练阶段的干预措施与推理阶段的提示工程进行对比，重点实验和分析了两者在消除性别偏见方面的效果。

Result: 基于实验，作者发现只有通过训练干预（如针对性别偏见的训练方法）才能显著降低情感推理中的性别偏见，单纯依赖提示工程难以带来明显改进。

Conclusion: 通过训练方法进行去偏置可以在大语言模型的性别情感推理任务中显著减少偏见，而仅靠推理时的提示工程难以实现有效的去偏置。

Abstract: The rapid advancement of large language models (LLMs) and their growing integration into daily life underscore the importance of evaluating and ensuring their fairness. In this work, we examine fairness within the domain of emotional theory of mind, investigating whether LLMs exhibit gender biases when presented with a description of a person and their environment and asked, "How does this person feel?". Furthermore, we propose and evaluate several debiasing strategies, demonstrating that achieving meaningful reductions in bias requires training based interventions rather than relying solely on inference-time prompt-based approaches such as prompt engineering.

</details>


### [6] [Breaking Bad: Norms for Valence, Arousal, and Dominance for over 10k English Multiword Expressions](https://arxiv.org/abs/2511.19816)
*Saif M. Mohammad*

Main category: cs.CL

TL;DR: 对比原NRC VAD词典，此新版本大幅增加了多词表达和常用单词的数据。为情感计算和多领域情感研究提供更全面可靠的资源，免费开放下载。


<details>
  <summary>Details</summary>
Motivation: 目前的NRC VAD词典主要针对单个词（unigrams），且自2018年以来新流行词缺乏覆盖。多词表达（MWEs，包含习语、复合名词、动词短语等）的情感维度数据稀缺。动机是弥补这些空白，提升情感词典的覆盖面和实用性。

Method: 本研究收集了10,000个英语多词表达及其组成词语的Valence（积极性）、Arousal（唤醒度）、Dominance（主控性）三维度的人类评评分。同时扩增了单词（unigram）覆盖，尤其是自2018年以来变得更常见的词汇。对数据的关联度进行了可靠性分析，还探讨了MWEs的情感特征和情感构成度。最后，发布了NRC VAD Lexicon v2并公开获取。

Result: NRC VAD Lexicon v2包含了10k MWEs和25k单词的新情感维度评分，极大扩展了原词典的覆盖范围。评分数据表现出高度可靠性。研究发现MWEs（如习语、复合结构等）具有显著的情感色彩，并对MWEs的情感成分合成度进行了分析。

Conclusion: NRC VAD Lexicon v2为多领域情感计算、心理学、公共健康、数字人文及社会科学等研究提供了大规模、多样化的情感资源，特别提升了多词表达和新流行词汇的情感维度覆盖，将极大促进相关领域研究。

Abstract: Factor analysis studies have shown that the primary dimensions of word meaning are Valence (V), Arousal (A), and Dominance (D). Existing lexicons such as the NRC VAD Lexicon, published in 2018, include VAD association ratings for words. Here, we present a complement to it, which has human ratings of valence, arousal, and dominance for 10k English Multiword Expressions (MWEs) and their constituent words. We also increase the coverage of unigrams, especially words that have become more common since 2018. In all, the new NRC VAD Lexicon v2 now has entries for 10k MWEs and 25k words, in addition to the entries in v1. We show that the associations are highly reliable. We use the lexicon to examine emotional characteristics of MWEs, including: 1. The degree to which MWEs (idioms, noun compounds, and verb particle constructions) exhibit strong emotionality; 2. The degree of emotional compositionality in MWEs. The lexicon enables a wide variety of research in NLP, Psychology, Public Health, Digital Humanities, and Social Sciences. The NRC VAD Lexicon v2 is freely available through the project webpage: http://saifmohammad.com/WebPages/nrc-vad.html

</details>


### [7] [Language-Independent Sentiment Labelling with Distant Supervision: A Case Study for English, Sepedi and Setswana](https://arxiv.org/abs/2511.19818)
*Koena Ronny Mabokela,Tim Schlippe,Mpho Raborife,Turgay Celik*

Main category: cs.CL

TL;DR: 文章提出了一种利用表情符号和情感词的自动化情感标注方法，显著提升了非洲低资源语言文本的标注效率，在三个语言的推文中取得了可用的准确率。


<details>
  <summary>Details</summary>
Motivation: 许多非洲语言属于低资源语言，缺乏带有情感标注的数字文本资源，这使得机器学习或自动化分析面临挑战。手动标注数据耗时且昂贵，因此需要自动化、快速的过程来提高标注效率。

Method: 提出并分析了一种自动化、与语言无关的情感标注方法，利用情感性表情符和情感词的信息。方法在英语、塞佩迪语和塞茨瓦纳语推文数据（来自SAfriSenti多语种情感语料库）上进行实验。

Result: 该自动化情感标注方法对英语推文的标注准确率为66%，塞佩迪语为69%，塞茨瓦纳语为63%，平均只有34%的自动生成标签需要后续人工修正。

Conclusion: 本文提出的方法能有效减轻低资源语言情感分析任务中人工标注的负担，自动化情感标注具有可用性和实用性，特别适用于资源稀缺语言的文本数据。

Abstract: Sentiment analysis is a helpful task to automatically analyse opinions and emotions on various topics in areas such as AI for Social Good, AI in Education or marketing. While many of the sentiment analysis systems are developed for English, many African languages are classified as low-resource languages due to the lack of digital language resources like text labelled with corresponding sentiment classes. One reason for that is that manually labelling text data is time-consuming and expensive. Consequently, automatic and rapid processes are needed to reduce the manual effort as much as possible making the labelling process as efficient as possible. In this paper, we present and analyze an automatic language-independent sentiment labelling method that leverages information from sentiment-bearing emojis and words. Our experiments are conducted with tweets in the languages English, Sepedi and Setswana from SAfriSenti, a multilingual sentiment corpus for South African languages. We show that our sentiment labelling approach is able to label the English tweets with an accuracy of 66%, the Sepedi tweets with 69%, and the Setswana tweets with 63%, so that on average only 34% of the automatically generated labels remain to be corrected.

</details>


### [8] [Profile-LLM: Dynamic Profile Optimization for Realistic Personality Expression in LLMs](https://arxiv.org/abs/2511.19852)
*Shi-Wei Dai,Yan-Wei Shie,Tsung-Huan Yang,Lun-Wei Ku,Yung-Hui Li*

Main category: cs.CL

TL;DR: PersonaPulse框架通过动态优化提示词显著提升LLMs的人格表达真实感与灵活性，为未来个性化和自适应AI交互提供了新思路和实践路径。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅用提示词诱发LLMs的人格特质，但未针对最大化人格表达进行提示词优化，导致人格展现不够充分和真实。为此，作者希望提出方法，提升和细致调控LLMs的人格化输出。

Method: 提出PersonaPulse框架，利用LLMs对人格特质的知识，结合情境响应基准分数，迭代优化角色扮演提示词，并与心理学人格描述设计的提示词进行定量对比测试。

Result: PersonaPulse生成的提示词较基于传统心理学描述的提示词表现更优；通过大规模实验评估了模型规模与人格建模能力间的关系，并发现可通过中止优化过程调控特定人格特质的表达程度。

Conclusion: PersonaPulse可以有效提升LLMs的个性化表达能力，通过动态优化角色扮演提示词，使虚拟人格的表达更加真实和情境化，在未来适应性AI交互研究中具有重要应用价值。

Abstract: Personalized Large Language Models (LLMs) have been shown to be an effective way to create more engaging and enjoyable user-AI interactions. While previous studies have explored using prompts to elicit specific personality traits in LLMs, they have not optimized these prompts to maximize personality expression. To address this limitation, we propose PersonaPulse: Dynamic Profile Optimization for Realistic Personality Expression in LLMs, a framework that leverages LLMs' inherent knowledge of personality traits to iteratively enhance role-play prompts while integrating a situational response benchmark as a scoring tool, ensuring a more realistic and contextually grounded evaluation to guide the optimization process. Quantitative evaluations demonstrate that the prompts generated by PersonaPulse outperform those of prior work, which were designed based on personality descriptions from psychological studies. Additionally, we explore the relationship between model size and personality modeling through extensive experiments. Finally, we find that, for certain personality traits, the extent of personality evocation can be partially controlled by pausing the optimization process. These findings underscore the importance of prompt optimization in shaping personality expression within LLMs, offering valuable insights for future research on adaptive AI interactions.

</details>


### [9] [A Systematic Analysis of Large Language Models with RAG-enabled Dynamic Prompting for Medical Error Detection and Correction](https://arxiv.org/abs/2511.19858)
*Farzad Ahmed,Joniel Augustine Jerome,Meliha Yetisgen,Özlem Uzuner*

Main category: cs.CL

TL;DR: 该论文比较了三种LLM提示方式用于医学文档错误检测与纠正，发现基于检索的动态提示法最优，显著提高准确性和减少误报，为实际医疗场景中的文档纠错和安全保障带来更强支持。


<details>
  <summary>Details</summary>
Motivation: 临床文档中常见错误可能危及病人安全，而人工检测这些错误既耗时又容易遗漏。尽管理论上大型语言模型可辅助发现并纠正此类错误，但不同提示策略下LLM的具体表现尚不明确。本研究旨在明确不同提示方法对于医学错误检测与纠正任务的效果差异。

Method: 本研究采用MEDEC数据集，对九种指令微调的大型语言模型（包括GPT、Claude、Gemini及OpenAI o系列）进行了对比实验。实验涵盖三项医学错误处理子任务：错误标注检测、错误句子检测、以及错误纠正。分别评估了零样本提示、静态随机举例提示和检索增强动态提示三种提示策略，并用准确率、召回率、假阳性率和ROUGE-1、BLEURT、BERTScore综合指标评价纠错表现。

Result: 零样本提示法在检测任务中召回率偏低，尤其易漏检缩略语或非典型错误。静态随机例子提示虽提升召回率，但增加了假阳性。检索增强动态提示能在全部九种LLM中显著降低假阳性（约15%），提升错误句子检测召回率（5-10%），并生成更具上下文相关性的纠错建议。

Conclusion: 在多种大型语言模型（LLM）中，基于检索增强的动态提示（RDP）方法相较于零样本提示（zero-shot prompting）和静态随机举例提示（SPR）表现更优。通过检索相关示例，能提升错误检测的准确率，降低误报率，并增强医学文档纠错的可靠性。

Abstract: Objective: Clinical documentation contains factual, diagnostic, and management errors that can compromise patient safety. Large language models (LLMs) may help detect and correct such errors, but their behavior under different prompting strategies remains unclear. We evaluate zero-shot prompting, static prompting with random exemplars (SPR), and retrieval-augmented dynamic prompting (RDP) for three subtasks of medical error processing: error flag detection, error sentence detection, and error correction.
  Methods: Using the MEDEC dataset, we evaluated nine instruction-tuned LLMs (GPT, Claude, Gemini, and OpenAI o-series models). We measured performance using accuracy, recall, false-positive rate (FPR), and an aggregate score of ROUGE-1, BLEURT, and BERTScore for error correction. We also analyzed example outputs to identify failure modes and differences between LLM and clinician reasoning.
  Results: Zero-shot prompting showed low recall in both detection tasks, often missing abbreviation-heavy or atypical errors. SPR improved recall but increased FPR. Across all nine LLMs, RDP reduced FPR by about 15 percent, improved recall by 5 to 10 percent in error sentence detection, and generated more contextually accurate corrections.
  Conclusion: Across diverse LLMs, RDP outperforms zero-shot and SPR prompting. Using retrieved exemplars improves detection accuracy, reduces false positives, and enhances the reliability of medical error correction.

</details>


### [10] [$\text{R}^2\text{R}$: A Route-to-Rerank Post-Training Framework for Multi-Domain Decoder-Only Rerankers](https://arxiv.org/abs/2511.19987)
*Xinyu Wang,Hanwei Wu,Qingchen Hu,Zhenghan Tai,Jingrui Tian,Lei Ding,Jijun Chi,Hailin He,Tung Sum Thomas Kwok,Yufei Cui,Sicheng Lyu,Muzhi Li,Mingze Li,Xinyue Yu,Ling Zhou,Peng Lu*

Main category: cs.CL

TL;DR: R2R通过动态专家路由和实体抽象泛化，解决RAG重排序在高风险领域的泛化与表面过拟合问题，在多个领域实验中表现优越且具备跨域鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有解码器重排序器在金融、法律等领域难以捕捉细微领域差异，直接微调又容易出现表面过拟合和灾难性遗忘，亟需通用、模块化、具领域适应性的RAG重排序框架。

Method: 提出R2R框架：1）动态专家路由结合两阶段训练策略；2）采用EAG（实体抽象泛化）机制，屏蔽关键实体表征以阻断捷径学习，促进模型学习领域不变的相关性；3）通过轻量级的Latent Semantic Router探查解码器内部特征，按查询动态选择最优LoRA专家。

Result: 在不同重排序主干和多种高风险领域数据集实验，R2R均显著优于通用和单域微调模型，实现了领域专化与跨领域泛化能力的兼顾。

Conclusion: R2R框架能够有效提升RAG系统在法律、医学和金融等高风险领域的重排序性能，比通用和单域微调基线表现更佳，且具备很强的跨域鲁棒性。

Abstract: Decoder-only rerankers are central to Retrieval-Augmented Generation (RAG). However, generalist models miss domain-specific nuances in high-stakes fields like finance and law, and naive fine-tuning causes surface-form overfitting and catastrophic forgetting. To address this challenge, we introduce R2R, a domain-aware framework that combines dynamic expert routing with a two-stage training strategy, Entity Abstraction for Generalization (EAG). EAG introduces a counter-shortcut mechanism by masking the most predictive surface cues, forcing the reranker to learn domain-invariant relevance patterns rather than memorizing dataset-specific entities. To efficiently activate domain experts, R2R employs a lightweight Latent Semantic Router that probes internal representations from the frozen backbone decoder to select the optimal LoRA expert per query. Extensive experiments across different reranker backbones and diverse domains (legal, medical, and financial) demonstrate that R2R consistently surpasses generalist and single-domain fine-tuned baselines. Our results confirm that R2R is a model-agnostic and modular approach to domain specialization with strong cross-domain robustness.

</details>


### [11] [Directional Optimization Asymmetry in Transformers: A Synthetic Stress Test](https://arxiv.org/abs/2511.19997)
*Mihir Sahasrabudhe*

Main category: cs.CL

TL;DR: 本文通过合成无语义基准，发现Transformer模型即使在缺乏任何真实语言偏置下，依然难以有效学到序列反向映射，揭示了Transformer固有的方向性劣化，与语料无关。


<details>
  <summary>Details</summary>
Motivation: 此前Transformer理论具备可逆性，但实际训练（如LLM与自然语言）始终表现出“逆序诅咒”，究竟是由数据偏置还是模型结构带来的，一直未有清晰结论。本文希望通过消除一切语义和统计变量，纯粹测试架构自身的方向差异。

Method: 作者设计了可控熵的合成基准，利用随机字符串映射任务，明确前向（熵为零）和逆向（可分析下界）任务，并在GPT-2和MLP之间进行对比实验，检验各种初始化和LoRA下模型表现。

Result: GPT-2等基于Transformer的模型在逆向任务上表现出持久且显著的损失劣势（如K=5时为1.16纳特），超过MLP，且预训练与LoRA等方法无法消除这一现象。这表明方向性瓶颈是内在且独立于数据语料特性的。

Conclusion: 本文通过全合成基准彻底剥离语义、统计等语言因素，证明因果Transformer在序列逆向学习上存在固有的方向性“摩擦”。该现象并非仅由自然语言数据偏置、预训练、频率或语序导致，而是模型本身的训练机制所致。

Abstract: Transformers are theoretically reversal-invariant: their function class does not prefer left-to-right over right-to-left mappings. Yet empirical studies on natural language repeatedly report a "reversal curse," and recent work on temporal asymmetry in LLMs suggests that real-world corpora carry their own arrow of time. This leaves an unresolved question: do directional failures stem from linguistic statistics, or from the architecture itself? We cut through this ambiguity with a fully synthetic, entropy-controlled benchmark designed as a clean-room stress test for directional learning. Using random string mappings with tunable branching factor K, we construct forward tasks with zero conditional entropy and inverse tasks with analytically determined entropy floors. Excess loss above these floors reveals that even scratch-trained GPT-2 models exhibit a strong, reproducible directional optimization gap (e.g., 1.16 nats at K=5), far larger than that of an MLP trained on the same data. Pre-trained initializations shift optimization behavior but do not eliminate this gap, while LoRA encounters a sharp capacity wall on high-entropy inverse mappings. Together, these results isolate a minimal, semantics-free signature of directional friction intrinsic to causal Transformer training-one that persists even when linguistic priors, token frequencies, and corpus-level temporal asymmetries are removed. Our benchmark provides a controlled instrument for dissecting directional biases in modern sequence models and motivates deeper mechanistic study of why inversion remains fundamentally harder for Transformers.

</details>


### [12] [Online-PVLM: Advancing Personalized VLMs with Online Concept Learning](https://arxiv.org/abs/2511.20056)
*Huiyu Bai,Runze Wang,Zhuoyun Du,Yiyang Zhao,Fengji Zhang,Haoyu Chen,Xiaoyong Zhu,Bo Zheng,Xuejiao Zhao*

Main category: cs.CL

TL;DR: 本文提出了Online-PVLM，通过超球嵌入实现测试时无训练的个性化概念生成，支持模型实时扩展和大规模检索，并首次构建了完整的大型基准集合，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有个性化视觉语言模型在学习用户特定概念时，需为每个新概念单独训练嵌入，导致测试阶段无法在线适应且大规模场景检索低效。该工作旨在解决实时性和扩展性不足的问题。

Method: 利用超球几何表示，实现测试时无需训练即可生成个性化概念嵌入，提高了模型在实时场景下的扩展性和效率；并设计了大规模的基准数据集OP-Eval用于评估。

Result: 提出的方法无需训练即可在测试阶段生成个性化概念嵌入，改善了大规模与实时应用中的效率和适应性，在新构建的大型OP-Eval基准上取得了最优实验效果。

Conclusion: 提出的Online-PVLM框架在个性化视觉语言模型的在线概念学习任务中达到了当前最优性能。

Abstract: Personalized Visual Language Models (VLMs) are gaining increasing attention for their formidable ability in user-specific concepts aligned interactions (e.g., identifying a user's bike). Existing methods typically require the learning of separate embeddings for each new concept, which fails to support real-time adaptation during testing. This limitation becomes particularly pronounced in large-scale scenarios, where efficient retrieval of concept embeddings is not achievable. To alleviate this gap, we propose Online-PVLM, a framework for online concept learning by leveraging hyperbolic representations. Our approach makes a train-free paradigm for concept embeddings generation at test time, making the use of personalized VLMs both scalable and efficient. In addition, we develop OP-Eval, a comprehensive and large-scale benchmark comprising 1,292 concepts and over 30K high-quality instances with diverse question types, designed to rigorously assess online concept learning in realistic scenarios. Extensive experiments demonstrate the state-of-the-art performance of our proposed framework. Our source code and dataset will be made available.

</details>


### [13] [MTA: A Merge-then-Adapt Framework for Personalized Large Language Model](https://arxiv.org/abs/2511.20072)
*Xiaopeng Li,Yuanjin Zheng,Wanyu Wang,wenlin zhang,Pengyue Jia,Yiqi Wang,Maolin Wang,Xuetao Wei,Xiangyu Zhao*

Main category: cs.CL

TL;DR: 本文提出的MTA框架利用锚点用户LoRA共享和动态融合，并通过叠加轻量模块实现高效个性化，突破存储和稀疏数据局限，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前个性化大语言模型（PLLMs）面临每个用户都需单独微调的方式，导致存储成本随用户数量线性增长，不具备可扩展性；此外，对于数据稀疏用户，单独微调常产生次优性能。研究动机即提出更高效、可扩展的个性化方法以解决上述瓶颈。

Method: 提出MTA（Merge-then-Adapt）框架，包括三大步骤：1）构建共享的Meta-LoRA Bank，预训练多个锚点用户的LoRA模块作为个性化特征基底；2）Adaptive LoRA Fusion阶段，检索并动态融合最相关的鉴点meta-LoRA，不再需要单独为每用户存储，对更广泛组合个性化需求支持更灵活；3）LoRA Stacking for Few-Shot阶段，在融合LoRA模块上叠加超低秩、轻量的LoRA，并对此进行微调，使个性化在少量样本下有效实现。

Result: 在LaMP基准上的多项任务实验显示，该方法在准确性和泛化性等指标上优于现有最优方法（SOTA），验证了其可扩展性及少样本下的个性化能力。

Conclusion: MTA框架通过Meta-LoRA共享、动态模块融合和轻量叠加微调，有效解决了个性化大模型存储不可扩展和稀疏数据场景下个性化效果不佳问题，在准确率和可扩展性方面均实现超越。

Abstract: Personalized Large Language Models (PLLMs) aim to align model outputs with individual user preferences, a crucial capability for user-centric applications. However, the prevalent approach of fine-tuning a separate module for each user faces two major limitations: (1) storage costs scale linearly with the number of users, rendering the method unscalable; and (2) fine-tuning a static model from scratch often yields suboptimal performance for users with sparse data. To address these challenges, we propose MTA, a Merge-then-Adapt framework for PLLMs. MTA comprises three key stages. First, we construct a shared Meta-LoRA Bank by selecting anchor users and pre-training meta-personalization traits within meta-LoRA modules. Second, to ensure scalability and enable dynamic personalization combination beyond static models, we introduce an Adaptive LoRA Fusion stage. This stage retrieves and dynamically merges the most relevant anchor meta-LoRAs to synthesize a user-specific one, thereby eliminating the need for user-specific storage and supporting more flexible personalization. Third, we propose a LoRA Stacking for Few-Shot Personalization stage, which applies an additional ultra-low-rank, lightweight LoRA module on top of the merged LoRA. Fine-tuning this module enables effective personalization under few-shot settings. Extensive experiments on the LaMP benchmark demonstrate that our approach outperforms existing SOTA methods across multiple tasks.

</details>


### [14] [More Bias, Less Bias: BiasPrompting for Enhanced Multiple-Choice Question Answering](https://arxiv.org/abs/2511.20086)
*Duc Anh Vu,Thong Nguyen,Cong-Duy Nguyen,Viet Anh Nguyen,Anh Tuan Luu*

Main category: cs.CL

TL;DR: 该文提出了BiasPrompting推理框架，通过对所有选项生成和评估推理理由，有效提升大语言模型在多项选择题任务上的能力，实验结果表明其优势明显。


<details>
  <summary>Details</summary>
Motivation: 现有多项选择题任务方法不足，主要体现在答案选项缺乏上下文解释，导致模型推理不充分，影响最终答题准确性。

Method: 提出了一种新的推理框架BiasPrompting，包括为每个选项生成推理理由，并通过整合这些理由进行最终答案选择。

Result: 在五个主流多项选择题基准上，BiasPrompting均取得了显著性能提升，表现优于传统方法，模型推理能力也得到更好体现。

Conclusion: BiasPrompting能够显著提升大语言模型在多项选择题任务上的推理和答题表现，尤其是在复杂问题和现有方法效果不佳时，展现出明显优势。

Abstract: With the advancement of large language models (LLMs), their performance on multiple-choice question (MCQ) tasks has improved significantly. However, existing approaches face key limitations: answer choices are typically presented to LLMs without contextual grounding or explanation. This absence of context can lead to incomplete exploration of all possible answers, ultimately degrading the models' reasoning capabilities. To address these challenges, we introduce BiasPrompting, a novel inference framework that guides LLMs to generate and critically evaluate reasoning across all plausible answer options before reaching a final prediction. It consists of two components: first, a reasoning generation stage, where the model is prompted to produce supportive reasonings for each answer option, and then, a reasoning-guided agreement stage, where the generated reasonings are synthesized to select the most plausible answer. Through comprehensive evaluations, BiasPrompting demonstrates significant improvements in five widely used multiple-choice question answering benchmarks. Our experiments showcase that BiasPrompting enhances the reasoning capabilities of LLMs and provides a strong foundation for tackling complex and challenging questions, particularly in settings where existing methods underperform.

</details>


### [15] [SSA: Sparse Sparse Attention by Aligning Full and Sparse Attention Outputs in Feature Space](https://arxiv.org/abs/2511.20102)
*Zhenyi Shen,Junru Lu,Lin Gui,Jiazheng Li,Yulan He,Di Yin,Xing Sun*

Main category: cs.CL

TL;DR: 本文提出SSA训练框架，解决稀疏注意力训练中的梯度流与输出对齐问题，实现高效、强稀疏性、高性能的大语言模型，并在长上下文处理与灵活推理上展现优异表现。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）在处理长上下文时，完全注意力机制的计算复杂度较高，限制了其高效应用。稀疏注意力机制虽然能够缓解计算成本，但通常会带来显著的性能损失。已有的原生稀疏注意力方法虽有改善，但存在稀疏度反而低于全注意力模型的悖论，影响效果。

Method: 提出了一个统一的训练框架SSA（Sparse Sparse Attention），在每一层同时考虑稀疏和完全注意力，并强制双向对齐；既保留所有token的梯度流，又显式鼓励稀疏注意力输出对齐于完全注意力结果，以增强稀疏性。

Result: SSA在多个常识性任务基准下，无论是稀疏或全注意力推理均达到了当前最优性能。同时，允许模型根据推理时可分配的稀疏预算灵活调整，更多token参与注意力时性能持续提升。此外，原生稀疏注意力训练在长上下文外推方面有意外效果，SSA提升了超长上下文适应能力。

Conclusion: SSA有效解决了原生稀疏注意力训练中的梯度缺失问题，实现了高稀疏度与强性能兼顾，支持灵活推理并提升长上下文泛化能力。

Abstract: The quadratic complexity of full attention limits efficient long-context processing in large language models (LLMs). Sparse attention mitigates this cost by restricting each query to attend to a subset of previous tokens; however, training-free approaches often lead to severe performance degradation. Native sparse-attention methods (e.g., NSA, MoBA) alleviate this issue, yet exhibit a critical paradox: they produce lower attention sparsity than full-attention models, despite aiming to approximate full attention, which may constrain their effectiveness. We attribute this paradox to gradient update deficiency: low-ranked key-value pairs excluded during sparse training receive neither forward contribution nor backward gradients, and thus never learn proper suppression. To overcome this limitation, we propose SSA (Sparse Sparse Attention), a unified training framework that considers both sparse and full attention and enforces bidirectional alignment at every layer. This design preserves gradient flow to all tokens while explicitly encouraging sparse-attention outputs to align with their full-attention counterparts, thereby promoting stronger sparsity. As a result, SSA achieves state-of-the-art performance under both sparse and full attention inference across multiple commonsense benchmarks. Furthermore, SSA enables models to adapt smoothly to varying sparsity budgets; performance improves consistently as more tokens are allowed to attend, supporting flexible compute-performance trade-offs at inference time. Finally, we show that native sparse-attention training surprisingly improves long-context extrapolation by mitigating the over-allocation of attention values in sink areas, with SSA demonstrating the strongest extrapolation capability.

</details>


### [16] [EM2LDL: A Multilingual Speech Corpus for Mixed Emotion Recognition through Label Distribution Learning](https://arxiv.org/abs/2511.20106)
*Xingfeng Li,Xiaohan Shi,Junjie Li,Yongwei Li,Masashi Unoki,Tomoki Toda,Masato Akagi*

Main category: cs.CL

TL;DR: EM2LDL提出了多语种、混合情感的语料库，突破了传统情感识别的限制，提升了模型对真实多语种场景下复杂情感的适应力，为情感计算等领域提供了重要资源。


<details>
  <summary>Details</summary>
Motivation: 现有情感语料库主要为单语言、单标签，无法反映多语种和混合情感表达，对真实多语言社交场景的适应性较差。为了解决这一问题，推动混合情感识别与多语种情感计算的进步。

Method: 构建了涵盖英语、普通话和粤语表达的多语种混合情感语料库，并采用细粒度的32类情感分布标注，融合自发性情感语料，包含真实场景下的跨语种切换，使用自监督学习模型（如HuBERT-large-EN）建立基线实验。

Result: EM2LDL语料库展示了在不同说话人、性别、年龄及个性分组下的混合情感识别基线，HuBERT-large-EN模型表现最佳。语料库支持更复杂的情感动态分析，同时公开了数据、标注及基线代码。

Conclusion: EM2LDL语料库突破了以往单语种、单标签情感语料库的局限，提升了情感识别系统在多语种和混合情感场景下的适应能力。该语料库及相关资源为情感计算和跨文化交流等应用提供了新的测试平台。

Abstract: This study introduces EM2LDL, a novel multilingual speech corpus designed to advance mixed emotion recognition through label distribution learning. Addressing the limitations of predominantly monolingual and single-label emotion corpora \textcolor{black}{that restrict linguistic diversity, are unable to model mixed emotions, and lack ecological validity}, EM2LDL comprises expressive utterances in English, Mandarin, and Cantonese, capturing the intra-utterance code-switching prevalent in multilingual regions like Hong Kong and Macao. The corpus integrates spontaneous emotional expressions from online platforms, annotated with fine-grained emotion distributions across 32 categories. Experimental baselines using self-supervised learning models demonstrate robust performance in speaker-independent gender-, age-, and personality-based evaluations, with HuBERT-large-EN achieving optimal results. By incorporating linguistic diversity and ecological validity, EM2LDL enables the exploration of complex emotional dynamics in multilingual settings. This work provides a versatile testbed for developing adaptive, empathetic systems for applications in affective computing, including mental health monitoring and cross-cultural communication. The dataset, annotations, and baseline codes are publicly available at https://github.com/xingfengli/EM2LDL.

</details>


### [17] [Mispronunciation Detection and Diagnosis Without Model Training: A Retrieval-Based Approach](https://arxiv.org/abs/2511.20107)
*Huu Tuong Tu,Ha Viet Khanh,Tran Tien Dat,Vu Huan,Thien Van Luong,Nguyen Tien Cuong,Nguyen Thi Thu Trang*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的新型误发检测方法，依赖检索和预训练ASR即可实现高效准确的发音错误检测与诊断，有效简化了实现流程并取得了优异实验结果。


<details>
  <summary>Details</summary>
Motivation: 当前误发检测方法大多需要复杂的打分模型、音素级别建模或额外的模型训练，增加了系统的开发和部署难度。

Method: 利用检索方法结合预训练的自动语音识别（ASR）模型，对发音错误进行检测和诊断，无需对音素建模或针对特定任务再训练。

Result: 在L2-ARCTIC数据集上的实验中，所提方法F1分数达到69.60%，且避免了模型训练的复杂性。

Conclusion: 提出了一种新的、无需训练的误发检测与诊断框架，通过检索技术和预训练ASR模型，达到了高准确率，简化了系统实现。

Abstract: Mispronunciation Detection and Diagnosis (MDD) is crucial for language learning and speech therapy. Unlike conventional methods that require scoring models or training phoneme-level models, we propose a novel training-free framework that leverages retrieval techniques with a pretrained Automatic Speech Recognition model. Our method avoids phoneme-specific modeling or additional task-specific training, while still achieving accurate detection and diagnosis of pronunciation errors. Experiments on the L2-ARCTIC dataset show that our method achieves a superior F1 score of 69.60% while avoiding the complexity of model training.

</details>


### [18] ["When Data is Scarce, Prompt Smarter"... Approaches to Grammatical Error Correction in Low-Resource Settings](https://arxiv.org/abs/2511.20120)
*Somsubhra De,Harsh Kumar,Arun Prakash A*

Main category: cs.CL

TL;DR: 通过基于提示的大型语言模型方法，显著提升了低资源Indic语种的自动语法纠错能力，在多个国际任务中取得领先，展现了LLM跨语言泛化和提示设计的巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 现有以英语等高资源语种为主的GEC模型精度高，但在Indic等低资源语种上表现欠佳，主要原因为可用数据有限、语言多样性和复杂词形变化等挑战。

Method: 采用多种主流LLM（如GPT-4.1、Gemini-2.5、LLaMA-4），结合零样本和少样本提示学习法，将其适配低资源语种的语法纠错任务，并与已针对Indic语种调优的模型进行对比实验。

Result: 简单的零样本、少样本提示法让LLM优于本地化调优模型（如Sarvam-22B）；适当设计提示和少量适配即可大幅提升多种Indic语种的纠错质量，在多个Shared task排名靠前。GLEU分数分别为泰米尔语91.57、印地语85.69、泰卢固语85.22、孟加拉语92.86、马拉雅拉姆语92.97。

Conclusion: 强化提示驱动的大型语言模型（LLM）方法可以显著提升多语种尤其是低资源Indic语种的语法纠错（GEC）性能。

Abstract: Grammatical error correction (GEC) is an important task in Natural Language Processing that aims to automatically detect and correct grammatical mistakes in text. While recent advances in transformer-based models and large annotated datasets have greatly improved GEC performance for high-resource languages such as English, the progress has not extended equally. For most Indic languages, GEC remains a challenging task due to limited resources, linguistic diversity and complex morphology. In this work, we explore prompting-based approaches using state-of-the-art large language models (LLMs), such as GPT-4.1, Gemini-2.5 and LLaMA-4, combined with few-shot strategy to adapt them to low-resource settings. We observe that even basic prompting strategies, such as zero-shot and few-shot approaches, enable these LLMs to substantially outperform fine-tuned Indic-language models like Sarvam-22B, thereby illustrating the exceptional multilingual generalization capabilities of contemporary LLMs for GEC. Our experiments show that carefully designed prompts and lightweight adaptation significantly enhance correction quality across multiple Indic languages. We achieved leading results in the shared task--ranking 1st in Tamil (GLEU: 91.57) and Hindi (GLEU: 85.69), 2nd in Telugu (GLEU: 85.22), 4th in Bangla (GLEU: 92.86), and 5th in Malayalam (GLEU: 92.97). These findings highlight the effectiveness of prompt-driven NLP techniques and underscore the potential of large-scale LLMs to bridge resource gaps in multilingual GEC.

</details>


### [19] [SEDA: A Self-Adapted Entity-Centric Data Augmentation for Boosting Gird-based Discontinuous NER Models](https://arxiv.org/abs/2511.20143)
*Wen-Fang Su,Hsiao-Wei Chou,Wen-Yang Lin*

Main category: cs.CL

TL;DR: 该论文通过在网格模型中引入图像增强技术，显著提升了对不连续实体的NER表现，尤其在处理跨句子和分割难题时效果明显。


<details>
  <summary>Details</summary>
Motivation: 传统的分割方法往往难以准确分割或遗漏跨句子的不连续实体，导致NER准确率受损，亟需新的方法改善这一难点。

Method: 采用基于网格的标签方法进行NER，并在其基础上引入图像领域常用的数据增强技术（如裁剪、缩放和填充），从而增强模型对不连续实体和分割挑战的鲁棒性。

Result: 在CADEC、ShARe13和ShARe14数据集上，所提出方法的F1分数整体提升1-2.5%，对不连续实体的识别提升3.7-8.4%。

Conclusion: 将图像数据增强技术融入到基于网格的命名实体识别（NER）模型，能够有效提升对跨句子不连续实体的识别性能。

Abstract: Named Entity Recognition (NER) is a critical task in natural language processing, yet it remains particularly challenging for discontinuous entities. The primary difficulty lies in text segmentation, as traditional methods often missegment or entirely miss cross-sentence discontinuous entities, significantly affecting recognition accuracy. Therefore, we aim to address the segmentation and omission issues associated with such entities. Recent studies have shown that grid-tagging methods are effective for information extraction due to their flexible tagging schemes and robust architectures. Building on this, we integrate image data augmentation techniques, such as cropping, scaling, and padding, into grid-based models to enhance their ability to recognize discontinuous entities and handle segmentation challenges. Experimental results demonstrate that traditional segmentation methods often fail to capture cross-sentence discontinuous entities, leading to decreased performance. In contrast, our augmented grid models achieve notable improvements. Evaluations on the CADEC, ShARe13, and ShARe14 datasets show F1 score gains of 1-2.5% overall and 3.7-8.4% for discontinuous entities, confirming the effectiveness of our approach.

</details>


### [20] [REFLEX: Self-Refining Explainable Fact-Checking via Disentangling Truth into Style and Substance](https://arxiv.org/abs/2511.20233)
*Chuyi Kong,Gao Wei,Jing Ma,Hongzhan Lin,Zhiyuan Fan*

Main category: cs.CL

TL;DR: REFLEX是一种自我优化的事实核查范式，无需外部知识源，通过模型内部对比激活信号提升判决和解释双重表现，实现小样本高效训练，并在真实性核查上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的虚假信息威胁公众信任，需要能提供可解释、高效和实时判决的自动化事实核查系统，而现有大模型依赖外部知识，导致延迟高、易出现幻觉，影响可靠性和可解释性。

Method: 提出一种称为REFLEX的插件化自我优化方法，将事实核查任务重构为角色扮演对话任务，通过联合训练判决预测和解释生成。利用主干模型及其微调模型间的对比激活对提取“steering vectors”，引导推理、抑制噪声、提升解释和判决准确性。实验在真实世界数据集上验证方法效果。

Result: REFLEX在仅用465条自我优化样本下刷新了真实性核查任务的SOTA，且“解释目标”模型能显著提升非解释目标模型（提升幅度最大达7.57%），展示出的内部解释信号具备诠释及增强推理的双重价值。

Conclusion: REFLEX范式能够有效提升自动化事实核查系统的准确性和可解释性，实现了对模型判决和解释的同步优化，在小样本条件下获得了SOTA成果，并证明内在解释信号不仅可解释，而且能提升推理效果。

Abstract: The prevalence of misinformation on social media threatens public trust, demanding automated fact-checking systems that provide accurate verdicts with interpretable explanations. However, existing large language model-based (LLM-based) approaches often rely heavily on external knowledge sources, introducing substantial latency and even hallucinations that undermine reliability, interpretability, and responsiveness, which is crucial for real-time use. To address these challenges, we propose REason-guided Fact-checking with Latent EXplanations REFLEX paradigm, a plug-and-play, self-refining paradigm that leverages the internal knowledge in backbone model to improve both verdict accuracy and explanation quality. REFLEX reformulates fact-checking as a role-play dialogue and jointly trains verdict prediction and explanation generation. It adaptively extracts contrastive activation pairs between the backbone model and its fine-tuned variant to construct steering vectors that disentangle truth into style and substance naturally. These activation-level signals guide inference and suppress noisy explanations, enabling more faithful and efficient reasoning. Experiments on real-world datasets show that REFLEX outperforms previous methods that steer toward a single truth direction and underscores the challenge traditional approaches face when handling the subtle, human-unknown truth in fact-checking tasks. Remarkably, with only 465 self-refined training samples, RELFEX achieves state-of-the-art performance. Furthermore, models trained with explanatory objectives can effectively guide those without them, yielding up to a 7.57% improvement, highlighting that internal explanation signals play a dual role in both interpreting and enhancing factual reasoning.

</details>


### [21] [Scaling LLM Speculative Decoding: Non-Autoregressive Forecasting in Large-Batch Scenarios](https://arxiv.org/abs/2511.20340)
*Luohe Shi,Zuchao Li,Lefei Zhang,Baoyuan Qi,Guoming Liu,Hai Zhao*

Main category: cs.CL

TL;DR: SpecFormer通过创新结构融合了自回归和并行生成优势，解决了投机解码在低资源和大批量下的加速难题，大幅提升了大语言模型推理效率且降低了成本。


<details>
  <summary>Details</summary>
Motivation: 现有的投机解码方法假设有大量可用计算力，但实际中，批量化推理已高度压缩了空闲计算资源，使得低核算资源下的投机解码需求变得重要。本文旨在设计更有效的模型，解决现有方法在低资源和低调度成本场景下的局限。

Method: 设计了一种结合单向与双向注意力机制的新型SpecFormer架构，通过在草稿序列上实现并行生成，既兼容自回归和非自回归模型优点，又避免了复杂的大型前缀树结构。实验采用无损投机解码，对不同规模模型做对比实验，验证效果及效率。

Result: SpecFormer在各种规模语言模型和大批量场景中均实现了推理速度提升，降低了训练和计算成本，实验结果优于现有投机解码方法，树立了大模型推理扩展的新标准。

Conclusion: SpecFormer能够在低计算资源情况下，通过创新的结构设计，实现大语言模型推理的加速，而且在不同规模模型和批量场景下均有效，并且有更低的训练和计算成本。

Abstract: Speculative decoding accelerates LLM inference by utilizing otherwise idle computational resources during memory-to-chip data transfer. Current speculative decoding methods typically assume a considerable amount of available computing power, then generate a complex and massive draft tree using a small autoregressive language model to improve overall prediction accuracy. However, methods like batching have been widely applied in mainstream model inference systems as a superior alternative to speculative decoding, as they compress the available idle computing power. Therefore, performing speculative decoding with low verification resources and low scheduling costs has become an important research problem. We believe that more capable models that allow for parallel generation on draft sequences are what we truly need. Recognizing the fundamental nature of draft models to only generate sequences of limited length, we propose SpecFormer, a novel architecture that integrates unidirectional and bidirectional attention mechanisms. SpecFormer combines the autoregressive model's ability to extract information from the entire input sequence with the parallel generation benefits of non-autoregressive models. This design eliminates the reliance on large prefix trees and achieves consistent acceleration, even in large-batch scenarios. Through lossless speculative decoding experiments across models of various scales, we demonstrate that SpecFormer sets a new standard for scaling LLM inference with lower training demands and reduced computational costs.

</details>


### [22] [The Curious Case of Analogies: Investigating Analogical Reasoning in Large Language Models](https://arxiv.org/abs/2511.20344)
*Taewhoo Lee,Minju Song,Chanwoong Yoon,Jungwoo Park,Jaewoo Kang*

Main category: cs.CL

TL;DR: 本文发现LLMs具备一定的高级关系类比推理能力，但远未达到人类水准，尤其在关系迁移与结构对齐方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs已知能表征任务模式和表层概念，但其能否捕捉和应用更高阶的关系型概念仍不明确，因此探究这一人类核心认知能力在模型中的体现。

Method: 通过对比例与故事类类比推理任务，分析LLMs在理解和迁移关系信息时的内部表示层（中上层），并通过修补隐藏层表示的方法辅助推理。

Result: LLMs能有效编码类比实体间的底层关系信息，但在关系信息缺失或需要迁移到新实体时往往表现不佳。通过补丁方式可部分提升迁移。成功推理表现为强的结构对齐，失败则为结构对齐弱化或错误。

Conclusion: LLMs在编码和应用高级关系概念方面展现出一定能力，但仍存在局限，与人类认知存在异同。

Abstract: Analogical reasoning is at the core of human cognition, serving as an important foundation for a variety of intellectual activities. While prior work has shown that LLMs can represent task patterns and surface-level concepts, it remains unclear whether these models can encode high-level relational concepts and apply them to novel situations through structured comparisons. In this work, we explore this fundamental aspect using proportional and story analogies, and identify three key findings. First, LLMs effectively encode the underlying relationships between analogous entities; both attributive and relational information propagate through mid-upper layers in correct cases, whereas reasoning failures reflect missing relational information within these layers. Second, unlike humans, LLMs often struggle not only when relational information is missing, but also when attempting to apply it to new entities. In such cases, strategically patching hidden representations at critical token positions can facilitate information transfer to a certain extent. Lastly, successful analogical reasoning in LLMs is marked by strong structural alignment between analogous situations, whereas failures often reflect degraded or misplaced alignment. Overall, our findings reveal that LLMs exhibit emerging but limited capabilities in encoding and applying high-level relational concepts, highlighting both parallels and gaps with human cognition.

</details>


### [23] [BengaliFig: A Low-Resource Challenge for Figurative and Culturally Grounded Reasoning in Bengali](https://arxiv.org/abs/2511.20399)
*Abdullah Al Sefat*

Main category: cs.CL

TL;DR: 作者提出了针对孟加拉语独特谜语的评测数据集BengaliFig，详细标注、多样转化，通过八大模型实验，发现目前模型在文化及比喻推理方面表现有限，强调了对低资源语言和文化内容更精细评估的必要性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在多语种基准测试中表现优异，但在低资源语种中涉及比喻与文化相关推理的能力缺乏深入评估，尤其是在如孟加拉语这类广泛使用但资源有限的语言中。

Method: 作者构建了BengaliFig数据集，包含435道源自孟加拉口头与文学传统的谜语，沿五个维度进行详细注释，并利用AI辅助流程自动转化为选择题。同时，评估了8款主流大模型在零样本、少样本链式思维提示下的表现。

Result: 所有主流大模型在具备文化深度和比喻性的谜语推理任务上表现不佳，展现出在低资源文化背景下推理的局限性。BengaliFig作为新的诊断性资源，有助于推动更具包容性和文化敏感性的自然语言处理评价体系的发展。

Conclusion: BengaliFig提供了评估大型语言模型在孟加拉语等低资源语言中进行比喻和文化相关推理的新窗口，现有模型对此表现仍有限。

Abstract: Large language models excel on broad multilingual benchmarks but remain to be evaluated extensively in figurative and culturally grounded reasoning, especially in low-resource contexts. We present BengaliFig, a compact yet richly annotated challenge set that targets this gap in Bengali, a widely spoken low-resourced language. The dataset contains 435 unique riddles drawn from Bengali oral and literary traditions. Each item is annotated along five orthogonal dimensions capturing reasoning type, trap type, cultural depth, answer category, and difficulty, and is automatically converted to multiple-choice format through a constraint-aware, AI-assisted pipeline. We evaluate eight frontier LLMs from major providers under zero-shot and few-shot chain-of-thought prompting, revealing consistent weaknesses in metaphorical and culturally specific reasoning. BengaliFig thus contributes both a diagnostic probe for evaluating LLM robustness in low-resource cultural contexts and a step toward inclusive and heritage-aware NLP evaluation.

</details>


### [24] [A Task-Oriented Evaluation Framework for Text Normalization in Modern NLP Pipelines](https://arxiv.org/abs/2511.20409)
*Md Abdullah Al Kafi,Raka Moni,Sumit Kumar Banshal*

Main category: cs.CL

TL;DR: 文章提出了一个多维度词干化方法评估框架，利用SES、MPD、ANLD三个指标，全面考察词干技术对语义和下游任务的影响，有助于科学区分效率提升与语义损伤，实验发现Bangla词干器存在过度词干化隐患，而英文的Snowball表现更可靠。


<details>
  <summary>Details</summary>
Motivation: 当前的词干化评估方法存在局限，无法全面反映过度词干化可能带来的负面影响，因此需要新的、多维度的评估手段来科学评价词干化技术。

Method: 提出了三维评估方法，包括词干化有效性得分（SES）、下游模型性能变化（MPD）、以及词干与原词的平均标准化编辑距离（ANLD），并将该框架应用于对比分析BNLTK（孟加拉语）和Snowball（英语）两个词干提取器。

Result: BNLTK因为过度词干化虽然在SES上获得最高分，但在ANLD上表现较差，影响了下游任务表现，说明高SES并不代表高可靠性；而Snowball在词干有效性和语义保持间取得良好平衡，是更可靠的选择。

Conclusion: 本文提出的综合评估框架能够有效区分词干化方法在效率提升与语义保持之间的平衡，对于挖掘词干提取的真正价值和避免过度简化导致的语义损伤有显著意义。

Abstract: Text normalization is an essential preprocessing step in many natural language processing (NLP) tasks, and stemming is one such normalization technique that reduces words to their base or root form. However, evaluating stemming methods is challenging because current evaluation approaches are limited and do not capture the potential harm caused by excessive stemming; therefore, it is essential to develop new approaches to evaluate stemming methods. To address this issue, this study propose a novel, task-oriented approach to evaluate stemming methods, which considers three aspects: (1) the utility of stemming using Stemming Effectiveness Score (SES), (2) the impact of stemming on downstream tasks using Model Performance Delta (MPD), and (3) the semantic similarity between stemmed and original words using Average Normalized Levenshtein Distance (ANLD), thus providing a comprehensive evaluation framework. We apply our evaluation framework to compare two stemmers for Bangla (BNLTK) and English (Snowball), and our results reveal a significant issue, prompting us to analyze their performance in detail. While the Bangla stemmer achieves the highest SES (1.67) due to effective word reduction (CR = 1.90), SES alone is insufficient because our proposed safety measure, ANLD, reveals that this high SES is due to harmful over-stemming (ANLD = 0.26), which correlates with the observed decrease in downstream performance.In contrast, the English stemmer achieves a moderate SES (1.31) with a safe meaning distance (ANLD = 0.14), allowing its word reduction to contribute positively to downstream performance; therefore, it is a more reliable stemmer. Our study provides a valuable tool for distinguishing between potential efficiency gains (high SES) and meaning preservation (low ANLD).

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [25] [Using Wearable Devices to Improve Chronic PainTreatment among Patients with Opioid Use Disorder](https://arxiv.org/abs/2511.19577)
*Abhay Goyal,Navin Kumar,Kimberly DiMeola,Rafael Trujillo,Soorya Ram Shimgekar,Christian Poellabauer,Pi Zonooz,Ermonda Gjoni-Markaj,Declan Barry,Lynn Madden*

Main category: cs.AI

TL;DR: 该研究发现机器学习模型可利用可穿戴设备准确预测疼痛激增，但大型语言模型在理解疼痛激增方面表现不佳，未来需优化LLM以提升其在OUD/CP治疗中的应用价值。


<details>
  <summary>Details</summary>
Motivation: 慢性疼痛与阿片类药物使用障碍高度相关，当前针对接受MOUD治疗者的统一管理证据缺乏。可穿戴设备及人工智能有望辅助复杂临床信息筛选与早期干预。该研究试图填补LLM结合穿戴数据在疼痛激增领域的空白。

Method: 采用多种人工智能方法（如机器学习模型和大型语言模型LLM），通过可穿戴设备收集数据，预测和分析疼痛激增的临床相关因素。

Result: 机器学习模型对疼痛激增的预测准确率较高（>0.7），LLM在提供疼痛激增相关洞察方面有限。结果显示该方法有助于降低阿片复发风险、提升MOUD依从性及慢性疼痛与OUD整合治疗效果。

Conclusion: 可穿戴设备结合先进AI模型可实现疼痛激增的早期检测，有助于提升OUD/CP患者干预效果，但现有大型语言模型在该领域的表现有限。

Abstract: Chronic pain (CP) and opioid use disorder (OUD) are common and interrelated chronic medical conditions. Currently, there is a paucity of evidence-based integrated treatments for CP and OUD among individuals receiving medication for opioid use disorder (MOUD). Wearable devices have the potential to monitor complex patient information and inform treatment development for persons with OUD and CP, including pain variability (e.g., exacerbations of pain or pain spikes) and clinical correlates (e.g., perceived stress). However, the application of large language models (LLMs) with wearable data for understanding pain spikes, remains unexplored. Consequently, the aim of this pilot study was to examine the clinical correlates of pain spikes using a range of AI approaches. We found that machine learning models achieved relatively high accuracy (>0.7) in predicting pain spikes, while LLMs were limited in providing insights on pain spikes. Real-time monitoring through wearable devices, combined with advanced AI models, could facilitate early detection of pain spikes and support personalized interventions that may help mitigate the risk of opioid relapse, improve adherence to MOUD, and enhance the integration of CP and OUD care. Given overall limited LLM performance, these findings highlight the need to develop LLMs which can provide actionable insights in the OUD/CP context.

</details>


### [26] [HeaRT: A Hierarchical Circuit Reasoning Tree-Based Agentic Framework for AMS Design Optimization](https://arxiv.org/abs/2511.19669)
*Souradip Poddar,Chia-Tung Ho,Ziming Wei,Weidong Cao,Haoxing Ren,David Z. Pan*

Main category: cs.AI

TL;DR: HeaRT是一种高效、准确且能快速适应不同电路架构的自动化电路优化推理引擎，极大提升了自动化设计的泛化性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于AI的AMS（模拟混合信号）电路自动化设计算法依赖高质量数据集，难以泛化到不同架构，缺乏自适应能力，不能充分模拟人类工程师的设计推理流程。

Method: 提出了一种基础的推理引擎HeaRT，用于自动化设计流程，并通过40个电路基准库评估其在不同复杂度下的推理准确性、效率和泛化能力。

Result: HeaRT在40个电路基准测试中保持了大于97%的推理准确率和大于98%的Pass@1性能，同时收敛速度提升超过3倍，消耗的资源低于先进基线的一半，并能保持先前的设计意图。

Conclusion: HeaRT方法在电路设计自动化中表现出色，具有高推理准确率和很强的迁移能力，能有效适应不同架构并加速优化流程。

Abstract: Conventional AI-driven AMS design automation algorithms remain constrained by their reliance on high-quality datasets to capture underlying circuit behavior, coupled with poor transferability across architectures, and a lack of adaptive mechanisms. This work proposes HeaRT, a foundational reasoning engine for automation loops and a first step toward intelligent, adaptive, human-style design optimization. HeaRT consistently demonstrates reasoning accuracy >97% and Pass@1 performance >98% across our 40-circuit benchmark repository, even as circuit complexity increases, while operating at <0.5x real-time token budget of SOTA baselines. Our experiments show that HeaRT yields >3x faster convergence in both sizing and topology design adaptation tasks across diverse optimization approaches, while preserving prior design intent.

</details>


### [27] [FISCAL: Financial Synthetic Claim-document Augmented Learning for Efficient Fact-Checking](https://arxiv.org/abs/2511.19671)
*Rishab Sharma,Iman Saberi,Elham Alipour,Jie JW Wu,Fatemeh Fard*

Main category: cs.AI

TL;DR: 通过金融领域合成数据和精细微调，作者提出的轻量级模型MiniCheck-FISCAL实现了高效、准确的金融事实核查能力，可替代大型模型，相关数据和代码已开放。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在金融领域应用中存在事实幻觉和计算资源消耗大等问题，亟需提升准确性和实用性，降低模型体量。

Method: 提出FISCAL模块化框架，自动生成金融事实核查所需的合成数据集（FISCAL-data），据此训练轻量级验证模型MiniCheck-FISCAL，并与主流大模型和同级别小模型在公开金融数据集上进行对比实验。

Result: MiniCheck-FISCAL在金融数字核查任务中优于同类小模型、优于GPT-3.5 Turbo等开源模型，甚至接近体量大20倍的大模型（Mixtral-8x22B、Command R+）的精度，并在FinDVer、Fin-Fact等外部数据集上与GPT-4o、Claude-3.5表现相当，超越Gemini-1.5 Flash。FISCAL-data及代码已开源。

Conclusion: 通过结合特定领域合成数据和高效微调，小体量模型实现了与大模型媲美的金融事实核查准确性、健壮性和可扩展性。

Abstract: Financial applications of large language models (LLMs) require factual reliability and computational efficiency, yet current systems often hallucinate details and depend on prohibitively large models. We propose FISCAL (Financial Synthetic Claim-Document Augmented Learning), a modular framework for generating synthetic data tailored to financial fact-checking. Using FISCAL, we generate a dataset called FISCAL-data and use it to train MiniCheck-FISCAL, a lightweight verifier for numerical financial claims. MiniCheck-FISCAL outperforms its baseline, surpasses GPT-3.5 Turbo and other open-source peers of similar size, and approaches the accuracy of much larger systems (20x), such as Mixtral-8x22B and Command R+. On external datasets FinDVer and Fin-Fact, it rivals GPT-4o and Claude-3.5 while outperforming Gemini-1.5 Flash. These results show that domain-specific synthetic data, combined with efficient fine-tuning, enables compact models to achieve state-of-the-art accuracy, robustness, and scalability for practical financial AI. The dataset and scripts are available in the project repository (link provided in the paper).

</details>


### [28] [Scaling Item-to-Standard Alignment with Large Language Models: Accuracy, Limits, and Solutions](https://arxiv.org/abs/2511.19749)
*Farzan Karimi-Malekabadi,Pooya Razavi,Sonya Powers*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As educational systems evolve, ensuring that assessment items remain aligned with content standards is essential for maintaining fairness and instructional relevance. Traditional human alignment reviews are accurate but slow and labor-intensive, especially across large item banks. This study examines whether Large Language Models (LLMs) can accelerate this process without sacrificing accuracy. Using over 12,000 item-skill pairs in grades K-5, we tested three LLMs (GPT-3.5 Turbo, GPT-4o-mini, and GPT-4o) across three tasks that mirror real-world challenges: identifying misaligned items, selecting the correct skill from the full set of standards, and narrowing candidate lists prior to classification. In Study 1, GPT-4o-mini correctly identified alignment status in approximately 83-94% of cases, including subtle misalignments. In Study 2, performance remained strong in mathematics but was lower for reading, where standards are more semantically overlapping. Study 3 demonstrated that pre-filtering candidate skills substantially improved results, with the correct skill appearing among the top five suggestions more than 95% of the time. These findings suggest that LLMs, particularly when paired with candidate filtering strategies, can significantly reduce the manual burden of item review while preserving alignment accuracy. We recommend the development of hybrid pipelines that combine LLM-based screening with human review in ambiguous cases, offering a scalable solution for ongoing item validation and instructional alignment.

</details>


### [29] [Scaling Agentic Reinforcement Learning for Tool-Integrated Reasoning in VLMs](https://arxiv.org/abs/2511.19773)
*Meng Lu,Ran Xu,Yi Fang,Wenxuan Zhang,Yue Yu,Gaurav Srivastava,Yuchen Zhuang,Mohamed Elhoseiny,Charles Fleming,Carl Yang,Zhengzhong Tu,Yang Xie,Guanghua Xiao,Hanrui Wang,Di Jin,Wenqi Shi,Xuan Wang*

Main category: cs.AI

TL;DR: VISTA-Gym提升了VLM模型工具整合和推理能力，所训练的模型在多个基准上大幅领先同规模模型。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型虽然具备良好的图像理解，但在多步视觉推理、工具选择和协同使用方面能力有限，亟需通过系统的环境训练提升系统的Agent式推理能力。

Method: 提出VISTA-Gym训练环境，将多种真实世界的多模态推理任务和标准化的视觉工具接口整合，并设计了可执行的交互循环、可验证反馈及轨迹记录，基于这一平台通过端到端强化学习训练模型进行工具使用和Agent式推理。

Result: VISTA-Gym训练下的VISTA-R1-8B模型在11个公开的复杂推理型视觉问答基准上，性能超过同类最新模型9.51%-18.72%，彰显了该训练平台的有效性。

Conclusion: VISTA-Gym能够有效提升视觉语言模型（VLM）结合工具进行多步视觉推理的能力，并在多个基准测试中取得了显著优于同规模模型的性能。

Abstract: While recent vision-language models (VLMs) demonstrate strong image understanding, their ability to "think with images", i.e., to reason through multi-step visual interactions, remains limited. We introduce VISTA-Gym, a scalable training environment for incentivizing tool-integrated visual reasoning capabilities in VLMs. VISTA-Gym unifies diverse real-world multimodal reasoning tasks (7 tasks from 13 datasets in total) with a standardized interface for visual tools (e.g., grounding, parsing), executable interaction loops, verifiable feedback signals, and efficient trajectory logging, enabling visual agentic reinforcement learning at scale. While recent VLMs exhibit strong text-only reasoning, both proprietary and open-source models still struggle with tool selection, invocation, and coordination. With VISTA-Gym, we train VISTA-R1 to interleave tool-use with agentic reasoning via multi-turn trajectory sampling and end-to-end reinforcement learning. Extensive experiments across 11 public reasoning-intensive VQA benchmarks show that VISTA-R1-8B outperforms state-of-the-art baselines with similar sizes by 9.51%-18.72%, demonstrating VISTA-Gym as an effective training ground to unlock the tool-integrated reasoning capabilities for VLMs.

</details>


### [30] [KOM: A Multi-Agent Artificial Intelligence System for Precision Management of Knee Osteoarthritis (KOA)](https://arxiv.org/abs/2511.19798)
*Weizhi Liu,Xi Chen,Zekun Jiang,Liang Zhao,Kunyuan Jiang,Ruisi Tang,Li Wang,Mingke You,Hanyu Zhou,Hongyu Chen,Qiankun Xiong,Yong Nie,Kang Li,Jian Li*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Knee osteoarthritis (KOA) affects more than 600 million individuals globally and is associated with significant pain, functional impairment, and disability. While personalized multidisciplinary interventions have the potential to slow disease progression and enhance quality of life, they typically require substantial medical resources and expertise, making them difficult to implement in resource-limited settings. To address this challenge, we developed KOM, a multi-agent system designed to automate KOA evaluation, risk prediction, and treatment prescription. This system assists clinicians in performing essential tasks across the KOA care pathway and supports the generation of tailored management plans based on individual patient profiles, disease status, risk factors, and contraindications. In benchmark experiments, KOM demonstrated superior performance compared to several general-purpose large language models in imaging analysis and prescription generation. A randomized three-arm simulation study further revealed that collaboration between KOM and clinicians reduced total diagnostic and planning time by 38.5% and resulted in improved treatment quality compared to each approach used independently. These findings indicate that KOM could help facilitate automated KOA management and, when integrated into clinical workflows, has the potential to enhance care efficiency. The modular architecture of KOM may also offer valuable insights for developing AI-assisted management systems for other chronic conditions.

</details>


### [31] [A Unified Evaluation-Instructed Framework for Query-Dependent Prompt Optimization](https://arxiv.org/abs/2511.19829)
*Ke Chen,Yifeng Wang,Hassan Almosapeeh,Haohan Wang*

Main category: cs.AI

TL;DR: 本文提出了一套统一、可衡量的提示质量评估与优化体系，让提示生成更加稳健、可解释且适用于不同任务，显著超过了以往静态或黑盒方法。


<details>
  <summary>Details</summary>
Motivation: 现有的提示优化方法仅针对单一静态模板，难以适应复杂多变的实际场景；基于现有的查询相关方法又依赖不稳定的反馈或黑盒奖励模型，且提示质量缺乏统一、系统的定义，导致评估信号零散且不可靠。

Method: 首先构建了一个以性能为导向、系统全面的提示评估框架，然后开发并微调了一个无需执行的质量评分器，能直接从文本中预测多维质量分数。该评分器反过来指导具备指标感知能力的优化器，对不同失败模式进行诊断和解释性重写，从而实现提示的动态优化。

Result: 所开发的评估器在预测提示性能方面达到了最佳准确率，基于该评估器指导的优化方法在八个数据集和三种主流模型上，均显著优于静态模板和现有查询相关的基线方法，展现出可解释性、稳定性和模型无关性的性能提升。

Conclusion: 本文提出的评估-指引优化方法在多项基准数据集和多种模型上均取得了稳定且优于现有方法的提升效果，为提示质量问题提供了统一且具可解释性的解决方案。

Abstract: Most prompt-optimization methods refine a single static template, making them ineffective in complex and dynamic user scenarios. Existing query-dependent approaches rely on unstable textual feedback or black-box reward models, providing weak and uninterpretable optimization signals. More fundamentally, prompt quality itself lacks a unified, systematic definition, resulting in fragmented and unreliable evaluation signals. Our approach first establishes a performance-oriented, systematic, and comprehensive prompt evaluation framework. Furthermore, we develop and finetune an execution-free evaluator that predicts multi-dimensional quality scores directly from text. The evaluator then instructs a metric-aware optimizer that diagnoses failure modes and rewrites prompts in an interpretable, query-dependent manner. Our evaluator achieves the strongest accuracy in predicting prompt performance, and the evaluation-instructed optimization consistently surpass both static-template and query-dependent baselines across eight datasets and on three backbone models. Overall, we propose a unified, metric-grounded perspective on prompt quality, and demonstrated that our evaluation-instructed optimization pipeline delivers stable, interpretable, and model-agnostic improvements across diverse tasks.

</details>


### [32] [Reinforcement Learning with $ω$-Regular Objectives and Constraints](https://arxiv.org/abs/2511.19849)
*Dominik Wagner,Leon Witzman,Luke Ong*

Main category: cs.AI

TL;DR: 该论文提出结合$ω$-正则目标与显式安全约束的RL算法，在不牺牲性能的前提下显著提升了安全性，且有理论最优性保证，适用于需要平衡容错风险与优化效果的复杂任务。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）传统依赖于标量奖励，难以表达复杂的时序、条件或安全关键目标，并且容易被奖励漏洞（reward hacking）利用。虽然时序逻辑通过$ω$-正则目标能更精确地描述行为，但单一标量衡量性能还是无法揭示安全-性能权衡，尤其在容忍一定风险的应用场景中。

Method: 本文提出将$ω$-正则目标与显式约束结合，从而可将安全要求与优化目标分开处理。具体方法为：基于线性规划开发了一个模型型强化学习算法，该算法极限下能够最大化满足$ω$-正则目标的概率，同时在设定的阈值内满足$ω$-正则约束。此外，该方法还建立了到受约束的极限平均（limit-average）问题的转换，并保证最优性。

Result: 提出的算法能够在满足安全约束（$ω$-正则约束）的前提下，最大化满足复杂时序逻辑目标的概率，并通过理论结果证明了向极限平均问题的转化过程可保持最优解。

Conclusion: 通过将$ω$-正则目标与独立的安全约束结合，突破了传统RL（奖励型与满足概率型）局限，提出的基于线性规划的模型型RL方法能够提高安全性并保有目标性能，且理论上具备最优保证。

Abstract: Reinforcement learning (RL) commonly relies on scalar rewards with limited ability to express temporal, conditional, or safety-critical goals, and can lead to reward hacking. Temporal logic expressible via the more general class of $ω$-regular objectives addresses this by precisely specifying rich behavioural properties. Even still, measuring performance by a single scalar (be it reward or satisfaction probability) masks safety-performance trade-offs that arise in settings with a tolerable level of risk.
  We address both limitations simultaneously by combining $ω$-regular objectives with explicit constraints, allowing safety requirements and optimisation targets to be treated separately. We develop a model-based RL algorithm based on linear programming, which in the limit produces a policy maximising the probability of satisfying an $ω$-regular objective while also adhering to $ω$-regular constraints within specified thresholds. Furthermore, we establish a translation to constrained limit-average problems with optimality-preserving guarantees.

</details>


### [33] [MicroSims: A Framework for AI-Generated, Scalable Educational Simulations with Universal Embedding and Adaptive Learning Support](https://arxiv.org/abs/2511.19864)
*Valerie Lockhart,Dan McCreary,Troy A. Peterson*

Main category: cs.AI

TL;DR: MicroSims是一套AI辅助的轻量教育仿真框架，通过标准化设计、iframe嵌入和可修改代码，实现快速生成、易定制及兼容性强，显著提高学习成效，是促进教育公平的新工具。


<details>
  <summary>Details</summary>
Motivation: 当前教育仿真创作成本高、技术门槛高，且难以跨平台，阻碍了仿真工具的普及。作者希望通过AI辅助的轻量框架，降低定制化和分发门槛，实现教育资源的普及与公平。

Method: 提出标准化设计模式、iframe架构以及可透明修改的代码体系，综合设计原则、技术架构、元数据标准和开发流程评价MicroSims；同时借助实证数据和元分析验证其效果。

Result: MicroSims实现交互式仿真，显著提升了学生概念理解，效果较传统教学提升30%-40%；同时解决了成本、技术复杂度及平台依赖问题。

Conclusion: MicroSims能够显著提升教学效果，通过降低开发门槛和平台依赖，推动教育公平，并为未来AI驱动的自适应学习系统奠定基础。

Abstract: Educational simulations have long been recognized as powerful tools for enhancing learning outcomes, yet their creation has traditionally required substantial resources and technical expertise. This paper introduces MicroSims a novel framework for creating lightweight, interactive educational simulations that can be rapidly generated using artificial intelligence, universally embedded across digital learning platforms, and easily customized without programming knowledge. MicroSims occupy a unique position at the intersection of three key innovations: (1) standardized design patterns that enable AI-assisted generation, (2) iframe-based architecture that provides universal embedding and sandboxed security, and (3) transparent, modifiable code that supports customization and pedagogical transparency. We present a comprehensive framework encompassing design principles, technical architecture, metadata standards, and development workflows. Drawing on empirical research from physics education studies and meta-analyses across STEM disciplines, we demonstrate that interactive simulations can improve conceptual understanding by up to 30-40\% compared to traditional instruction. MicroSims extend these benefits while addressing persistent barriers of cost, technical complexity, and platform dependence. This work has significant implications for educational equity, and low-cost intelligent interactive textbooks that enabling educators worldwide to create customized, curriculum-aligned simulations on demand. We discuss implementation considerations, present evidence of effectiveness, and outline future directions for AI-powered adaptive learning systems built on the MicroSim foundation.

</details>


### [34] [Simulated Self-Assessment in Large Language Models: A Psychometric Approach to AI Self-Efficacy](https://arxiv.org/abs/2511.19872)
*Daniel I Jackson,Emma L Jensen,Syed-Amad Hussain,Emre Sezgin*

Main category: cs.AI

TL;DR: 用心理测量量表模拟LLM自我评估，发现自评结果与实际能力不一致，只能反映模型沟通风格，无法准确评估其真实表现。


<details>
  <summary>Details</summary>
Motivation: 当前对大型语言模型的评估侧重于任务准确率，缺乏对模型自我认知或自我评估能力的研究，本研究希望探究LLM自评能力的表现及其与真实性能的关系。

Method: 将10项通用自我效能感量表（GSES）改编用于提示10个大型语言模型（LLMs），在无任务、计算推理、社交推理和摘要四种场景下进行自我模拟评估，并分析多次测验、一致性和与实际任务表现的关系。

Result: GSES得分高度稳定但显著低于人类；各模型在计算与社交题目上表现完美，摘要能力差异较大。自我评估与实际能力不一致，存在轻度自我高估倾向。心理测量提示法可分析模型沟通风格但不能反推出其真实任务能力。

Conclusion: 心理测量法如自我效能感量表可用于评估LLM的沟通与自我表达行为，但这种自我评估与模型实际任务表现（尤其是总结任务）并不一致，不能作为其能力的有效校准指标。

Abstract: Self-assessment is a key aspect of reliable intelligence, yet evaluations of large language models (LLMs) focus mainly on task accuracy. We adapted the 10-item General Self-Efficacy Scale (GSES) to elicit simulated self-assessments from ten LLMs across four conditions: no task, computational reasoning, social reasoning, and summarization. GSES responses were highly stable across repeated administrations and randomized item orders. However, models showed significantly different self-efficacy levels across conditions, with aggregate scores lower than human norms. All models achieved perfect accuracy on computational and social questions, whereas summarization performance varied widely. Self-assessment did not reliably reflect ability: several low-scoring models performed accurately, while some high-scoring models produced weaker summaries. Follow-up confidence prompts yielded modest, mostly downward revisions, suggesting mild overestimation in first-pass assessments. Qualitative analysis showed that higher self-efficacy corresponded to more assertive, anthropomorphic reasoning styles, whereas lower scores reflected cautious, de-anthropomorphized explanations. Psychometric prompting provides structured insight into LLM communication behavior but not calibrated performance estimates.

</details>


### [35] [RPM-MCTS: Knowledge-Retrieval as Process Reward Model with Monte Carlo Tree Search for Code Generation](https://arxiv.org/abs/2511.19895)
*Yuanyuan Lin,Xiangyu Ouyang,Teng Zhang,Kaixin Sui*

Main category: cs.AI

TL;DR: 他们提出了一种结合知识检索奖励和树搜索的新方法RPM-MCTS，能更智能纠错、提升代码生成质量且节省资源，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有树搜索方法在中间步骤评估与错误定位修正方面存在瓶颈，导致代码生成错误率高且计算成本上升，亟需更高效的代码推理验证与纠错机制。

Method: 提出结合知识检索奖励模型与蒙特卡洛树搜索的代码生成方法（RPM-MCTS），通过知识库检索评价中间步骤，无需复杂训练奖励模型，并应用相似性过滤与沙盒执行反馈辅助纠错。

Result: 在四个代码生成公开基准上，RPM-MCTS显著优于当前先进方法，并降低约15%的token消耗，用该方法生成的数据微调基础模型大幅提升其代码能力。

Conclusion: RPM-MCTS方法有效提升了大型语言模型的代码生成质量，能够更好地纠正生成过程中的错误，且在减少计算资源消耗方面表现优异。采用该方法生成的数据用于模型全量微调也可显著增强基础模型的代码能力。

Abstract: Tree search-based methods have made significant progress in enhancing the code generation capabilities of large language models. However, due to the difficulty in effectively evaluating intermediate algorithmic steps and the inability to locate and timely correct erroneous steps, these methods often generate incorrect code and incur increased computational costs. To tackle these problems, we propose RPM-MCTS, an effective method that utilizes Knowledge-Retrieval as Process Reward Model based on Monte Carlo Tree Search to evaluate intermediate algorithmic steps. By utilizing knowledge base retrieval, RPM-MCTS avoids the complex training of process reward models. During the expansion phase, similarity filtering is employed to remove redundant nodes, ensuring diversity in reasoning paths. Furthermore, our method utilizes sandbox execution feedback to locate erroneous algorithmic steps during generation, enabling timely and targeted corrections. Extensive experiments on four public code generation benchmarks demonstrate that RPM-MCTS outperforms current state-of-the-art methods while achieving an approximately 15% reduction in token consumption. Furthermore, full fine-tuning of the base model using the data constructed by RPM-MCTS significantly enhances its code capabilities.

</details>


### [36] [Semantic-KG: Using Knowledge Graphs to Construct Benchmarks for Measuring Semantic Similarity](https://arxiv.org/abs/2511.19925)
*Qiyao Wei,Edward Morrell,Lea Goetz,Mihaela van der Schaar*

Main category: cs.AI

TL;DR: 本文提出了基于知识图谱生成多领域语义相似基准的新方法，发现不同方法在不同领域和语义变体下优劣不同，对丰富和科学评估LLM输出的语义相似性具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 现有LLM输出语义相似性测评方法存在标准构建成本高、领域覆盖有限及等价性定义不清等问题，且许多方法更偏重句法或词汇表面而非真实语义内容，对实际应用与模型评测产生局限。

Method: 利用知识图谱（KGs）自动生成语义相似或不相似的自然语言语句对，并根据不相似类别细分为4种子类型。通过这套方法，在四个领域（通识、生命医学、金融、生物）生成基准数据集，并比较不同语义相似度方法，包括传统NLP分数和大模型的判别结果。

Result: 提出了新的基准生成方法，涵盖四个领域，发现不同的语义变体子类型和领域会极大影响语义相似度评测方法的性能，没有一种方法对所有情形表现最佳。提出的多领域多样本基准为评估与改进现有方法提供了科学依据，并对大模型作为判别者的有效性进行了分析。

Conclusion: 不同语义相似度方法在不同的领域和语义变体子类型下表现不一，没有一个方法始终优于其他。当前的语义相似度评估方法尚有改进空间，尤其是在多领域应用和复杂语义变体识别方面。

Abstract: Evaluating the open-form textual responses generated by Large Language Models (LLMs) typically requires measuring the semantic similarity of the response to a (human generated) reference. However, there is evidence that current semantic similarity methods may capture syntactic or lexical forms over semantic content. While benchmarks exist for semantic equivalence, they often suffer from high generation costs due to reliance on subjective human judgment, limited availability for domain-specific applications, and unclear definitions of equivalence. This paper introduces a novel method for generating benchmarks to evaluate semantic similarity methods for LLM outputs, specifically addressing these limitations. Our approach leverages knowledge graphs (KGs) to generate pairs of natural-language statements that are semantically similar or dissimilar, with dissimilar pairs categorized into one of four sub-types. We generate benchmark datasets in four different domains (general knowledge, biomedicine, finance, biology), and conduct a comparative study of semantic similarity methods including traditional natural language processing scores and LLM-as-a-judge predictions. We observe that the sub-type of semantic variation, as well as the domain of the benchmark impact the performance of semantic similarity methods, with no method being consistently superior. Our results present important implications for the use of LLM-as-a-judge in detecting the semantic content of text. Code is available at https://github.com/QiyaoWei/semantic-kg and the dataset is available at https://huggingface.co/datasets/QiyaoWei/Semantic-KG.

</details>


### [37] [A System-Level Taxonomy of Failure Modes in Large Language Model Applications](https://arxiv.org/abs/2511.19933)
*Vaishali Vinay*

Main category: cs.AI

TL;DR: 本文系统地梳理了大语言模型在实际应用中的十五种隐藏故障模式，指出现有的评测方法难以反映其稳定性和集成挑战，强调从系统工程角度出发制定可靠性和可维护性设计原则，为未来LLM系统的评测和部署提供理论基础。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是应对当前LLM在真实生产环境中表现出的不稳定性和多样化失败方式，这些失败模式与传统机器学习模型有显著不同，现有评测体系难以覆盖。

Method: 该论文通过对多种实际应用中的隐藏故障模式进行系统性分类和分析，提出了十五种典型的LLM失败模式，并基于这些模式探讨了当前评测和监控方法的不足。

Result: 论文发现当前的评估基准重在知识与推理能力，对模型稳定性、复现性、模型漂移以及与实际工作流整合等关键问题关注有限。进一步，作者提出了若干指导性设计原则，旨在提升LLM系统的可靠性、可维护性以及与成本相关的可控性。

Conclusion: 本论文认为，LLM系统的可靠性问题需要从系统工程的角度进行重新审视和应对，并为未来LLM评测方法学、系统鲁棒性及可靠性部署研究提供了理论基础。

Abstract: Large language models (LLMs) are being rapidly integrated into decision-support tools, automation workflows, and AI-enabled software systems. However, their behavior in production environments remains poorly understood, and their failure patterns differ fundamentally from those of traditional machine learning models. This paper presents a system-level taxonomy of fifteen hidden failure modes that arise in real-world LLM applications, including multi-step reasoning drift, latent inconsistency, context-boundary degradation, incorrect tool invocation, version drift, and cost-driven performance collapse. Using this taxonomy, we analyze the growing gap in evaluation and monitoring practices: existing benchmarks measure knowledge or reasoning but provide little insight into stability, reproducibility, drift, or workflow integration. We further examine the production challenges associated with deploying LLMs - including observability limitations, cost constraints, and update-induced regressions - and outline high-level design principles for building reliable, maintainable, and cost-aware LLM systems. Finally, we outline high-level design principles for building reliable, maintainable, and cost-aware LLM-based systems. By framing LLM reliability as a system-engineering problem rather than a purely model-centric one, this work provides an analytical foundation for future research on evaluation methodology, AI system robustness, and dependable LLM deployment.

</details>


### [38] [M$^3$Prune: Hierarchical Communication Graph Pruning for Efficient Multi-Modal Multi-Agent Retrieval-Augmented Generation](https://arxiv.org/abs/2511.19969)
*Weizi Shao,Taolin Zhang,Zijie Zhou,Chen Chen,Chengyu Wang,Xiaofeng He*

Main category: cs.AI

TL;DR: M$^3$Prune 通过剪枝多智能体通信图，有效减少了 token 开销同时提升多模态任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统尽管性能优越，但通信中 token 开销大、计算成本高，影响大规模部署，亟需高效通信结构。

Method: 提出了多模态多智能体分层通信图剪枝框架，包括模态内图稀疏化和模态间动态拓扑构建，以及逐步冗余边剪枝。

Result: 在多模态检索增强生成基准测试中，M$^3$Prune 不仅提升了任务表现，还显著降低了 token 消耗。

Conclusion: M$^3$Prune 能在多模态检索增强生成任务中，在显著减少 token 开销的同时，超过单智能体和传统多智能体的表现。

Abstract: Recent advancements in multi-modal retrieval-augmented generation (mRAG), which enhance multi-modal large language models (MLLMs) with external knowledge, have demonstrated that the collective intelligence of multiple agents can significantly outperform a single model through effective communication. Despite impressive performance, existing multi-agent systems inherently incur substantial token overhead and increased computational costs, posing challenges for large-scale deployment. To address these issues, we propose a novel Multi-Modal Multi-agent hierarchical communication graph PRUNING framework, termed M$^3$Prune. Our framework eliminates redundant edges across different modalities, achieving an optimal balance between task performance and token overhead. Specifically, M$^3$Prune first applies intra-modal graph sparsification to textual and visual modalities, identifying the edges most critical for solving the task. Subsequently, we construct a dynamic communication topology using these key edges for inter-modal graph sparsification. Finally, we progressively prune redundant edges to obtain a more efficient and hierarchical topology. Extensive experiments on both general and domain-specific mRAG benchmarks demonstrate that our method consistently outperforms both single-agent and robust multi-agent mRAG systems while significantly reducing token consumption.

</details>


### [39] [VICoT-Agent: A Vision-Interleaved Chain-of-Thought Framework for Interpretable Multimodal Reasoning and Scalable Remote Sensing Analysis](https://arxiv.org/abs/2511.20085)
*Chujie Wang,Zhiyuan Luo,Ruiqi Liu,Can Ran,Shenghua Fan,Xi Chen,Chu He*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The current remote sensing image analysis task is increasingly evolving from traditional object recognition to complex intelligence reasoning, which places higher requirements on the model's reasoning ability and the flexibility of tool invocation. To this end, we propose a new multimodal agent framework, Vision-Interleaved Chain-of-Thought Framework (VICoT), which implements explicit multi-round reasoning by dynamically incorporating visual tools into the chain of thought. Through a stack-based reasoning structure and a modular MCP-compatible tool suite, VICoT enables LLMs to efficiently perform multi-round, interleaved vision-language reasoning tasks with strong generalization and flexibility.We also propose the Reasoning Stack distillation method to migrate complex Agent behaviors to small, lightweight models, which ensures the reasoning capability while significantly reducing complexity. Experiments on multiple remote sensing benchmarks demonstrate that VICoT significantly outperforms existing SOTA frameworks in reasoning transparency, execution efficiency, and generation quality.

</details>


### [40] [From data to concepts via wiring diagrams](https://arxiv.org/abs/2511.20138)
*Jason Lo,Mohammadnima Jafari*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: A wiring diagram is a labeled directed graph that represents an abstract concept such as a temporal process. In this article, we introduce the notion of a quasi-skeleton wiring diagram graph, and prove that quasi-skeleton wiring diagram graphs correspond to Hasse diagrams. Using this result, we designed algorithms that extract wiring diagrams from sequential data. We used our algorithms in analyzing the behavior of an autonomous agent playing a computer game, and the algorithms correctly identified the winning strategies. We compared the performance of our main algorithm with two other algorithms based on standard clustering techniques (DBSCAN and agglomerative hierarchical), including when some of the data was perturbed. Overall, this article brings together techniques in category theory, graph theory, clustering, reinforcement learning, and data engineering.

</details>


### [41] [Interactive AI NPCs Powered by LLMs: Technical Report for the CPDC Challenge 2025](https://arxiv.org/abs/2511.20200)
*Yitian Huang,Yuxuan Lei,Jianxun Lian,Hao Liao*

Main category: cs.AI

TL;DR: 提出集成上下文优化与强化学习训练的简单有效框架，大幅提升Persona-Grounded对话任务表现，在国际赛事中排名突出。


<details>
  <summary>Details</summary>
Motivation: 提升Persona-Grounded对话系统稳定性、执行可靠性和角色扮演感，缓解小样本过拟合，整体提升任务型对话能力。

Method: 方法包括上下文工程（动态工具剪枝、角色剪切、后处理技术如参数归一化和函数合并）、手工优化Prompt，同时在GPU赛道采用GRPO训练（基于奖励信号的强化学习，替代监督微调）。

Result: 最终团队在API任务2获得第一、API任务1第二、任务3 API与GPU赛道均获得第三，取得了优异成绩。

Conclusion: 该论文提出的方法在CPDC 2025大赛中表现优异，多个赛道获得前三名，验证了方法的有效性。

Abstract: This report presents the solution and results of our team MSRA\_SC in the Commonsense Persona-Grounded Dialogue Challenge (CPDC 2025). We propose a simple yet effective framework that unifies improvements across both GPU Track and API Track. Our method centers on two key components. First, Context Engineering applies dynamic tool pruning and persona clipping for input compression, combined with post-processing techniques such as parameter normalization and function merging. Together with manually refined prompts, this design improves tool call stability, execution reliability, and role-playing guidance. Second, in the GPU Track, we further adopt GRPO training, replacing supervised fine-tuning with reinforcement learning directly optimized by reward signals. This mitigates small-sample overfitting and significantly enhances task-oriented dialogue performance. In the final evaluation, our team ranks 1st in Task 2 API, 2nd in Task 1 API, and 3rd in both Task 3 API and GPU track, demonstrating the effectiveness of our approach. Our code is publicly available at https://gitlab.aicrowd.com/nikoo_yu/cpdc-2025-winning-solution

</details>


### [42] [CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents](https://arxiv.org/abs/2511.20216)
*Haebin Seong,Sungmin Kim,Minchan Kim,Yongjun Cho,Myunchul Joe,Suhwan Choi,Jaeyoon Jung,Jiyong Youn,Yoonshik Kim,Samwoo Seong,Yubeen Park,Youngjae Yu,Yunsung Lee*

Main category: cs.AI

TL;DR: CostNav平台首次结合经济模型评估自动导航系统，发现现有成功率高的方案不能盈利，最大成本在于碰撞维护，未来应优化碰撞规避和成本敏感的导航方法。


<details>
  <summary>Details</summary>
Motivation: 现有导航基准只注重任务完成率，忽视了自动化配送机器人商业化部署中的经济可行性；实际应用需要考虑成本与收益的平衡。

Method: 提出了CostNav微导航经济测试平台，建立了包括硬件、训练、能源、维护和服务协议下收入的完整成本-收益模型，利用行业参数进行建模，并通过缩小规模的仿真推算现实交付场景。

Result: 基线模型在服务协议（SLA）达标率为43.0％，但因碰撞维护费用占比高达99.7％，每次运行亏损$30.009，无法实现盈亏平衡，碰撞规避成为核心优化方向。

Conclusion: CostNav揭示了当前导航研究中的任务成功率与实际商业可行性之间的巨大差距，指出仅优化任务指标无法实现实际盈利，需关注经济成本，尤其是碰撞维护费用。

Abstract: Existing navigation benchmarks focus on task success metrics while overlooking economic viability -- critical for commercial deployment of autonomous delivery robots. We introduce \emph{CostNav}, a \textbf{Micro-Navigation Economic Testbed} that evaluates embodied agents through comprehensive cost-revenue analysis aligned with real-world business operations. CostNav models the complete economic lifecycle including hardware, training, energy, maintenance costs, and delivery revenue with service-level agreements, using industry-derived parameters. \textbf{To our knowledge, CostNav is the first work to quantitatively expose the gap between navigation research metrics and commercial viability}, revealing that optimizing for task success fundamentally differs from optimizing for economic deployment. Our cost model uses parameters derived from industry data sources (energy rates, delivery service pricing), and we project from a reduced-scale simulation to realistic deliveries. Under this projection, the baseline achieves 43.0\% SLA compliance but is \emph{not} commercially viable: yielding a loss of \$30.009 per run with no finite break-even point, because operating costs are dominated by collision-induced maintenance, which accounts for 99.7\% of per-run costs and highlights collision avoidance as a key optimization target. We demonstrate a learning-based on-device navigation baseline and establish a foundation for evaluating rule-based navigation, imitation learning, and cost-aware RL training. CostNav bridges the gap between navigation research and commercial deployment, enabling data-driven decisions about economic trade-offs across navigation paradigms.

</details>


### [43] [Improving Language Agents through BREW](https://arxiv.org/abs/2511.20297)
*Shashank Kirtania,Param Biyani,Priyanshu Gupta,Yasharth Bajpai,Roshni Iyer,Sumit Gulwani,Gustavo Soares*

Main category: cs.AI

TL;DR: 本文提出了BREW框架，通过将经验转化为结构化知识库替代复杂权重优化方法，实现了更高效、可解释及可控的智能体优化，验证了显著提升性能和效率。


<details>
  <summary>Details</summary>
Motivation: 当前主流PPO等权重优化方法训练开销高、收敛慢，得到的策略难以解释和增量改进，限制了LLM智能体的实际应用，亟需新的高效、可解释的优化方案。

Method: 1）设计BREW框架，将智能体的经验分区存储到结构化知识库中；2）借助任务评分器和行为规范抽取洞见；3）结合状态空间搜索优化知识获取的鲁棒性；4）在真实世界多领域基准集（OSWorld、τ^2Bench、SpreadsheetBench）进行验证。

Result: BREW在多个真实基准测试中带来10-20%任务精度提升，减少10-15%的API/工具调用和执行时长，计算效率与基础模型相当。同时，BREW支持更透明、可控和可解释的智能体行为优化。

Conclusion: 提出了BREW框架，通过构建和细化知识库以优化LLM智能体任务表现，将记忆作为可解释、透明和可控的优化“杠杆”，提升了智能体行动的可控性和可解释性。

Abstract: Large Language Model (LLM)-based agents are increasingly applied to tasks requiring structured reasoning, tool use, and environmental adaptation, such as data manipulation, multistep planning, and computer-use automation. However, despite their versatility, current training paradigms for model weight optimization methods, like PPO and GRPO, remain relatively impractical with their high computational overhead for rollout convergence. In addition, the resulting agent policies are difficult to interpret, adapt, or incrementally improve. To address this, we investigate creating and refining structured memory of experiential learning of an agent from its environment as an alternative route to agent optimization. We introduce BREW (Bootstrapping expeRientially-learned Environmental knoWledge), a framework for agent optimization for downstream tasks via KB construction and refinement. In our formulation, we introduce an effective method for partitioning agent memory for more efficient retrieval and refinement. BREW uses task graders and behavior rubrics to learn insights while leveraging state-space search for ensuring robustness from the noise and non-specificity in natural language. Empirical results on real world, domain-grounded benchmarks -- OSWorld, $τ^2$Bench, and SpreadsheetBench -- show BREW achieves $10-20\%$ improvement in task precision, $10-15\%$ reduction in API/tool calls leading to faster execution time, all while maintaining computational efficiency on par with base models. Unlike prior work where memory is treated as static context, we establish the KB as a modular and controllable substrate for agent optimization -- an explicit lever for shaping behavior in a transparent, interpretable, and extensible manner.

</details>


### [44] [Active Inference in Discrete State Spaces from First Principles](https://arxiv.org/abs/2511.20321)
*Patrick Kenny*

Main category: cs.AI

TL;DR: 本文将主动推理与自由能原理区分开来，可用平均场法实现，无预期自由能依赖，感知/行动散度准则提供更普适的建模途径。


<details>
  <summary>Details</summary>
Motivation: 澄清主动推理与自由能原理的关系，并提出一种独立于预期自由能的主动推理实现方式。

Method: 采用离散状态空间建模，将主动推理的优化问题转化为受约束的散度最小化，并以标准的平均场方法解决，无需依赖预期自由能。

Result: 在感知建模时，作者提出的感知/行动散度准则与变分自由能一致；在行动建模时，该准则与预期自由能函数不同，额外包含熵正则项。

Conclusion: 主动推理可以独立于自由能原理进行概念上的澄清，并且可通过受约束的散度最小化问题加以实现。

Abstract: We seek to clarify the concept of active inference by disentangling it from the Free Energy Principle. We show how the optimizations that need to be carried out in order to implement active inference in discrete state spaces can be formulated as constrained divergence minimization problems which can be solved by standard mean field methods that do not appeal to the idea of expected free energy. When it is used to model perception, the perception/action divergence criterion that we propose coincides with variational free energy. When it is used to model action, it differs from an expected free energy functional by an entropy regularizer.

</details>


### [45] [VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning](https://arxiv.org/abs/2511.20422)
*Bo Pang,Chenxi Xu,Jierui Ren,Guoping Wang,Sheng Li*

Main category: cs.AI

TL;DR: 作者提出VibraVerse数据集和CLASP对齐框架，将3D几何、物理属性、振动模态与声音数据物理一致地关联，提升多模态因果可解释性和任务表现，建立了新的物理一致性多模态学习基准。


<details>
  <summary>Details</summary>
Motivation: 当前多模态学习多集中于视觉与语言，缺乏物理一致性，忽略了形状、材料、振动模式与声音之间的因果物理链路。为实现对物理世界更真实、因果一致的感知与理解，需要具备严格物理一致性的多模态数据集与方法。

Method: 1. 构建VibraVerse数据库，包含3D模型的体积几何、物理属性（密度、杨氏模量、泊松比）以及通过模态分析计算的固有频率、振型和受控激发下的撞击声音。2. 提出CLASP对比学习框架，实现物理结构与声学响应的跨模态对齐，并确保样本来源物理可追溯、表征空间统一（形状、图像、声音）。3. 定义几何到声音预测、声音引导形状重建、多模态表征学习等基准任务并在其上验证方法效果。

Result: VibraVerse为多模态因果一致性学习提供了坚实数据基础，所设计框架CLASP实现跨模态物理一致对齐。大量实验验证模型在各类任务上的优越性，推动了声音引导的具身感知及物理世界理解的发展。

Conclusion: VibraVerse数据集及CLASP框架实现了3D物理结构与声学表现的物理一致、多模态因果对齐，为物理一致和因果可解释的多模态学习提供了新基准。实验结果显示所训练模型在多模态任务中表现出更高准确性、可解释性及泛化能力。

Abstract: Understanding the physical world requires perceptual models grounded in physical laws rather than mere statistical correlations. However, existing multimodal learning frameworks, focused on vision and language, lack physical consistency and overlook the intrinsic causal relationships among an object's geometry, material, vibration modes, and the sounds it produces. We introduce VibraVerse, a large-scale geometry-acoustics alignment dataset that explicitly bridges the causal chain from 3D geometry -> physical attributes -> modal parameters -> acoustic signals. Each 3D model has explicit physical properties (density, Young's modulus, Poisson's ratio) and volumetric geometry, from which modal eigenfrequencies and eigenvectors are computed for impact sound synthesis under controlled excitations. To establish this coherence, we introduce CLASP, a contrastive learning framework for cross-modal alignment that preserves the causal correspondence between an object's physical structure and its acoustic response. This framework enforces physically consistent alignment across modalities, ensuring that every sample is coherent, traceable to the governing equations, and embedded within a unified representation space spanning shape, image, and sound. Built upon VibraVerse, we define a suite of benchmark tasks for geometry-to-sound prediction, sound-guided shape reconstruction, and cross-modal representation learning. Extensive validations on these tasks demonstrate that models trained on VibraVerse exhibit superior accuracy, interpretability, and generalization across modalities. These results establish VibraVerse as a benchmark for physically consistent and causally interpretable multimodal learning, providing a foundation for sound-guided embodied perception and a deeper understanding of the physical world. The dataset will be open-sourced.

</details>
