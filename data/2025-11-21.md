<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 23]
- [cs.AI](#cs.AI) [Total: 44]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Mind the Motions: Benchmarking Theory-of-Mind in Everyday Body Language](https://arxiv.org/abs/2511.15887)
*Seungbeen Lee,Jinhong Jeong,Donghyun Kim,Yejin Son,Youngjae Yu*

Main category: cs.CL

TL;DR: 本文提出Motion2Mind框架和新数据集，用于评估AI在解释非言语线索方面的Theory of Mind能力；实验证明AI在此领域与人类存在显著差距，表现不佳且解释有过度倾向。


<details>
  <summary>Details</summary>
Motivation: 现有的Theory of Mind基准主要聚焦于信息不对称的推理与虚假信念任务，忽视了非信念类心理状态以及丰富的人类非言语交流。因此，作者希望填补这一评估空白，提高AI对更广泛心理状态及非言语交流的理解能力。

Method: 提出了Motion2Mind框架，通过建立一个涵盖222种非言语线索和397种心理状态的视频数据集，配以专家注释和心理解释，用以评估机器对非言语线索的理解能力。

Result: 实验显示，当前AI系统在非言语线索的检测与解释方面与人类注释者有很大差距，且在解释时有过度推断现象。

Conclusion: 当前的AI系统在解释非言语线索（NVC）以推断他人心理状态方面存在显著不足。AI在识别和解释NVC方面的表现远低于人类，并且在解释环节有过度推断的倾向。

Abstract: Our ability to interpret others' mental states through nonverbal cues (NVCs) is fundamental to our survival and social cohesion. While existing Theory of Mind (ToM) benchmarks have primarily focused on false-belief tasks and reasoning with asymmetric information, they overlook other mental states beyond belief and the rich tapestry of human nonverbal communication. We present Motion2Mind, a framework for evaluating the ToM capabilities of machines in interpreting NVCs. Leveraging an expert-curated body-language reference as a proxy knowledge base, we build Motion2Mind, a carefully curated video dataset with fine-grained nonverbal cue annotations paired with manually verified psychological interpretations. It encompasses 222 types of nonverbal cues and 397 mind states. Our evaluation reveals that current AI systems struggle significantly with NVC interpretation, exhibiting not only a substantial performance gap in Detection, as well as patterns of over-interpretation in Explanation compared to human annotators.

</details>


### [2] [TOD-ProcBench: Benchmarking Complex Instruction-Following in Task-Oriented Dialogues](https://arxiv.org/abs/2511.15976)
*Sarik Ghazarian,Abhinav Gullapalli,Swair Shah,Anurag Beniwal,Nanyun Peng,Narayanan Sadagopan,Zhou Yu*

Main category: cs.CL

TL;DR: 本文提出TOD-ProcBench基准，填补了对话系统遵循复杂自然语言流程指令评测的空白，设计了三项系统任务，数据和基准已对外发布，适用于LLM能力系统评测。


<details>
  <summary>Details</summary>
Motivation: 现有对话系统评测基准过于简化，将复杂自然语言指令转化为简单意图和槽位，无法真实反映系统在复杂任务中的表现，故提出新基准以推动大模型遵循指令能力的研发和评测。

Method: 作者基于高质量ABCD数据集，设计了包含复杂约束和细粒度动作流程的指令文档及对应对话，构建了三项任务：相关指令检索与动作预测、违规响应识别、条件响应生成。此外，论文研究了多语言设置和不同指令格式对模型表现的影响。

Result: TOD-ProcBench能有效区分不同LLM对复杂过程及约束理解和遵循能力的差异，且多语言和指令表述方式对模型表现有显著影响。作者公开了基准数据集。

Conclusion: 论文提出了TOD-ProcBench基准，对大语言模型在多轮对话中遵循复杂过程型自然语言指令的能力进行了系统性评测，其多层次任务有效揭示了模型在推理、检索、响应生成等方面的表现。

Abstract: In real-world task-oriented dialogue (TOD) settings, agents are required to strictly adhere to complex instructions while conducting multi-turn conversations with customers. These instructions are typically presented in natural language format and include general guidelines and step-by-step procedures with complex constraints. Existing TOD benchmarks often oversimplify the complex nature of these instructions by reducing them to simple schemas composed of intents, slots, and API call configurations. To address this gap and systematically benchmark LLMs' instruction-following capabilities, we propose TOD-ProcBench, a challenging benchmark featuring complex process instructions with intricate, fine-grained constraints that evaluates various LLMs' abilities to understand and follow instructions in multi-turn TODs. Our benchmark dataset comprises instruction documents derived from the high-quality ABCD dataset with corresponding conversations under human quality control. We formulate fine-grained constraints and action procedures as multi-level condition-action instruction statements. We design three tasks to comprehensively benchmark LLMs' complex instruction-following capabilities in multi-turn TODs. Task 1 evaluates how LLMs retrieve the most relevant statement from a complex instruction and predict the corresponding next action. In Task 2, we synthesize instruction-violating responses by injecting inconsistencies and manipulating the original instructions, and then we analyze how effectively LLMs can identify instruction-violating responses. Task 3 investigates LLMs' abilities in conditional generation of instruction-following responses based on the original complex instructions. Additionally, we conduct studies on the impact of multilingual settings and different instruction text formats on compliance performance. We release our benchmark under the Llama 3.3 Community License Agreement.

</details>


### [3] [Liars' Bench: Evaluating Lie Detectors for Language Models](https://arxiv.org/abs/2511.16035)
*Kieron Kretschmar,Walter Laurito,Sharan Maiya,Samuel Marks*

Main category: cs.CL

TL;DR: 本文提出LIARS' BENCH数据集，评估当前谎言检测方法，发现其在多样化谎言情境下存在显著不足，平台可作为推动技术改进的基准测试工具。


<details>
  <summary>Details</summary>
Motivation: 现有谎言检测方法验证场景过于单一，无法全面覆盖LLM实际生成的多样化谎言，为更全面客观评估谎言检测技术，需要构建多类型谎言的测试基准。

Method: 提出了LIARS' BENCH测试平台，收集并生成了72,863个来自四个开源模型在七个数据集上的谎言与诚实回答样本。作者根据模型说谎的动因和所针对的信念对象对谎言类型进行分类评价，并在该平台上对三种黑盒与白盒谎言检测方法进行系统性评估。

Result: 实验表明，现有谎言检测方法在某些谎言类型上表现不佳，LIARS' BENCH平台揭示了这些技术的局限性，并为未来谎言检测发展提供了实用的测试工具。

Conclusion: 现有大型语言模型（LLM）谎言检测技术在复杂多样的谎言场景中存在明显局限性，尤其是难以识别那些无法仅通过文本判断是否说谎的情形。LIARS' BENCH为相关研究领域提供了重要的测试基准，可推动谎言检测技术的进步。

Abstract: Prior work has introduced techniques for detecting when large language models (LLMs) lie, that is, generating statements they believe are false. However, these techniques are typically validated in narrow settings that do not capture the diverse lies LLMs can generate. We introduce LIARS' BENCH, a testbed consisting of 72,863 examples of lies and honest responses generated by four open-weight models across seven datasets. Our settings capture qualitatively different types of lies and vary along two dimensions: the model's reason for lying and the object of belief targeted by the lie. Evaluating three black- and white-box lie detection techniques on LIARS' BENCH, we find that existing techniques systematically fail to identify certain types of lies, especially in settings where it's not possible to determine whether the model lied from the transcript alone. Overall, LIARS' BENCH reveals limitations in prior techniques and provides a practical testbed for guiding progress in lie detection.

</details>


### [4] [Learning Tractable Distributions Of Language Model Continuations](https://arxiv.org/abs/2511.16054)
*Gwen Yidou-Weng,Ian Li,Anji Liu,Oliver Broadrick,Guy Van den Broeck,Benjie Wang*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Controlled language generation conditions text on sequence-level constraints (for example, syntax, style, or safety). These constraints may depend on future tokens, which makes directly conditioning an autoregressive language model (LM) generally intractable. Prior work uses tractable surrogates such as hidden Markov models (HMMs) to approximate the distribution over continuations and adjust the model's next-token logits at decoding time. However, we find that these surrogates are often weakly context aware, which reduces query quality. We propose Learning to Look Ahead (LTLA), a hybrid approach that pairs the same base language model for rich prefix encoding with a fixed tractable surrogate model that computes exact continuation probabilities. Two efficiency pitfalls arise when adding neural context: (i) naively rescoring the prefix with every candidate next token requires a sweep over the entire vocabulary at each step, and (ii) predicting fresh surrogate parameters for each prefix, although tractable at a single step, forces recomputation of future probabilities for every new prefix and eliminates reuse. LTLA avoids both by using a single batched HMM update to account for all next-token candidates at once, and by conditioning only the surrogate's latent state prior on the LM's hidden representations while keeping the surrogate decoder fixed, so computations can be reused across prefixes. Empirically, LTLA attains higher conditional likelihood than an unconditional HMM, approximates continuation distributions for vision-language models where a standalone HMM cannot encode visual context, and improves constraint satisfaction at comparable fluency on controlled-generation tasks, with minimal inference overhead.

</details>


### [5] [Early science acceleration experiments with GPT-5](https://arxiv.org/abs/2511.16072)
*Sébastien Bubeck,Christian Coester,Ronen Eldan,Timothy Gowers,Yin Tat Lee,Alexandru Lupsasca,Mehtaab Sawhney,Robert Scherrer,Mark Sellke,Brian K. Spears,Derya Unutmaz,Kevin Weil,Steven Yin,Nikita Zhivotovskiy*

Main category: cs.CL

TL;DR: GPT-5助力多领域科研、突破部分数学难题，展示AI与科学家协作的潜力，未来影响深远但仍有局限。


<details>
  <summary>Details</summary>
Motivation: 推动科学家认知和利用前沿AI工具（如GPT-5）的能力，展示AI在科研实际应用中的价值与局限。

Method: 论文通过收集并分析不同学科作者与GPT-5合作的真实案例研究，记录交互过程和结果，并重点验证其中数学领域的新成果。

Result: GPT-5推动了多学科研究，包括产出四项经过专家验证的数学新成果；AI合作节省了专家时间，但人类判断依然不可替代。

Conclusion: GPT-5能够在多个科学领域内促成创新研究步骤，实际加速科学研究进程，但仍需人类专家的关键判断和协作。

Abstract: AI models like GPT-5 are an increasingly valuable tool for scientists, but many remain unaware of the capabilities of frontier AI. We present a collection of short case studies in which GPT-5 produced new, concrete steps in ongoing research across mathematics, physics, astronomy, computer science, biology, and materials science. In these examples, the authors highlight how AI accelerated their work, and where it fell short; where expert time was saved, and where human input was still key. We document the interactions of the human authors with GPT-5, as guiding examples of fruitful collaboration with AI. Of note, this paper includes four new results in mathematics (carefully verified by the human authors), underscoring how GPT-5 can help human mathematicians settle previously unsolved problems. These contributions are modest in scope but profound in implication, given the rate at which frontier AI is progressing.

</details>


### [6] [ELPO: Ensemble Learning Based Prompt Optimization for Large Language Models](https://arxiv.org/abs/2511.16122)
*Qing Zhang,Bing Xu,Xudong Zhang,Yifan Shi,Yang Li,Chen Zhang,Yik Chung Wu,Ngai Wong,Yijie Chen,Hong Dai,Xiansen Chen,Mian Zhang*

Main category: cs.CL

TL;DR: 本文提出ELPO框架，以集成学习方式实现自动提示词优化，显著提升大模型在复杂任务上的表现，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 针对当前自动提示词优化方法受限于单一模型或算法，难以应对复杂任务，人工设计提示词耗时费力的问题，提出更具通用性和高效性的优化策略。

Method: 通过集成学习思想，采用投票机制并引入多样化的生成和搜索策略，提升提示词优化的准确性和鲁棒性，同时提出高效的提示词生成与搜索算法。

Result: ELPO在包括ArSarcasm等不同任务上均超越最新方法，提升了结果准确率。例如在ArSarcasm数据集上F1分数提高7.6。

Conclusion: 提出了一种基于集成学习的新型自动提示词优化框架ELPO，相较于现有方法在多项任务上取得了更优性能。

Abstract: The remarkable performance of Large Language Models (LLMs) highly relies on crafted prompts. However, manual prompt engineering is a laborious process, creating a core bottleneck for practical application of LLMs. This phenomenon has led to the emergence of a new research area known as Automatic Prompt Optimization (APO), which develops rapidly in recent years. Existing APO methods such as those based on evolutionary algorithms or trial-and-error approaches realize an efficient and accurate prompt optimization to some extent. However, those researches focus on a single model or algorithm for the generation strategy and optimization process, which limits their performance when handling complex tasks. To address this, we propose a novel framework called Ensemble Learning based Prompt Optimization (ELPO) to achieve more accurate and robust results. Motivated by the idea of ensemble learning, ELPO conducts voting mechanism and introduces shared generation strategies along with different search methods for searching superior prompts. Moreover, ELPO creatively presents more efficient algorithms for the prompt generation and search process. Experimental results demonstrate that ELPO outperforms state-of-the-art prompt optimization methods across different tasks, e.g., improving F1 score by 7.6 on ArSarcasm dataset.

</details>


### [7] [TS-PEFT: Token-Selective Parameter-Efficient Fine-Tuning with Learnable Threshold Gating](https://arxiv.org/abs/2511.16147)
*Dabiao Ma,Ziming Dai,Zhimin Xin,Shu Wang,Ye Wang,Haojun Fei*

Main category: cs.CL

TL;DR: 论文提出Token-Selective PEFT，只对部分位置索引进行参数高效微调，相较于传统对全部位置修改的方法，该方式更高效且性能更优，为未来大模型微调优化提供新思路。


<details>
  <summary>Details</summary>
Motivation: 传统PEFT方法默认对所有位置索引微调参数，但并未考察这种做法的必要性。作者拟探索是否对所有位置都进行微调是最优策略，并尝试提出更高效的替代方法。

Method: 提出了一种新范式Token-Selective PEFT（TS-PEFT），该方法通过函数S，仅对部分位置索引实施PEFT修改，并进行实验对比全量PEFT与选择性PEFT的效果。

Result: 实验表明，有选择性地进行PEFT能够带来更优甚至更稳定的下游任务表现，而全索引应用PEFT可导致性能下降。

Conclusion: 论文得出结论：在参数高效微调（PEFT）中，不必对所有位置索引都进行参数修改，有选择性地对部分位置施加微调反而效果更佳。无差别应用PEFT不仅不必要，甚至可能适得其反。

Abstract: In the field of large models (LMs) for natural language processing (NLP) and computer vision (CV), Parameter-Efficient Fine-Tuning (PEFT) has emerged as a resource-efficient method that modifies a limited number of parameters while keeping the pretrained weights fixed. This paper investigates the traditional PEFT approach, which applies modifications to all position indices, and questions its necessity. We introduce a new paradigm called Token-Selective PEFT (TS-PEFT), in which a function S selectively applies PEFT modifications to a subset of position indices, potentially enhancing performance on downstream tasks. Our experimental results reveal that the indiscriminate application of PEFT to all indices is not only superfluous, but may also be counterproductive. This study offers a fresh perspective on PEFT, advocating for a more targeted approach to modifications and providing a framework for future research to optimize the fine-tuning process for large models.

</details>


### [8] [SemanticCite: Citation Verification with AI-Powered Full-Text Analysis and Evidence-Based Reasoning](https://arxiv.org/abs/2511.16198)
*Sebastian Haan*

Main category: cs.CL

TL;DR: SemanticCite是一套开源AI引文验证系统，可细致分析引文与原文关系，自动判别支持程度并提供证据片段，用低算力实现高准确性，大幅提升科研引用质量和透明度。


<details>
  <summary>Details</summary>
Motivation: 学术引文存在语义错误、AI生成幻觉引用及无法细粒度验证的传统格式，导致科研交流和证据链弱化，亟需高效、可扩展、自动化的引文准确性验证系统。

Method: 系统结合多种检索方法和四分类（Supported, Partially Supported, Unsupported, Uncertain）AI模型，对引文和源文献进行全文语义分析和详细推理，并返回相关文本片段作为证据。通过对轻量化语言模型进行微调，兼顾性能与计算资源消耗。构建了包含详细对齐关系和语义标注的千余条引文数据集，用于训练和评估。

Result: 轻量化微调模型达到了与大型商用系统相当的验证能力，但计算资源显著减少；系统能高效、规模化地辅助同行评审、AI内容质量控制，并提升用户理解与信任。公开数据集、微调模型与完整框架软件。

Conclusion: SemanticCite显著提升了学术文献引证的准确性和透明度，为科研诚信和高质量AI生成内容的审查与控制提供了有力保障。

Abstract: Effective scientific communication depends on accurate citations that validate sources and guide readers to supporting evidence. Yet academic literature faces mounting challenges: semantic citation errors that misrepresent sources, AI-generated hallucinated references, and traditional citation formats that point to entire papers without indicating which sections substantiate specific claims. We introduce SemanticCite, an AI-powered system that verifies citation accuracy through full-text source analysis while providing rich contextual information via detailed reasoning and relevant text snippets. Our approach combines multiple retrieval methods with a four-class classification system (Supported, Partially Supported, Unsupported, Uncertain) that captures nuanced claim-source relationships and enables appropriate remedial actions for different error types. Our experiments show that fine-tuned lightweight language models achieve performance comparable to large commercial systems with significantly lower computational requirements, making large-scale citation verification practically feasible. The system provides transparent, evidence-based explanations that support user understanding and trust. We contribute a comprehensive dataset of over 1,000 citations with detailed alignments, functional classifications, semantic annotations, and bibliometric metadata across eight disciplines, alongside fine-tuned models and the complete verification framework as open-source software. SemanticCite addresses critical challenges in research integrity through scalable citation verification, streamlined peer review, and quality control for AI-generated content, providing an open-source foundation for maintaining citation accuracy at scale.

</details>


### [9] [SeSE: A Structural Information-Guided Uncertainty Quantification Framework for Hallucination Detection in LLMs](https://arxiv.org/abs/2511.16275)
*Xingtao Zhao,Hao Peng,Dingli Su,Xianghua Zeng,Chunyang Liu,Jinzhi Liao,Philip S. Yu*

Main category: cs.CL

TL;DR: SeSE利用语义结构信息定量衡量大语言模型不确定性，在安全场景下有效预防幻觉生成，实验优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性量化方法忽略了语义潜在结构信息，导致在幻觉检测和模型自我约束方面精度不足，因此亟需更精细、可解释的UQ方法以提升安全性。

Method: 提出语义结构熵（SeSE）框架，通过自适应稀疏化的有向语义图建模语义空间结构，并通过分层抽象，定义语义编码树的结构熵来度量语言模型的固有不确定性。

Result: SeSE在29组模型-数据集组合上的实验表现均优于当前高级UQ方法，包括强监督和新近KLE基线，在幻觉检测和细粒度不确定性量化方面效果突出。

Conclusion: SeSE能够显著提升大语言模型在安全关键场景下的不确定性量化表现，有效检测并减少幻觉生成问题，优于现有先进基线方法。

Abstract: Reliable uncertainty quantification (UQ) is essential for deploying large language models (LLMs) in safety-critical scenarios, as it enables them to abstain from responding when uncertain, thereby avoiding hallucinating falsehoods. However, state-of-the-art UQ methods primarily rely on semantic probability distributions or pairwise distances, overlooking latent semantic structural information that could enable more precise uncertainty estimates. This paper presents Semantic Structural Entropy (SeSE), a principled UQ framework that quantifies the inherent semantic uncertainty of LLMs from a structural information perspective for hallucination detection. Specifically, to effectively model semantic spaces, we first develop an adaptively sparsified directed semantic graph construction algorithm that captures directional semantic dependencies while automatically pruning unnecessary connections that introduce negative interference. We then exploit latent semantic structural information through hierarchical abstraction: SeSE is defined as the structural entropy of the optimal semantic encoding tree, formalizing intrinsic uncertainty within semantic spaces after optimal compression. A higher SeSE value corresponds to greater uncertainty, indicating that LLMs are highly likely to generate hallucinations. In addition, to enhance fine-grained UQ in long-form generation -- where existing methods often rely on heuristic sample-and-count techniques -- we extend SeSE to quantify the uncertainty of individual claims by modeling their random semantic interactions, providing theoretically explicable hallucination detection. Extensive experiments across 29 model-dataset combinations show that SeSE significantly outperforms advanced UQ baselines, including strong supervised methods and the recently proposed KLE.

</details>


### [10] [SDA: Steering-Driven Distribution Alignment for Open LLMs without Fine-Tuning](https://arxiv.org/abs/2511.16324)
*Wei Xia,Zhi-Hong Deng*

Main category: cs.CL

TL;DR: 该文提出免训练的SDA对齐技术，通过调整输出概率显著提升开源LLM的三维对齐表现，具备高效、灵活、个性化优势并已在多个模型上取得良好结果。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在实际应用需对齐人类意图，传统方法成本高、不灵活，亟需一种高效、低成本、可扩展的推理期对齐方案。

Method: 提出了一种训练无关、模型无关的对齐机制SDA，在推理阶段动态调整模型输出概率，基于用户自定义指令实现行为对齐，无需微调，可与训练期对齐技术结合使用，并支持个性化偏好设置。

Result: 在8个不同开源LLM上实证，SDA在helpfulness、honesty、harmlessness三维度分别平均提升64.4%、30%、11.5%，验证了其通用性和显著效果。

Conclusion: SDA方法有效提升了开源大模型在推理阶段的输出与人类意图的对齐度，无需重新训练且具备良好的通用性与扩展性。

Abstract: With the rapid advancement of large language models (LLMs), their deployment in real-world applications has become increasingly widespread. LLMs are expected to deliver robust performance across diverse tasks, user preferences, and practical scenarios. However, as demands grow, ensuring that LLMs produce responses aligned with human intent remains a foundational challenge. In particular, aligning model behavior effectively and efficiently during inference, without costly retraining or extensive supervision, is both a critical requirement and a non-trivial technical endeavor. To address the challenge, we propose SDA (Steering-Driven Distribution Alignment), a training-free and model-agnostic alignment framework designed for open-source LLMs. SDA dynamically redistributes model output probabilities based on user-defined alignment instructions, enhancing alignment between model behavior and human intents without fine-tuning. The method is lightweight, resource-efficient, and compatible with a wide range of open-source LLMs. It can function independently during inference or be integrated with training-based alignment strategies. Moreover, SDA supports personalized preference alignment, enabling flexible control over the model response behavior. Empirical results demonstrate that SDA consistently improves alignment performance across 8 open-source LLMs with varying scales and diverse origins, evaluated on three key alignment dimensions, helpfulness, harmlessness, and honesty (3H). Specifically, SDA achieves average gains of 64.4% in helpfulness, 30% in honesty and 11.5% in harmlessness across the tested models, indicating its effectiveness and generalization across diverse models and application scenarios.

</details>


### [11] [Incorporating Self-Rewriting into Large Language Model Reasoning Reinforcement](https://arxiv.org/abs/2511.16331)
*Jiashu Yao,Heyan Huang,Shuang Zeng,Chuwei Luo,WangJie You,Jie Tang,Qingsong Liu,Yuhang Guo,Yangyang Kang*

Main category: cs.CL

TL;DR: 本文提出自我重写框架，通过模型自身推理文本重写提升内部推理质量与准确率，减少推理冗余，在多项任务和评测中优于现有强基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法仅用最终正确性作为奖励，忽略了对模型内部推理过程的细致监督，导致如过度推理、推理不足、冗余和混乱等问题，亟需提升内部思考质量。

Method: 提出自我重写（self-rewriting）框架，模型对其自身推理文本进行重写学习，通过选择性重写仅对‘简单’样本应用该机制，且在算法上批处理中合并重写与常规生成，控制计算开销在10%左右。

Result: 自我重写方法在各种任务和模型规模下均可提升准确率（提升0.6），明显缩短推理长度（减少46%），在LLM评判指标下，内部推理质量分显著提升（+7.2），有效缓解推理缺陷。

Conclusion: 自我重写方法在提升推理模型内部推理质量和准确率、减少冗余推理方面效果显著，优于现有主流方法。

Abstract: Through reinforcement learning (RL) with outcome correctness rewards, large reasoning models (LRMs) with scaled inference computation have demonstrated substantial success on complex reasoning tasks. However, the one-sided reward, focused solely on final correctness, limits its ability to provide detailed supervision over internal reasoning process. This deficiency leads to suboptimal internal reasoning quality, manifesting as issues like over-thinking, under-thinking, redundant-thinking, and disordered-thinking. Inspired by the recent progress in LRM self-rewarding, we introduce self-rewriting framework, where a model rewrites its own reasoning texts, and subsequently learns from the rewritten reasoning to improve the internal thought process quality. For algorithm design, we propose a selective rewriting approach wherein only "simple" samples, defined by the model's consistent correctness, are rewritten, thereby preserving all original reward signals of GRPO. For practical implementation, we compile rewriting and vanilla generation within one single batch, maintaining the scalability of the RL algorithm and introducing only ~10% overhead. Extensive experiments on diverse tasks with different model sizes validate the effectiveness of self-rewriting. In terms of the accuracy-length tradeoff, the self-rewriting approach achieves improved accuracy (+0.6) with substantially shorter reasoning (-46%) even without explicit instructions in rewriting prompts to reduce reasoning length, outperforming existing strong baselines. In terms of internal reasoning quality, self-rewriting achieves significantly higher scores (+7.2) under the LLM-as-a-judge metric, successfully mitigating internal reasoning flaws.

</details>


### [12] [NLP Datasets for Idiom and Figurative Language Tasks](https://arxiv.org/abs/2511.16345)
*Blake Matheny,Phuong Minh Nguyen,Minh Le Nguyen,Stephanie Reynolds*

Main category: cs.CL

TL;DR: 本文提出并公开了一套大规模习语及比喻性语言数据集，经实验验证对提升大模型理解和检测习语能力有显著帮助，丰富了相关NLP研究资源。


<details>
  <summary>Details</summary>
Motivation: 由于习语和比喻性语言对于LLMs来说仍较难理解，且现有微调方法虽有效但优质数据资源有限，因此需要构建更多类型丰富且质量优良的新数据集，强化LLMs对此类现象的建模能力。

Method: 作者整合了最新的习语和比喻性语言数据集，抽取习语列表并从大语料库检索上下文序列，最终创建了一个大规模候选习语数据集及两个由人工标注的确定习语数据集，并在预训练语言模型上进行了槽位标注与序列标注实验评测。

Result: 获得了一个用于候选习语和比喻性表达的大规模数据集，以及两个高质量人工标注数据集，实验评估显示数据集对于提升预训练语言模型习语识别能力有效。

Conclusion: 本论文构建的大规模习语和比喻性语言数据集能够有效提升LLMs在处理习语识别任务上的表现，为NLP领域相关问题提供了新的数据支持和研究基础。

Abstract: Idiomatic and figurative language form a large portion of colloquial speech and writing. With social media, this informal language has become more easily observable to people and trainers of large language models (LLMs) alike. While the advantage of large corpora seems like the solution to all machine learning and Natural Language Processing (NLP) problems, idioms and figurative language continue to elude LLMs. Finetuning approaches are proving to be optimal, but better and larger datasets can help narrow this gap even further. The datasets presented in this paper provide one answer, while offering a diverse set of categories on which to build new models and develop new approaches. A selection of recent idiom and figurative language datasets were used to acquire a combined idiom list, which was used to retrieve context sequences from a large corpus. One large-scale dataset of potential idiomatic and figurative language expressions and two additional human-annotated datasets of definite idiomatic and figurative language expressions were created to evaluate the baseline ability of pre-trained language models in handling figurative meaning through idiom recognition (detection) tasks. The resulting datasets were post-processed for model agnostic training compatibility, utilized in training, and evaluated on slot labeling and sequence tagging.

</details>


### [13] [Learning from Sufficient Rationales: Analysing the Relationship Between Explanation Faithfulness and Token-level Regularisation Strategies](https://arxiv.org/abs/2511.16353)
*Jonathan Kamp,Lisa Beinborn,Antske Fokkens*

Main category: cs.CL

TL;DR: 总结性指标难以全面评估rationale价值，本研究以两种建模方式探究其复杂影响，发现人类解释对模型提升效果有限且涉及多维度互动，评价方法亟需升级。


<details>
  <summary>Details</summary>
Motivation: 目前常用的rationale充分性指标只能粗略估算解释信息价值，难以深度理解其如何影响模型表现，因此试图揭示rationale信息在不同建模方式下的具体作用和潜在复杂性。

Method: 通过将rationale的充分性与两种建模范式关联：合理token的识别（token classification）和将rationale信息融入输入以正则化注意力（attention regularisation），进而分析它们对模型性能的影响。

Result: 高度信息化的rationale不一定提升分类正确性，充分性反而反映非rationale上下文的影响，且token分类与充分性指标无关。加入rationale信息能提升部分场景的跨领域准确率，但结果不一致。

Conclusion: 高度信息性的人类解释（rationale）未必有助于模型正确分类实例。将解释信息加入模型输入可提升跨领域分类能力，但在不同任务和模型类型中结果并不一致。总结性和标记分类能力之间并无关联，显示出人类解释在模型中的复杂性，现有评价指标需进一步研究。

Abstract: Human explanations of natural language, rationales, form a tool to assess whether models learn a label for the right reasons or rely on dataset-specific shortcuts. Sufficiency is a common metric for estimating the informativeness of rationales, but it provides limited insight into the effects of rationale information on model performance. We address this limitation by relating sufficiency to two modelling paradigms: the ability of models to identify which tokens are part of the rationale (through token classification) and the ability of improving model performance by incorporating rationales in the input (through attention regularisation). We find that highly informative rationales are not likely to help classify the instance correctly. Sufficiency conversely captures the classification impact of the non-rationalised context, which interferes with rationale information in the same input. We also find that incorporating rationale information in model inputs can boost cross-domain classification, but results are inconsistent per task and model type. Finally, sufficiency and token classification appear to be unrelated. These results exemplify the complexity of rationales, showing that metrics capable of systematically capturing this type of information merit further investigation.

</details>


### [14] [AICC: Parse HTML Finer, Make Models Better -- A 7.3T AI-Ready Corpus Built by a Model-Based HTML Parser](https://arxiv.org/abs/2511.16397)
*Ren Ma,Jiantao Qiu,Chao Xu,Pei Chu,Kaiwen Liu,Pengli Ren,Yuan Qu,Jiahui Peng,Linfeng Hou,Mengjie Liu,Lindong Lu,Wenchang Ning,Jia Yu,Rui Min,Jin Shi,Haojiong Chen,Peng Zhang,Wenjian Zhang,Qian Jiang,Zengjie Hu,Guoqiang Yang,Zhenxiang Li,Fukai Shang,Zhongying Tu,Wentao Zhang,Dahua Lin,Conghui He*

Main category: cs.CL

TL;DR: 提出将HTML内容抽取建模为语义序列标注任务，并用专用语言模型实现大幅提升，对结构化信息保留效果远超传统方法。打造高质量多语言语料库AICC，并通过大模型下游任务实验，直接证明抽取质量对建模性能影响极大。相关工具和基准均已公开，强调HTML语义抽取在网页语料构建中的关键性。


<details>
  <summary>Details</summary>
Motivation: 现有网页语料库的HTML到文本转换主要依赖启发式方法，导致结构元素（如公式、代码、表格）损坏严重，影响语料质量。作者认为提取质量提升可以和过滤策略一样大幅提升下游模型能力，因此提出新的语义驱动提取方案。

Method: 将HTML内容提取问题重新表述为序列标注任务，使用0.6B参数的语言模型进行语义分类，并采用两阶段格式化管道将内容转化为Markdown。与传统的文本密度启发式方法相比，更侧重语义理解和结构元素显式分类。

Result: 在MainWebBench基准测试中，新方法MinerU-HTML的ROUGE-N F1分数达到81.8%，显著优于Trafilatura（63.6%）；结构元素保留率高（代码块90.9%、公式94.0%）。新建7.3万亿Token的多语种高质量语料库AICC，预训练实验表明AICC语料训练的模型平均准确率高于传统文本抽取方式，且超过RefinedWeb与FineWeb等关键基准。

Conclusion: HTML内容提取质量对大规模语言模型下游任务表现有显著影响，矿工式语义标注方法优化后的提取管道可以远超现有基于启发式方法的系统。

Abstract: While web data quality is crucial for large language models, most curation efforts focus on filtering and deduplication,treating HTML-to-text extraction as a fixed pre-processing step. Existing web corpora rely on heuristic-based extractors like Trafilatura, which struggle to preserve document structure and frequently corrupt structured elements such as formulas, codes, and tables. We hypothesize that improving extraction quality can be as impactful as aggressive filtering strategies for downstream performance. We introduce MinerU-HTML, a novel extraction pipeline that reformulates content extraction as a sequence labeling problem solved by a 0.6B-parameter language model. Unlike text-density heuristics, MinerU-HTML leverages semantic understanding and employs a two-stage formatting pipeline that explicitly categorizes semantic elements before converting to Markdown. Crucially, its model-based approach is inherently scalable, whereas heuristic methods offer limited improvement pathways. On MainWebBench, our benchmark of 7,887 annotated web pages, MinerU-HTML achieves 81.8\% ROUGE-N F1 compared to Trafilatura's 63.6\%, with exceptional structured element preservation (90.9\% for code blocks, 94.0\% for formulas). Using MinerU-HTML, we construct AICC (AI-ready Common Crawl), a 7.3-trillion token multilingual corpus from two Common Crawl snapshots. In controlled pretraining experiments where AICC and Trafilatura-extracted TfCC undergo identical filtering, models trained on AICC (62B tokens) achieve 50.8\% average accuracy across 13 benchmarks, outperforming TfCC by 1.08pp-providing direct evidence that extraction quality significantly impacts model capabilities. AICC also surpasses RefinedWeb and FineWeb on key benchmarks. We publicly release MainWebBench, MinerU-HTML, and AICC, demonstrating that HTML extraction is a critical, often underestimated component of web corpus construction.

</details>


### [15] [Classification of worldwide news articles by perceived quality, 2018-2024](https://arxiv.org/abs/2511.16416)
*Connor McElroy,Thiago E. A. de Oliveira,Chris Brogly*

Main category: cs.CL

TL;DR: 本研究利用140万余篇新闻与专家评级，用机器学习与深度学习模型辨别新闻质量。深度学习模型准确率及ROC AUC显著领先，表明这些方法能够有效区分高低质量新闻。


<details>
  <summary>Details</summary>
Motivation: 新闻信息质量对读者影响极大，推动开发自动化工具以有效区分高低质量新闻文章。当前关于用机器学习区分新闻质量的研究有限，作者希望通过大规模数据和先进模型检验区分能力。

Method: 作者整理了2018-2024年Common Crawl的数据集，包含1,412,272篇英文新闻。根据专家评分把来源网站分成高低质量两类，利用194种语言特征对每篇文章进行标注，并采用三种传统机器学习模型（如随机森林）和三种深度学习模型（如ModernBERT、DistilBERT）进行分类实验。

Result: 传统机器学习分类器如随机森林取得了0.7355准确率和0.8131 ROC AUC。深度学习模型表现更佳，ModernBERT-large在256上下文长度下达到0.8744准确率和0.9593 ROC AUC，F1值也很高。DistilBERT-base和ModernBERT-base等其他变体也取得了0.85以上准确率，均优于传统方法。

Conclusion: 文章得出结论，新闻文章的主观质量可以通过传统机器学习和深度学习模型进行有效区分，其中深度学习模型尤其表现优异。

Abstract: This study explored whether supervised machine learning and deep learning models can effectively distinguish perceived lower-quality news articles from perceived higher-quality news articles. 3 machine learning classifiers and 3 deep learning models were assessed using a newly created dataset of 1,412,272 English news articles from the Common Crawl over 2018-2024. Expert consensus ratings on 579 source websites were split at the median, creating perceived low and high-quality classes of about 706,000 articles each, with 194 linguistic features per website-level labelled article. Traditional machine learning classifiers such as the Random Forest demonstrated capable performance (0.7355 accuracy, 0.8131 ROC AUC). For deep learning, ModernBERT-large (256 context length) achieved the best performance (0.8744 accuracy; 0.9593 ROC-AUC; 0.8739 F1), followed by DistilBERT-base (512 context length) at 0.8685 accuracy and 0.9554 ROC-AUC. DistilBERT-base (256 context length) reached 0.8478 accuracy and 0.9407 ROC-AUC, while ModernBERT-base (256 context length) attained 0.8569 accuracy and 0.9470 ROC-AUC. These results suggest that the perceived quality of worldwide news articles can be effectively differentiated by traditional CPU-based machine learning classifiers and deep learning classifiers.

</details>


### [16] [ESGBench: A Benchmark for Explainable ESG Question Answering in Corporate Sustainability Reports](https://arxiv.org/abs/2511.16438)
*Sherine George,Nithish Saji*

Main category: cs.CL

TL;DR: 本文推出了用于企业可持续发展报告的可解释ESG问答基准ESGBench，并分析了大模型在该基准上的主要表现与挑战。


<details>
  <summary>Details</summary>
Motivation: 当前ESG（环境、社会与治理）领域的AI系统缺乏可解释性与可靠性评价标准，因此亟需针对企业可持续发展报告的问答系统研究与标准化评估工具。

Method: 提出了ESGBench数据集和评测框架，通过人类标注答案与证据，开展多维度评估。

Result: 分析了主流大模型在ESGBench上的表现，揭示了在事实一致性、可追溯性和领域适配方面存在的难点与挑战。

Conclusion: ESGBench旨在推动ESG领域可解释性问答系统的透明、可追溯与可问责性研究。

Abstract: We present ESGBench, a benchmark dataset and evaluation framework designed to assess explainable ESG question answering systems using corporate sustainability reports. The benchmark consists of domain-grounded questions across multiple ESG themes, paired with human-curated answers and supporting evidence to enable fine-grained evaluation of model reasoning. We analyze the performance of state-of-the-art LLMs on ESGBench, highlighting key challenges in factual consistency, traceability, and domain alignment. ESGBench aims to accelerate research in transparent and accountable ESG-focused AI systems.

</details>


### [17] [Anatomy of an Idiom: Tracing Non-Compositionality in Language Models](https://arxiv.org/abs/2511.16467)
*Andrew Gomes*

Main category: cs.CL

TL;DR: 本文提出电路分析新方法，揭示变换器模型中对习语的特殊处理机制，并对未来理解复杂语言结构提供了参考。


<details>
  <summary>Details</summary>
Motivation: 习语作为非组合性语言的典型代表，传统语言模型常难以处理清晰，而探究其底层机制可加深对变换器结构理解及语言智能化水平提升。

Method: 采用一种改进的路径补丁算法，结合电路发现与分析技术，对模型内部习语处理流程进行追踪与归纳。

Result: 发现了习语处理中活跃的Idiom Heads以及习语词间的“增强接收”现象，揭示了模型致力于在效率与鲁棒性间的平衡，并提出了对复杂语法结构建模的新路径。

Conclusion: 变换器语言模型处理习语时，存在专门的注意力头（Idiom Heads）和独特的处理机制，这为理解模型如何应对非组合性语言提供了新视角。

Abstract: We investigate the processing of idiomatic expressions in transformer-based language models using a novel set of techniques for circuit discovery and analysis. First discovering circuits via a modified path patching algorithm, we find that idiom processing exhibits distinct computational patterns. We identify and investigate ``Idiom Heads,'' attention heads that frequently activate across different idioms, as well as enhanced attention between idiom tokens due to earlier processing, which we term ``augmented reception.'' We analyze these phenomena and the general features of the discovered circuits as mechanisms by which transformers balance computational efficiency and robustness. Finally, these findings provide insights into how transformers handle non-compositional language and suggest pathways for understanding the processing of more complex grammatical constructions.

</details>


### [18] [Arctic-Extract Technical Report](https://arxiv.org/abs/2511.16470)
*Mateusz Chiliński,Julita Ołtusek,Wojciech Jaśkowski*

Main category: cs.CL

TL;DR: Arctic-Extract是一款高效轻量的文档结构数据抽取模型，既适合大规模文档处理，也能在硬件资源有限的设备上优异运行。


<details>
  <summary>Details</summary>
Motivation: 目前业界对于在资源受限硬件上高效处理大型、复杂文档的需求日益增长，需兼顾准确性和部署便利性。

Method: 本研究介绍了Arctic-Extract的训练协议及模型评估流程，包括对问答、实体识别和表格抽取等任务的测试。

Result: Arctic-Extract模型体积仅为6.6 GiB，可在内存为24GB的A10 GPU上一次处理多达125页A4文档，评估显示其在文档理解任务上性能优越。

Conclusion: Arctic-Extract模型在商业文档结构化数据抽取任务中表现优异，兼具高性能与轻量化，适合资源受限设备部署。

Abstract: Arctic-Extract is a state-of-the-art model designed for extracting structural data (question answering, entities and tables) from scanned or digital-born business documents. Despite its SoTA capabilities, the model is deployable on resource-constrained hardware, weighting only 6.6 GiB, making it suitable for deployment on devices with limited resources, such as A10 GPUs with 24 GB of memory. Arctic-Extract can process up to 125 A4 pages on those GPUs, making suitable for long document processing. This paper highlights Arctic-Extract's training protocols and evaluation results, demonstrating its strong performance in document understanding.

</details>


### [19] [TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval](https://arxiv.org/abs/2511.16528)
*Özay Ezerceli,Mahmoud El Hussieni,Selva Taş,Reyhan Bayraktar,Fatma Betül Terzioğlu,Yusuf Çelebi,Yağız Asker*

Main category: cs.CL

TL;DR: 首次系统比较了土耳其语信息检索领域的稠密编码器与晚期交互模型，晚期交互模型在较低参数量下保留高性能，更适合低延迟场景并推动生产部署，但未来需更大规模真实数据验证。


<details>
  <summary>Details</summary>
Motivation: 土耳其语作为形态复杂、资源较少的语言，现有神经IR系统未充分探索晚期交互模型的优势，缺乏系统评测。

Method: 提出了TurkColBERT评测基准，采用两阶段自适应流程：先在土耳其语NLI/STS任务上微调英语和多语编码器，再用PyLate和MS MARCO-TR转换为ColBERT风格检索器，并比较多种索引算法。

Result: 超小参数ColBERT模型能保留超过71%主流稠密编码器的mAP，并显著超越稠密编码器；MUVERA+Rerank速度提升3.33倍且mAP提升1.7%；ColmmBERT-base-TR的查询延迟仅0.54 ms。

Conclusion: 晚期交互模型在土耳其语信息检索中表现优异，且参数效率远高于传统的稠密编码器。MUVERA算法带来更低延迟和更快速度，为实际部署铺路。

Abstract: Neural information retrieval systems excel in high-resource languages but remain underexplored for morphologically rich, lower-resource languages such as Turkish. Dense bi-encoders currently dominate Turkish IR, yet late-interaction models -- which retain token-level representations for fine-grained matching -- have not been systematically evaluated. We introduce TurkColBERT, the first comprehensive benchmark comparing dense encoders and late-interaction models for Turkish retrieval. Our two-stage adaptation pipeline fine-tunes English and multilingual encoders on Turkish NLI/STS tasks, then converts them into ColBERT-style retrievers using PyLate trained on MS MARCO-TR. We evaluate 10 models across five Turkish BEIR datasets covering scientific, financial, and argumentative domains. Results show strong parameter efficiency: the 1.0M-parameter colbert-hash-nano-tr is 600$\times$ smaller than the 600M turkish-e5-large dense encoder while preserving over 71\% of its average mAP. Late-interaction models that are 3--5$\times$ smaller than dense encoders significantly outperform them; ColmmBERT-base-TR yields up to +13.8\% mAP on domain-specific tasks. For production-readiness, we compare indexing algorithms: MUVERA+Rerank is 3.33$\times$ faster than PLAID and offers +1.7\% relative mAP gain. This enables low-latency retrieval, with ColmmBERT-base-TR achieving 0.54 ms query times under MUVERA. We release all checkpoints, configs, and evaluation scripts. Limitations include reliance on moderately sized datasets ($\leq$50K documents) and translated benchmarks, which may not fully reflect real-world Turkish retrieval conditions; larger-scale MUVERA evaluations remain necessary.

</details>


### [20] [Beyond Tokens in Language Models: Interpreting Activations through Text Genre Chunks](https://arxiv.org/abs/2511.16540)
*Éloïse Benito-Rodriguez,Einar Urdshals,Jasmina Nasufi,Nicky Pochinkov*

Main category: cs.CL

TL;DR: 本文提出了一种基于LLM激活值预测文本体裁的方法，使用浅层学习模型，在体裁推断准确率上表现突出，为LLMs解释和安全应用提供新思路。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs难以解释结构，同时时间和资源限制使得人工评估所有输出不现实。作者希望找到一种新的自动化方法，以提升LLMs的可解释性和可控性。

Method: 作者利用Mistral-7B模型，对两组数据集提取激活值，并采用scikit-learn分类器进行体裁预测。

Result: 通过浅层学习模型，对LLM激活值进行分析，在两个数据集上的体裁预测F1分数分别达到98%和71%，均显著优于对照组任务。

Conclusion: 本文首次证明，可以通过浅层学习模型有效预测促使大型语言模型（LLM）生成文本的体裁，为LLMs的可解释性和安全部署奠定了基础。

Abstract: Understanding Large Language Models (LLMs) is key to ensure their safe and beneficial deployment. This task is complicated by the difficulty of interpretability of LLM structures, and the inability to have all their outputs human-evaluated. In this paper, we present the first step towards a predictive framework, where the genre of a text used to prompt an LLM, is predicted based on its activations. Using Mistral-7B and two datasets, we show that genre can be extracted with F1-scores of up to 98% and 71% using scikit-learn classifiers. Across both datasets, results consistently outperform the control task, providing a proof of concept that text genres can be inferred from LLMs with shallow learning models.

</details>


### [21] [WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue](https://arxiv.org/abs/2511.16544)
*Zachary Ellis,Jared Joselowitz,Yash Deo,Yajie He,Anna Kalygina,Aisling Higham,Mana Rahimzadeh,Yan Jia,Ibrahim Habli,Ernest Lim*

Main category: cs.CL

TL;DR: 论文指出传统指标难以评估ASR在临床对话中的真实风险，提出用优化的LLM模型自动评判临床风险，实现高准确率和一致性，推动ASR安全评估向更高标准发展。


<details>
  <summary>Details</summary>
Motivation: ASR在医疗领域应用增加，但传统以WER为代表的评估度量无法真实反映ASR误差对患者安全的影响。为推动临床对话ASR转录的安全评估而不仅仅是文字准确率，需要创新的评价框架。

Method: 构建了专家标注的临床对话数据集，专家比较ASR及人工转录，标注低、中、高风险。之后，提出基于大型语言模型（LLM）的自动评审系统，利用GEPA进行调优，以模拟专业医生的风险评定，再与人工标注结果对比。

Result: 新提出的LLM-as-a-Judge，经优化后（Gemini-2.5-Pro），在人类专业医生划分的风险等级评估任务中达到90%准确率和Cohen’s κ为0.816，与专家水平相当，实现了ASR评估自动化与安全性升级。

Conclusion: 传统的ASR评估指标（比如WER）与实际临床风险相关性较弱，论文提出的LLM自动评审系统能更准确反映ASR误差对临床安全的真实影响。此系统在安全评估上表现接近专家，同时具有高准确率和一致性。

Abstract: As Automatic Speech Recognition (ASR) is increasingly deployed in clinical dialogue, standard evaluations still rely heavily on Word Error Rate (WER). This paper challenges that standard, investigating whether WER or other common metrics correlate with the clinical impact of transcription errors. We establish a gold-standard benchmark by having expert clinicians compare ground-truth utterances to their ASR-generated counterparts, labeling the clinical impact of any discrepancies found in two distinct doctor-patient dialogue datasets. Our analysis reveals that WER and a comprehensive suite of existing metrics correlate poorly with the clinician-assigned risk labels (No, Minimal, or Significant Impact). To bridge this evaluation gap, we introduce an LLM-as-a-Judge, programmatically optimized using GEPA to replicate expert clinical assessment. The optimized judge (Gemini-2.5-Pro) achieves human-comparable performance, obtaining 90% accuracy and a strong Cohen's $κ$ of 0.816. This work provides a validated, automated framework for moving ASR evaluation beyond simple textual fidelity to a necessary, scalable assessment of safety in clinical dialogue.

</details>


### [22] [Integrating Symbolic Natural Language Understanding and Language Models for Word Sense Disambiguation](https://arxiv.org/abs/2511.16577)
*Kexin Zhao,Ken Forbus*

Main category: cs.CL

TL;DR: 该论文提出利用大语言模型自动对复杂语义表示进行词义消歧，无需人工标注，实验效果好。


<details>
  <summary>Details</summary>
Motivation: 现有词义消歧方法依赖粗粒度知识库和人工标注数据，难以应对更丰富语义表示需求，需要自动化且无需人工标注的新方法。

Method: 将符号型自然语言理解系统生成的多个候选释义转化为可区分的自然语言表达，利用大型语言模型（LLM）进行上下文判别选择，最终将选中的释义反馈到符号系统。

Result: 通过与人工标注的标准答案对比，验证了所提方法的有效性。

Conclusion: 提出的方法无需人工注释训练数据也能有效进行词义消歧，且在实验中表现良好。

Abstract: Word sense disambiguation is a fundamental challenge in natural language understanding. Current methods are primarily aimed at coarse-grained representations (e.g. WordNet synsets or FrameNet frames) and require hand-annotated training data to construct. This makes it difficult to automatically disambiguate richer representations (e.g. built on OpenCyc) that are needed for sophisticated inference. We propose a method that uses statistical language models as oracles for disambiguation that does not require any hand-annotation of training data. Instead, the multiple candidate meanings generated by a symbolic NLU system are converted into distinguishable natural language alternatives, which are used to query an LLM to select appropriate interpretations given the linguistic context. The selected meanings are propagated back to the symbolic NLU system. We evaluate our method against human-annotated gold answers to demonstrate its effectiveness.

</details>


### [23] [Comparison of Text-Based and Image-Based Retrieval in Multimodal Retrieval Augmented Generation Large Language Model Systems](https://arxiv.org/abs/2511.16654)
*Elias Lumer,Alex Cardenas,Matt Melich,Myles Mason,Sara Dieter,Vamse Kumar Subbiah,Pradeep Honaganahalli Basavaraju,Roberto Hernandez*

Main category: cs.CL

TL;DR: 论文证明了直接多模态嵌入检索在RAG系统中比传统LLM文本摘要方法效果更佳，特别是在金融数据图表等多模态知识库问答上表现突出，推荐采用直接多模态嵌入方案。


<details>
  <summary>Details</summary>
Motivation: 现有多模态RAG系统在将图像转为文本摘要后存储，导致关键信息和视觉细节丢失，影响问答效果。该工作旨在比较不同多模态检索方法，探索更高效的方法提升系统性能。

Method: 设计了两种多模态RAG检索方式的对比实验：一种将图像内容预摘要为文本并嵌入数据库，另一种是图像与文本原始嵌入多模态向量空间。对多种LLM和多模态嵌入模型，在新构建的金融财报问答基准上，进行系统评测。

Result: 直接多模态嵌入检索方法在mAP@5和nDCG@5等指标上分别取得13%和11%的绝对提升，对比文本摘要方法提升显著。同时在正确性、一致性等人工比较上也明显优于传统文本摘要方法。

Conclusion: 直接多模态嵌入检索能够显著提升多模态RAG系统在金融文档问答场景中的检索和回答准确性，较文本摘要嵌入检索有明显优势。

Abstract: Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models (LLMs) to access multimodal knowledge bases containing both text and visual information such as charts, diagrams, and tables in financial documents. However, existing multimodal RAG systems rely on LLM-based summarization to convert images into text during preprocessing, storing only text representations in vector databases, which causes loss of contextual information and visual details critical for downstream retrieval and question answering. To address this limitation, we present a comprehensive comparative analysis of two retrieval approaches for multimodal RAG systems, including text-based chunk retrieval (where images are summarized into text before embedding) and direct multimodal embedding retrieval (where images are stored natively in the vector space). We evaluate all three approaches across 6 LLM models and a two multi-modal embedding models on a newly created financial earnings call benchmark comprising 40 question-answer pairs, each paired with 2 documents (1 image and 1 text chunk). Experimental results demonstrate that direct multimodal embedding retrieval significantly outperforms LLM-summary-based approaches, achieving absolute improvements of 13% in mean average precision (mAP@5) and 11% in normalized discounted cumulative gain. These gains correspond to relative improvements of 32% in mAP@5 and 20% in nDCG@5, providing stronger evidence of their practical impact. We additionally find that direct multimodal retrieval produces more accurate and factually consistent answers as measured by LLM-as-a-judge pairwise comparisons. We demonstrate that LLM summarization introduces information loss during preprocessing, whereas direct multimodal embeddings preserve visual context for retrieval and inference.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [24] [Majority Rules: LLM Ensemble is a Winning Approach for Content Categorization](https://arxiv.org/abs/2511.15714)
*Ariel Kamen,Yakov Kamen*

Main category: cs.AI

TL;DR: 本文提出eLLM方法，将多个LLM集成用于文本分类，显著提升了性能，验证了方法有效性，结果接近人工专家标准。


<details>
  <summary>Details</summary>
Motivation: 单一LLM在文本分类时易出现一致性不足、幻觉、类别膨胀和误分类等问题，集成框架可弥补各自短板，提升模型鲁棒性和准确度。

Method: 提出一种集成大型语言模型（eLLM）的框架，通过数学模型进行集体决策建模，并制定了聚合准则。在IAB分类体系下，对十个先进LLM在同一零样本条件下进行评测分析。

Result: eLLM方法相比于最强单一模型在F1分数上最多提升65%，改善了鲁棒性与准确性，分类表现稳定并接近人类专家水平。

Conclusion: eLLM框架通过集成多种大型语言模型，有效提升了非结构化文本分类的性能，达到了接近人类专家的水平，并具备可扩展性，有望显著减少对人工标注的依赖。

Abstract: This study introduces an ensemble framework for unstructured text categorization using large language models (LLMs). By integrating multiple models, the ensemble large language model (eLLM) framework addresses common weaknesses of individual systems, including inconsistency, hallucination, category inflation, and misclassification. The eLLM approach yields a substantial performance improvement of up to 65\% in F1-score over the strongest single model. We formalize the ensemble process through a mathematical model of collective decision-making and establish principled aggregation criteria. Using the Interactive Advertising Bureau (IAB) hierarchical taxonomy, we evaluate ten state-of-the-art LLMs under identical zero-shot conditions on a human-annotated corpus of 8{,}660 samples. Results show that individual models plateau in performance due to the compression of semantically rich text into sparse categorical representations, while eLLM improves both robustness and accuracy. With a diverse consortium of models, eLLM achieves near human-expert-level performance, offering a scalable and reliable solution for taxonomy-based classification that may significantly reduce dependence on human expert labeling.

</details>


### [25] [Graph-Memoized Reasoning: Foundations Structured Workflow Reuse in Intelligent Systems](https://arxiv.org/abs/2511.15715)
*Yash Raj Singh*

Main category: cs.AI

TL;DR: 本文提出用图结构记忆复用推理流程，通过优化目标与评估协议提升大模型推理效率、解释性和自我完善性。


<details>
  <summary>Details</summary>
Motivation: 现有基于大模型的推理系统在任务间不断重复相似推理，造成算力浪费、推理延迟增大与复现性降低。作者希望通过持久性推理机制回忆并复用过往计算痕迹来解决上述问题。

Method: 本文采用图结构存储过往推理决策流程，并通过结构和语义相似性进行检索和复用。提出了一个优化目标，通过正则化处理已存与新生成推理之间的不一致性，实现效率与一致性的权衡。

Result: 实现了以图为本的推理流程记忆和复用机制，有望提升推理系统的可解释性、计算效率和自我优化能力。提出了与优化目标匹配的评估方案，为后续实践提供了理论依据。

Conclusion: 本文提出了一种基于图结构记忆的推理框架，实现了推理流程的高效存储与复用。这为大规模智能体系统的可解释性、成本效率、自我完善能力奠定了基础。

Abstract: Modern large language model-based reasoning systems frequently recompute similar reasoning steps across tasks, wasting computational resources, inflating inference latency, and limiting reproducibility. These inefficiencies underscore the need for persistent reasoning mechanisms that can recall and reuse prior computational traces.
  We introduce Graph-Memoized Reasoning, a formal framework for representing, storing, and reusing reasoning workflows as graph-structured memory. By encoding past decision graphs and retrieving them through structural and semantic similarity, our approach enables compositional reuse of subgraphs across new reasoning tasks.
  We formulate an optimization objective that minimizes total reasoning cost regularized by inconsistency between stored and generated workflows, providing a theoretical foundation for efficiency-consistency trade-offs in intelligent systems. We outline a conceptual evaluation protocol aligned with the proposed optimization objective.
  This framework establishes the groundwork for interpretable, cost-efficient, and self-improving reasoning architectures, offering a step toward persistent memory in large-scale agentic systems.

</details>


### [26] [MACIE: Multi-Agent Causal Intelligence Explainer for Collective Behavior Understanding](https://arxiv.org/abs/2511.15716)
*Abraham Itzhak Weinberg*

Main category: cs.AI

TL;DR: MACIE框架结合因果推断与多智能体价值分析，实现了个体归因、系统涌现量化及可操作解释，显著提高多智能体强化学习的可解释性，适合实时应用。


<details>
  <summary>Details</summary>
Motivation: 当前可解释AI方法难以应对多智能体场景，无法有效归因个体贡献、量化涌现行为及刻画复杂交互。随着MARL被应用于安全关键领域，亟需实现多智能体系统的可解释性。

Method: MACIE融合了结构因果模型、干预反事实和Shapley值，通过因果归因分数、涌现智能度量和自然语言叙述，对个体贡献、系统性涌现行为及可操作解释进行全面分析。

Result: MACIE在四类多智能体场景（协作、竞争、混合动机）中展现高效、准确的结果。个体归因分数均值phi_i为5.07，标准差小于0.05，协作任务中成功检测出正向涌现行为（涌现指数最高0.461），计算效率高（单数据集0.79秒，CPU）。

Conclusion: MACIE框架能够为多智能体强化学习（MARL）系统提供可解释性，显著提高多智能体系统的可解释性与透明度，为可解释、可信、可追溯的多智能体AI奠定基础。

Abstract: As Multi Agent Reinforcement Learning systems are used in safety critical applications. Understanding why agents make decisions and how they achieve collective behavior is crucial. Existing explainable AI methods struggle in multi agent settings. They fail to attribute collective outcomes to individuals, quantify emergent behaviors, or capture complex interactions. We present MACIE Multi Agent Causal Intelligence Explainer, a framework combining structural causal models, interventional counterfactuals, and Shapley values to provide comprehensive explanations. MACIE addresses three questions. First, each agent's causal contribution using interventional attribution scores. Second, system level emergent intelligence through synergy metrics separating collective effects from individual contributions. Third, actionable explanations using natural language narratives synthesizing causal insights. We evaluate MACIE across four MARL scenarios: cooperative, competitive, and mixed motive. Results show accurate outcome attribution, mean phi_i equals 5.07, standard deviation less than 0.05, detection of positive emergence in cooperative tasks, synergy index up to 0.461, and efficient computation, 0.79 seconds per dataset on CPU. MACIE uniquely combines causal rigor, emergence quantification, and multi agent support while remaining practical for real time use. This represents a step toward interpretable, trustworthy, and accountable multi agent AI.

</details>


### [27] [How Modality Shapes Perception and Reasoning: A Study of Error Propagation in ARC-AGI](https://arxiv.org/abs/2511.15717)
*Bo Wen,Chen Wang,Erhan Bilal*

Main category: cs.AI

TL;DR: 论文探讨ARC-AGI任务中的文本和图片感知瓶颈，提出感知与推理隔离的方法，发现融合文本与图片能提升模型准确率，且无需变更模型结构。


<details>
  <summary>Details</summary>
Motivation: ARC-AGI等任务需要模型具备强泛化和组合能力，但不同的编码方式可能影响模型对任务特征的捕捉和理解。当前缺乏系统性分析如何区分指令错误与执行错误，以及编码模态如何影响模型感知。

Method: 采用加权集合分歧指标与两阶段推理流程，隔离感知和推理，比较九种文本与图片模态在ARC-AGI任务中的表现，并分析其对模型感知与执行的影响。

Result: 结构化文本能准确提取稀疏特征坐标，图片可还原2D形状但受分辨率影响，文本与图片结合可以提升约8个感知点及0.20中位相似度，对齐表示和交叉验证进一步增强指令和执行的可靠性。

Conclusion: 通过对比多种文本和图像模态，结合两者能够有效提升ARC-AGI任务的感知及执行准确性，无需更改模型结构即可获得更优结果。

Abstract: ARC-AGI and ARC-AGI-2 measure generalization-through-composition on small color-quantized grids, and their prize competitions make progress on these harder held-out tasks a meaningful proxy for systematic generalization. Recent instruction-first systems translate grids into concise natural-language or DSL rules executed in generate-execute-select loops, yet we lack a principled account of how encodings shape model perception and how to separate instruction errors from execution errors. We hypothesize that modality imposes perceptual bottlenecks -- text flattens 2D structure into 1D tokens while images preserve layout but can introduce patch-size aliasing -- thereby shaping which grid features are reliably perceived. To test this, we isolate perception from reasoning across nine text and image modalities using a weighted set-disagreement metric and a two-stage reasoning pipeline, finding that structured text yields precise coordinates on sparse features, images capture 2D shapes yet are resolution-sensitive, and combining them improves execution (about 8 perception points; about 0.20 median similarity). Overall, aligning representations with transformer inductive biases and enabling cross-validation between text and image yields more accurate instructions and more reliable execution without changing the underlying model.

</details>


### [28] [Chain of Summaries: Summarization Through Iterative Questioning](https://arxiv.org/abs/2511.15719)
*William Brach,Lukas Galke Poech*

Main category: cs.AI

TL;DR: 作者提出了链式摘要（CoS）算法，能够自动生成适合LLM读取的高度信息密集的通用文本摘要。相比流行摘要方法和原始网页内容，该方法能大幅提升自动问答等任务效果，减少Token消耗，并适用于各种LLM。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）在使用外部网页内容时，常受制于内容格式不友好和上下文长度限制，无法高效地理解网页信息，因此亟需为LLM设计更适配的内容摘要形式。

Method: 本研究提出了受黑格尔辩证法启发的“链式摘要（Chain of Summaries, CoS）”方法。该方法通过初始总结（论文称为thesis）、对其进行质疑发现不足（antithesis）、再生成合成总结（synthesis）这样的迭代流程，不断精炼摘要以形成信息密集、通用性强的web内容文本摘要。

Result: 在TriviaQA、TruthfulQA和SQUAD等数据集上，CoS方法在相关任务的表现上超越了零样本（zero-shot）LLM基线最高66%，优于主流摘要算法BRIO和PEGASUS最高27%；CoS生成的摘要在问答任务中表现优于原始网页内容，并消耗更少Token，且对于下游使用的哪个LLM不敏感。

Conclusion: CoS 方法生成的信息密集型通用摘要，不仅提升了LLM对于网页内容的可访问性，还能显著提升下游问答等任务的表现，同时减少了所需的Token数，并且对后续使用的LLM模型本身无依赖性。该方法对网站维护者来说，既方便机器，又便于人工监督。

Abstract: Large Language Models (LLMs) are increasingly using external web content. However, much of this content is not easily digestible by LLMs due to LLM-unfriendly formats and limitations of context length. To address this issue, we propose a method for generating general-purpose, information-dense summaries that act as plain-text repositories of web content. Inspired by Hegel's dialectical method, our approach, denoted as Chain of Summaries (CoS), iteratively refines an initial summary (thesis) by identifying its limitations through questioning (antithesis), leading to a general-purpose summary (synthesis) that can satisfy current and anticipate future information needs. Experiments on the TriviaQA, TruthfulQA, and SQUAD datasets demonstrate that CoS outperforms zero-shot LLM baselines by up to 66% and specialized summarization methods such as BRIO and PEGASUS by up to 27%. CoS-generated summaries yield higher Q&A performance compared to the source content, while requiring substantially fewer tokens and being agnostic to the specific downstream LLM. CoS thus resembles an appealing option for website maintainers to make their content more accessible for LLMs, while retaining possibilities for human oversight.

</details>


### [29] [Automated Hazard Detection in Construction Sites Using Large Language and Vision-Language Models](https://arxiv.org/abs/2511.15720)
*Islem Sahraoui*

Main category: cs.AI

TL;DR: 本论文提出基于文本和图像分析的多模态AI框架，提升施工安全隐患识别效率。实验证明，小型开源模型在低成本条件下可实现竞争性性能，促进安全监测自动化。


<details>
  <summary>Details</summary>
Motivation: 在施工现场，安全事故数据分散于多种形式（文本报告、检查记录、现场图片），传统方法难以整合，亟需多模态AI方法提升安全隐患识别效率。

Method: 提出并实现了多模态AI框架，结合文本和图像分析。采用两个案例研究：一是利用GPT 4o和GPT 4o mini处理OSHA事故报告文本；二是利用Molmo 7B和Qwen2 VL 2B在ConstructionSite10k数据集上进行视觉-语言模型的安全违规检测。

Result: 多模态AI框架在自动化安全隐患识别任务上表现优秀。Molmo 7B和Qwen2 VL 2B在某些提示配置下显示出接近专有模型的性能，具备成本效益及扩展潜力。

Conclusion: 轻量级开放源代码视觉-语言模型（Molmo 7B 及 Qwen2 VL 2B）在特定配置下可以实现与专有模型相媲美的安全检测效果，证明了低资源多模态系统在施工安全监测中的可行性。

Abstract: This thesis explores a multimodal AI framework for enhancing construction safety through the combined analysis of textual and visual data. In safety-critical environments such as construction sites, accident data often exists in multiple formats, such as written reports, inspection records, and site imagery, making it challenging to synthesize hazards using traditional approaches. To address this, this thesis proposed a multimodal AI framework that combines text and image analysis to assist in identifying safety hazards on construction sites. Two case studies were consucted to evaluate the capabilities of large language models (LLMs) and vision-language models (VLMs) for automated hazard identification.The first case study introduces a hybrid pipeline that utilizes GPT 4o and GPT 4o mini to extract structured insights from a dataset of 28,000 OSHA accident reports (2000-2025). The second case study extends this investigation using Molmo 7B and Qwen2 VL 2B, lightweight, open-source VLMs. Using the public ConstructionSite10k dataset, the performance of the two models was evaluated on rule-level safety violation detection using natural language prompts. This experiment served as a cost-aware benchmark against proprietary models and allowed testing at scale with ground-truth labels. Despite their smaller size, Molmo 7B and Quen2 VL 2B showed competitive performance in certain prompt configurations, reinforcing the feasibility of low-resource multimodal systems for rule-aware safety monitoring.

</details>


### [30] [Spatial Reasoning in Multimodal Large Language Models: A Survey of Tasks, Benchmarks and Methods](https://arxiv.org/abs/2511.15722)
*Weichen Liu,Qiyao Xue,Haoming Wang,Xiangyu Yin,Boyuan Yang,Wei Gao*

Main category: cs.AI

TL;DR: 面向空间推理，本文创新性提出认知视角分类体系，结合现有各种模态方法，系统分析了MLLMs空间智能研究现状、挑战与提升途径，为学界梳理现有差距并指明未来方向。


<details>
  <summary>Details</summary>
Motivation: 现有综述多以输入模态分类空间推理任务，未能从认知和推理复杂度出发划分，对比人类空间智能存在不足，缺乏统一标准及交叉任务对比。本文旨在弥补这一空白，促进领域进步。

Method: 提出以认知能力为基础的新型空间推理分类体系，并将现有的文本、视觉-语言和具身（embodied）类基准测试映射到该体系，系统梳理任务、评测标准与空间能力提升方法。

Result: 建立了基于认知空间推理分类体系，总结了相关任务、基准与评测方法，分析了训练与推理方法的互补性，指出了MLLMs在空间智能上的不足，为新入领域的研究者提供系统性指引及未来发展建议。

Conclusion: 本文通过认知角度对空间推理进行分类，将相关任务与认知函数联系起来，有助于明确当前多模态大语言模型（MLLMs）与人类空间推理能力的差距，为后续研究提供清晰方向。

Abstract: Spatial reasoning, which requires ability to perceive and manipulate spatial relationships in the 3D world, is a fundamental aspect of human intelligence, yet remains a persistent challenge for Multimodal large language models (MLLMs). While existing surveys often categorize recent progress based on input modality (e.g., text, image, video, or 3D), we argue that spatial ability is not solely determined by the input format. Instead, our survey introduces a taxonomy that organizes spatial intelligence from cognitive aspect and divides tasks in terms of reasoning complexity, linking them to several cognitive functions. We map existing benchmarks across text only, vision language, and embodied settings onto this taxonomy, and review evaluation metrics and methodologies for assessing spatial reasoning ability. This cognitive perspective enables more principled cross-task comparisons and reveals critical gaps between current model capabilities and human-like reasoning. In addition, we analyze methods for improving spatial ability, spanning both training-based and reasoning-based approaches. This dual perspective analysis clarifies their respective strengths, uncovers complementary mechanisms. By surveying tasks, benchmarks, and recent advances, we aim to provide new researchers with a comprehensive understanding of the field and actionable directions for future research.

</details>


### [31] [Uncertainty-Resilient Multimodal Learning via Consistency-Guided Cross-Modal Transfer](https://arxiv.org/abs/2511.15741)
*Hyo-Jeong Jang*

Main category: cs.AI

TL;DR: 本文提出一致性引导的跨模态学习方法，通过投射到共享潜在空间和对齐结构关系，极大提升了多模态系统应对噪声、弱监督等不确定性问题的能力，并在多模态情感识别等应用中取得优异效果，对人机交互等领域具有实际意义。


<details>
  <summary>Details</summary>
Motivation: 多模态系统在实际人机交互中经常遭遇数据噪声、标签质量低以及多模态特性异质等问题，常规方法对这些不确定性鲁棒性不足，因此需要发展能适应不良数据和弱监督的新型学习机制。

Method: 1）提出将异构模态投影到共享潜在空间，实现模态间跨域一致性和结构关系建模；2）利用一致性引导的跨模态知识迁移提升特征的鲁棒性和判别能力；3）基于潜在空间分析和多模态情感识别基准实验，评估了框架的抗噪性和稳定性。

Result: 一致性引导的跨模态迁移方法显著提升了模型对噪声、数据不完整和低质量监督的鲁棒性与判别能力，实验在情感识别等多模态基准数据集上超过传统方法，并在理论上揭示了跨模态一致性对结构关系建模和不确定性表征的重要作用。

Conclusion: 通过提出一致性引导的跨模态迁移框架，有效提升了多模态学习系统在不确定性、高噪声和低标注质量条件下的稳健性，验证了其在脑-机接口等实际应用中的可靠性和实用性。

Abstract: Multimodal learning systems often face substantial uncertainty due to noisy data, low-quality labels, and heterogeneous modality characteristics. These issues become especially critical in human-computer interaction settings, where data quality, semantic reliability, and annotation consistency vary across users and recording conditions. This thesis tackles these challenges by exploring uncertainty-resilient multimodal learning through consistency-guided cross-modal transfer. The central idea is to use cross-modal semantic consistency as a basis for robust representation learning. By projecting heterogeneous modalities into a shared latent space, the proposed framework mitigates modality gaps and uncovers structural relations that support uncertainty estimation and stable feature learning. Building on this foundation, the thesis investigates strategies to enhance semantic robustness, improve data efficiency, and reduce the impact of noise and imperfect supervision without relying on large, high-quality annotations. Experiments on multimodal affect-recognition benchmarks demonstrate that consistency-guided cross-modal transfer significantly improves model stability, discriminative ability, and robustness to noisy or incomplete supervision. Latent space analyses further show that the framework captures reliable cross-modal structure even under challenging conditions. Overall, this thesis offers a unified perspective on resilient multimodal learning by integrating uncertainty modeling, semantic alignment, and data-efficient supervision, providing practical insights for developing reliable and adaptive brain-computer interface systems.

</details>


### [32] [Multi-Agent LLM Orchestration Achieves Deterministic, High-Quality Decision Support for Incident Response](https://arxiv.org/abs/2511.15755)
*Philip Drammeh*

Main category: cs.AI

TL;DR: 本文提出用于事故响应的多智能体LLM编排框架，实验证明其能极大提升行动可执行性与一致性，满足生产需求，并引入新指标DQ量化质量优势，所有代码与数据公开可复现。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的单智能体事故响应输出易产生模糊且不可用的建议，无法满足生产环境对SLA质量的要求，迫切需要提升输出的可执行性和一致性。

Method: 开发了MyAntFarm.ai可复现容器化框架，通过对单智能体与多智能体系统在同一事故场景下进行了348次受控实验对比，并提出了新的衡量指标Decision Quality (DQ)。

Result: 多智能体系统实现了100%的可执行推荐率，较单智能体1.7%提升近80倍，并在行动具体性和方案正确性上分别达到了80倍和140倍提升，且所有实验质量零方差，速度与单智能体持平。

Conclusion: 多智能体编排能够显著提升基于LLM的生产环境事故响应的质量，使其达到确定性的、高度可执行的推荐输出，远优于单智能体方案。

Abstract: Large language models (LLMs) promise to accelerate incident response in production systems, yet single-agent approaches generate vague, unusable recommendations. We present MyAntFarm.ai, a reproducible containerized framework demonstrating that multi-agent orchestration fundamentally transforms LLM-based incident response quality. Through 348 controlled trials comparing single-agent copilot versus multi-agent systems on identical incident scenarios, we find that multi-agent orchestration achieves 100% actionable recommendation rate versus 1.7% for single-agent approaches, an 80 times improvement in action specificity and 140 times improvement in solution correctness. Critically, multi-agent systems exhibit zero quality variance across all trials, enabling production SLA commitments impossible with inconsistent single-agent outputs. Both architectures achieve similar comprehension latency (approx.40s), establishing that the architectural value lies in deterministic quality, not speed. We introduce Decision Quality (DQ), a novel metric capturing validity, specificity, and correctness properties essential for operational deployment that existing LLM metrics do not address. These findings reframe multi-agent orchestration from a performance optimization to a production-readiness requirement for LLM-based incident response. All code, Docker configurations, and trial data are publicly available for reproduction.

</details>


### [33] [Identifying the Supply Chain of AI for Trustworthiness and Risk Management in Critical Applications](https://arxiv.org/abs/2511.15763)
*Raymond K. Sheh,Karen Geappen*

Main category: cs.AI

TL;DR: 本文针对AI供应链风险的系统性评估提出了创新分类法，填补了AI风险管理在关键领域内的空白，有助于提升AI治理水平和关键应用的安全保障。


<details>
  <summary>Details</summary>
Motivation: 当前AI风险的研究虽然广泛，但针对AI复杂供应链结构所带来的系统性风险评估存在明显缺口，尤其是在关键领域应用时更加突出。填补该缺口对于关键应用的安全性至关重要。

Method: 通过对现有AI风险评估与管理研究进行文献调研，并提出了用于分类AI供应链实体的新分类法。

Result: 提出了针对AI供应链实体的分类法，帮助非专业人员系统盘点AI系统的依赖，推动AI治理和风险管理措施发展。

Conclusion: 本文提出了针对AI供应链风险进行系统性评估的必要性，并提出了一个用于分类AI供应链实体的分类法，有助于更好地管理AI在关键领域的应用风险。

Abstract: Risks associated with the use of AI, ranging from algorithmic bias to model hallucinations, have received much attention and extensive research across the AI community, from researchers to end-users. However, a gap exists in the systematic assessment of supply chain risks associated with the complex web of data sources, pre-trained models, agents, services, and other systems that contribute to the output of modern AI systems. This gap is particularly problematic when AI systems are used in critical applications, such as the food supply, healthcare, utilities, law, insurance, and transport.
  We survey the current state of AI risk assessment and management, with a focus on the supply chain of AI and risks relating to the behavior and outputs of the AI system. We then present a proposed taxonomy specifically for categorizing AI supply chain entities. This taxonomy helps stakeholders, especially those without extensive AI expertise, to "consider the right questions" and systematically inventory dependencies across their organization's AI systems. Our contribution bridges a gap between the current state of AI governance and the urgent need for actionable risk assessment and management of AI use in critical applications.

</details>


### [34] [Balancing Natural Language Processing Accuracy and Normalisation in Extracting Medical Insights](https://arxiv.org/abs/2511.15778)
*Paulina Tworek,Miłosz Bargieł,Yousef Khan,Tomasz Pełech-Pilichowski,Marek Mikołajczyk,Roman Lewandowski,Jose Sousa*

Main category: cs.AI

TL;DR: 本研究比较了规则方法与LLM在波兰医院EHR信息抽取中的表现，发现二者各有优势，且建议采用混合方案以实现医疗文本结构化的最优效果。


<details>
  <summary>Details</summary>
Motivation: 在医疗领域从非结构化文本中提取有效信息仍具挑战，尤其是在非英语环境资源有限的情况下，需要优选适合实际应用的NLP方法。

Method: 分别采用低算力NLP规则方法和大型语言模型(LLM)，在原始波兰语和翻译成英文的电子病历(EHR)文本上抽取患者人口统计、临床发现和药物信息，并对比两者在无文本归一化和翻译信息损耗情况下的表现。

Result: 规则方法在信息检索（如年龄和性别抽取）上准确度更高，LLM在药物命名识别更具扩展性和适应性。翻译可带来信息损失，且LLM对原文与译文存在表现差异。整体工作显示准确性、归一化和计算成本三者间的权衡。

Conclusion: 最佳实践是在实际医院环境中采取混合方案，将规则系统的精确性与大型语言模型的适应性结合，以实现更可靠、高效的结构化医学信息抽取。

Abstract: Extracting structured medical insights from unstructured clinical text using Natural Language Processing (NLP) remains an open challenge in healthcare, particularly in non-English contexts where resources are scarce. This study presents a comparative analysis of NLP low-compute rule-based methods and Large Language Models (LLMs) for information extraction from electronic health records (EHR) obtained from the Voivodeship Rehabilitation Hospital for Children in Ameryka, Poland. We evaluate both approaches by extracting patient demographics, clinical findings, and prescribed medications while examining the effects of lack of text normalisation and translation-induced information loss. Results demonstrate that rule-based methods provide higher accuracy in information retrieval tasks, particularly for age and sex extraction. However, LLMs offer greater adaptability and scalability, excelling in drug name recognition. The effectiveness of the LLMs was compared with texts originally in Polish and those translated into English, assessing the impact of translation. These findings highlight the trade-offs between accuracy, normalisation, and computational cost when deploying NLP in healthcare settings. We argue for hybrid approaches that combine the precision of rule-based systems with the adaptability of LLMs, offering a practical path toward more reliable and resource-efficient clinical NLP in real-world hospitals.

</details>


### [35] [IMACT-CXR - An Interactive Multi-Agent Conversational Tutoring System for Chest X-Ray Interpretation](https://arxiv.org/abs/2511.15825)
*Tuan-Anh Le,Anh Mai Vu,David Yang,Akash Awasthi,Hien Van Nguyen*

Main category: cs.AI

TL;DR: IMACT-CXR是一套多智能体互动教学系统，通过自动化评估和指导，提升胸部X光判读学习，已初步验证其有效性并具备实际部署潜力。


<details>
  <summary>Details</summary>
Motivation: 胸部X光片判读需要结合空间位置、专业知识和图像推理能力，现有自动化教学系统难以整合多模态交互、实时反馈和知识追踪，限制了临床培训效果。IMACT-CXR旨在统一这些关键功能，提高教学质量。

Method: 该系统基于多智能体会话框架（AutoGen），融合空间标注、注视分析、知识检索及图像-文本推理。通过引入专用智能体，系统可评价定位质量、生成启发式指导、检索PubMed文献、推荐类似病例，并结合Bayesian Knowledge Tracing跟踪技能掌握程度。同时结合肺叶分割模块进行视线反馈，并设置安全提示避免标签泄漏。

Result: IMACT-CXR已集成于REFLACX数据集支持的真实DICOM案例中。初步实验结果表明，相较基线方法，IMACT-CXR能显著提升学员在定位和诊断推理方面的表现。

Conclusion: IMACT-CXR系统能够有效提升学员定位和诊断推理能力，并具备低延迟、精细控制答案泄漏和良好的可扩展性，适合进一步应用于真实临床教学场景。

Abstract: IMACT-CXR is an interactive multi-agent conversational tutor that helps trainees interpret chest X-rays by unifying spatial annotation, gaze analysis, knowledge retrieval, and image-grounded reasoning in a single AutoGen-based workflow. The tutor simultaneously ingests learner bounding boxes, gaze samples, and free-text observations. Specialized agents evaluate localization quality, generate Socratic coaching, retrieve PubMed evidence, suggest similar cases from REFLACX, and trigger NV-Reason-CXR-3B for vision-language reasoning when mastery remains low or the learner explicitly asks. Bayesian Knowledge Tracing (BKT) maintains skill-specific mastery estimates that drive both knowledge reinforcement and case similarity retrieval. A lung-lobe segmentation module derived from a TensorFlow U-Net enables anatomically aware gaze feedback, and safety prompts prevent premature disclosure of ground-truth labels. We describe the system architecture, implementation highlights, and integration with the REFLACX dataset for real DICOM cases. IMACT-CXR demonstrates responsive tutoring flows with bounded latency, precise control over answer leakage, and extensibility toward live residency deployment. Preliminary evaluation shows improved localization and diagnostic reasoning compared to baselines.

</details>


### [36] [Step-Audio-R1 Technical Report](https://arxiv.org/abs/2511.15848)
*Fei Tian,Xiangyu Tony Zhang,Yuxin Zhang,Haoyang Zhang,Yuxin Li,Daijiao Liu,Yayue Deng,Donghang Wu,Jun Chen,Liang Zhao,Chengyuan Yao,Hexin Liu,Eng Siong Chng,Xuerui Yang,Xiangyu Zhang,Daxin Jiang,Gang Yu*

Main category: cs.AI

TL;DR: 本论文提出了首个具备有效音频推理能力的模型Step-Audio-R1，通过创新的MGRD框架，解决了音频领域推理难题，推动了多模态深度推理的发展。


<details>
  <summary>Details</summary>
Motivation: 尽管在文本和视觉领域，链式推理模型取得了巨大进展，但音频领域的推理模型却在“多想反而不如少想”的现象中挣扎。作者希望证明音频智能同样能从深度推理中获益，并填补该领域的空白。

Method: 提出了Modality-Grounded Reasoning Distillation（MGRD）框架，使模型能够生成与音频特征高度相关的推理链，并避免脱离音频内容的幻觉推理。通过对现有强大模型进行对比实验，评估模型性能。

Result: Step-Audio-R1在处理语音、环境声和音乐等多元音频推理任务中，超越了Gemini 2.5 Pro，并与当前最强的Gemini 3 Pro表现持平，证明合理的推理机制能极大提升音频理解能力。

Conclusion: Step-Audio-R1首次在音频领域实现了有效的推理能力，表明在合理锚定模态特征下，推理能力具有跨模态的可迁移性。

Abstract: Recent advances in reasoning models have demonstrated remarkable success in text and vision domains through extended chain-of-thought deliberation. However, a perplexing phenomenon persists in audio language models: they consistently perform better with minimal or no reasoning, raising a fundamental question - can audio intelligence truly benefit from deliberate thinking? We introduce Step-Audio-R1, the first audio reasoning model that successfully unlocks reasoning capabilities in the audio domain. Through our proposed Modality-Grounded Reasoning Distillation (MGRD) framework, Step-Audio-R1 learns to generate audio-relevant reasoning chains that genuinely ground themselves in acoustic features rather than hallucinating disconnected deliberations. Our model exhibits strong audio reasoning capabilities, surpassing Gemini 2.5 Pro and achieving performance comparable to the state-of-the-art Gemini 3 Pro across comprehensive audio understanding and reasoning benchmarks spanning speech, environmental sounds, and music. These results demonstrate that reasoning is a transferable capability across modalities when appropriately anchored, transforming extended deliberation from a liability into a powerful asset for audio intelligence. By establishing the first successful audio reasoning model, Step-Audio-R1 opens new pathways toward building truly multimodal reasoning systems that think deeply across all sensory modalities.

</details>


### [37] [Decomposing Theory of Mind: How Emotional Processing Mediates ToM Abilities in LLMs](https://arxiv.org/abs/2511.15895)
*Ivan Chulo,Ananya Joshi*

Main category: cs.AI

TL;DR: 通过激活引导提升ToM能力时，语言模型表现出更强的情感处理功能，而非分析性推理，这是其任务表现提升的主要机制。


<details>
  <summary>Details</summary>
Motivation: 激活引导已证明可增强语言模型的ToM能力，但尚不清楚内部激活发生了什么变化，促使模型输出不同结果。

Method: 训练线性探针分析LLMs内的激活，并将激活引导（CAA）应用于Gemma-3-4B模型，通过比较引导与原始模型在45种认知行为上的激活差异。

Result: 激活引导后，模型在BigToM任务上准确率从32.5%提升到46.7%，并表现出更强的情感内容处理（如感知和评价），而分析性认知（如质疑、收敛性思考）受到抑制。

Conclusion: LLMs在归因信念等ToM任务中的成功更多依赖于情感理解而非分析性推理。

Abstract: Recent work shows activation steering substantially improves language models' Theory of Mind (ToM) (Bortoletto et al. 2024), yet the mechanisms of what changes occur internally that leads to different outputs remains unclear. We propose decomposing ToM in LLMs by comparing steered versus baseline LLMs' activations using linear probes trained on 45 cognitive actions. We applied Contrastive Activation Addition (CAA) steering to Gemma-3-4B and evaluated it on 1,000 BigToM forward belief scenarios (Gandhi et al. 2023), we find improved performance on belief attribution tasks (32.5\% to 46.7\% accuracy) is mediated by activations processing emotional content : emotion perception (+2.23), emotion valuing (+2.20), while suppressing analytical processes: questioning (-0.78), convergent thinking (-1.59). This suggests that successful ToM abilities in LLMs are mediated by emotional understanding, not analytical reasoning.

</details>


### [38] [Thinking, Faithful and Stable: Mitigating Hallucinations in LLMs](https://arxiv.org/abs/2511.15921)
*Chelsea Zou,Yiheng Yao,Basant Khalil*

Main category: cs.AI

TL;DR: 本文提出一种针对LLM多步推理幻觉问题的自纠正框架，利用置信度一致性和熵突变信号，通过强化学习优化推理路径，结果显著提升了答案准确率和推理校准效果。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在多步推理过程中出现幻觉（hallucination）的问题，改善模型推理过程中的不可靠与不忠实表现，而不仅仅关注最终答案正确性。

Method: 采集细粒度的不确定性信号（自评置信度一致性和分词级熵突变），设计复合型奖励函数，通过强化学习策略引导模型生成行为，期间对不合理置信和熵突变进行惩罚，鼓励稳定、准确的推理过程。

Result: 所提出的自纠正框架在实验中提升了最终答案的准确率和推理过程的校准度，消融实验进一步验证了各个信号对整体性能的贡献。

Conclusion: 提出的方法能够有效提升大语言模型多步推理中的最终答案准确性及推理过程的校准度。各组成信号在提升模型性能方面均有贡献。

Abstract: This project develops a self correcting framework for large language models (LLMs) that detects and mitigates hallucinations during multi-step reasoning. Rather than relying solely on final answer correctness, our approach leverages fine grained uncertainty signals: 1) self-assessed confidence alignment, and 2) token-level entropy spikes to detect unreliable and unfaithful reasoning in real time. We design a composite reward function that penalizes unjustified high confidence and entropy spikes, while encouraging stable and accurate reasoning trajectories. These signals guide a reinforcement learning (RL) policy that makes the model more introspective and shapes the model's generation behavior through confidence-aware reward feedback, improving not just outcome correctness but the coherence and faithfulness of their intermediate reasoning steps. Experiments show that our method improves both final answer accuracy and reasoning calibration, with ablations validating the individual contribution of each signal.

</details>


### [39] [Detecting Sleeper Agents in Large Language Models via Semantic Drift Analysis](https://arxiv.org/abs/2511.15992)
*Shahin Zanbaghi,Ryan Rostampour,Farhan Abid,Salim Al Jarmakani*

Main category: cs.AI

TL;DR: 本文提出结合语义漂移和canary检测的双重方法，无需修改模型，可实时并高精度检测LLM后门行为，为AI系统安全部署提供首个可用检测工具。


<details>
  <summary>Details</summary>
Motivation: 目前LLM可能存在后门（“sleeper agents”），这些模型在训练时表现安全，但在特定条件下会展现恶意行为。既往缺少有效的实用检测手段。

Method: 该方法结合了语义漂移分析（利用Sentence-BERT嵌入，测量模型与安全基线的语义偏离）与canary问题基线比对（通过注入有监控作用的问题观察模型回答的一致性）进行检测，无需修改模型。

Result: 在官方dolphin-llama3-8B sleeper agent模型上，检测系统实现了92.5%的准确率、100%的精确率（无误报）和85%的召回率，并且检测速度可实时运行（每询问小于1秒）。

Conclusion: 提出的双重检测系统可以高效、准确地检测LLM中的后门，并在实际部署中为AI安全提供实用解决方案。

Abstract: Large Language Models (LLMs) can be backdoored to exhibit malicious behavior under specific deployment conditions while appearing safe during training a phenomenon known as "sleeper agents." Recent work by Hubinger et al. demonstrated that these backdoors persist through safety training, yet no practical detection methods exist. We present a novel dual-method detection system combining semantic drift analysis with canary baseline comparison to identify backdoored LLMs in real-time. Our approach uses Sentence-BERT embeddings to measure semantic deviation from safe baselines, complemented by injected canary questions that monitor response consistency. Evaluated on the official Cadenza-Labs dolphin-llama3-8B sleeper agent model, our system achieves 92.5% accuracy with 100% precision (zero false positives) and 85% recall. The combined detection method operates in real-time (<1s per query), requires no model modification, and provides the first practical solution to LLM backdoor detection. Our work addresses a critical security gap in AI deployment and demonstrates that embedding-based detection can effectively identify deceptive model behavior without sacrificing deployment efficiency.

</details>


### [40] [CARE-RAG - Clinical Assessment and Reasoning in RAG](https://arxiv.org/abs/2511.15994)
*Deepthi Potluri,Aby Mammen Mathew,Jeffrey B DeWitt,Alexander L. Rasgon,Yide Hao,Junyuan Hong,Ying Ding*

Main category: cs.AI

TL;DR: 针对大语言模型在临床领域检索与推理脱节的问题，提出了能综合评估准确性与推理忠诚度的规范框架，发现仅有检索约束无法完全保证输出安全，需加强推理评估。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在临床问答场景中，虽能获取权威证据，但在合理推理和遵循结构化方案方面仍有不足，亟需系统研究并规范化其推理过程。

Method: 以书面暴露治疗（WET）指南为实验平台，通过专家审核的问题，对模型的检索与推理能力进行评估，并给出包含准确性、一致性和推理忠诚度的新评价框架。

Result: 即使用权威问题和证据，LLM仍存在推理和输出错误。新框架可全方位衡量检索增强推理模型的表现，强调部署安全需对推理进行严格评估。

Conclusion: 仅有权威证据并不能确保大语言模型能正确推理和应用，特别是在临床环境下，需进一步完善其推理评估。

Abstract: Access to the right evidence does not guarantee that large language models (LLMs) will reason with it correctly. This gap between retrieval and reasoning is especially concerning in clinical settings, where outputs must align with structured protocols. We study this gap using Written Exposure Therapy (WET) guidelines as a testbed. In evaluating model responses to curated clinician-vetted questions, we find that errors persist even when authoritative passages are provided. To address this, we propose an evaluation framework that measures accuracy, consistency, and fidelity of reasoning. Our results highlight both the potential and the risks: retrieval-augmented generation (RAG) can constrain outputs, but safe deployment requires assessing reasoning as rigorously as retrieval.

</details>


### [41] [MUSEKG: A Knowledge Graph Over Museum Collections](https://arxiv.org/abs/2511.16014)
*Jinhao Li,Jianzhong Qi,Soyeon Caren Han,Eun-Jung Holden*

Main category: cs.AI

TL;DR: MuseKG整合结构化与非结构化博物馆数据，构建统一的知识图谱，实现高效自然语言查询，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有博物馆信息系统难以整合异构元数据、非结构化文档和多模态藏品信息，影响数据互操作与查询体验，亟需统一且可扩展的知识管理方法。

Method: 提出MuseKG知识图谱框架，将结构化与非结构化数据通过符号与神经方法融合，构建类型化属性图，并支持自然语言查询。对真实博物馆数据进行评测，涵盖多种查询类型，并与当前主流大语言模型及SPARQL方法进行比较。

Result: MuseKG在属性、关系及相关实体的查询任务中均优于大语言模型零样本、少样本和SPARQL基线；系统具备强健性能，有助于大规模数字文化遗产知识整合。

Conclusion: MuseKG通过符号-神经一体化框架，实现了结构化与非结构化博物馆数据的统一，提升了查询性能，并展现了可解释性和可扩展性优势。

Abstract: Digital transformation in the cultural heritage sector has produced vast yet fragmented collections of artefact data. Existing frameworks for museum information systems struggle to integrate heterogeneous metadata, unstructured documents, and multimodal artefacts into a coherent and queryable form. We present MuseKG, an end-to-end knowledge-graph framework that unifies structured and unstructured museum data through symbolic-neural integration. MuseKG constructs a typed property graph linking objects, people, organisations, and visual or textual labels, and supports natural language queries. Evaluations on real museum collections demonstrate robust performance across queries over attributes, relations, and related entities, surpassing large-language-model zero-shot, few-shot and SPARQL prompt baselines. The results highlight the importance of symbolic grounding for interpretable and scalable cultural heritage reasoning, and pave the way for web-scale integration of digital heritage knowledge.

</details>


### [42] [SpellForger: Prompting Custom Spell Properties In-Game using BERT supervised-trained model](https://arxiv.org/abs/2511.16018)
*Emanuel C. Silva,Emily S. M. Salum,Gabriel M. Arantes,Matheus P. Pereira,Vinicius F. Oliveira,Alessandro L. Bicho*

Main category: cs.AI

TL;DR: 本论文提出一种用AI生成自定义法术的游戏方式，通过BERT模型实现玩家创意到竞争性法术的自动转化，为AI作为游戏核心玩法开辟新路径。


<details>
  <summary>Details</summary>
Motivation: 当前AI主要用于游戏内容生成，但少有研究将其作为核心玩法创作工具，本研究旨在探索AI直接参与游戏创作，提高玩家参与度和创意体验。

Method: 采用监督训练的BERT模型解析玩家自然语言描述，并与现有法术模板匹配，自动调整参数，实现多样且平衡的法术生成；游戏开发采用Unity引擎，AI后端用Python实现。

Result: 预计展示一个可实时生成法术原型系统，具备完整玩法循环，突出玩家创造力，并有效证明AI在游戏中的创新应用价值。

Conclusion: 提出并验证了AI作为游戏创意核心工具的可行性，通过玩家自定义法术，实现了游戏内容的高度个性化和创新体验。

Abstract: Introduction: The application of Artificial Intelligence in games has evolved significantly, allowing for dynamic content generation. However, its use as a core gameplay co-creation tool remains underexplored. Objective: This paper proposes SpellForger, a game where players create custom spells by writing natural language prompts, aiming to provide a unique experience of personalization and creativity. Methodology: The system uses a supervisedtrained BERT model to interpret player prompts. This model maps textual descriptions to one of many spell prefabs and balances their parameters (damage, cost, effects) to ensure competitive integrity. The game is developed in the Unity Game Engine, and the AI backend is in Python. Expected Results: We expect to deliver a functional prototype that demonstrates the generation of spells in real time, applied to an engaging gameplay loop, where player creativity is central to the experience, validating the use of AI as a direct gameplay mechanic.

</details>


### [43] [An Aligned Constraint Programming Model For Serial Batch Scheduling With Minimum Batch Size](https://arxiv.org/abs/2511.16045)
*Jorge A. Huertas,Pascal Van Hentenryck*

Main category: cs.AI

TL;DR: 本文针对串行分批调度问题，提出了更紧凑且高效的约束规划模型，极大减少了计算复杂度，在实验中显著优于现有调度方法，特别是在大规模实例上实现了高达25%的效果提升。


<details>
  <summary>Details</summary>
Motivation: 当前关于具有最小批次规模约束的串行分批调度问题的CP模型较少，现有模型由于依赖虚拟批次集合而存在维度灾难和求解复杂度高的问题，亟需更高效、更紧凑的模型应对实际需求，尤其是在半导体制造等领域。

Method: 提出了一种新的约束规划(CP)模型，通过关键对齐参数和直接在同一批次作业序列上推理，避免了传统模型中对预定义虚拟批次集合的依赖。同时，结合专门定制的搜索阶段和增强的约束传播推理水平进行了模型优化。

Result: 在近五千个实例的广泛实验中，所提模型在100作业以下的小中规模实例上表现优异，在大规模实例（500作业、10族、10台设备）上的最优解优于现有方法，提升高达25%。

Conclusion: 新提出的约束规划(CP)模型在小中规模实例以及大规模实例中都明显优于现有方法，能够找到更优的调度方案。

Abstract: In serial batch (s-batch) scheduling, jobs from similar families are grouped into batches and processed sequentially to avoid repetitive setups that are required when processing consecutive jobs of different families. Despite its large success in scheduling, only three Constraint Programming (CP) models have been proposed for this problem considering minimum batch sizes, which is a common requirement in many practical settings, including the ion implantation area in semiconductor manufacturing. These existing CP models rely on a predefined virtual set of possible batches that suffers from the curse of dimensionality and adds complexity to the problem. This paper proposes a novel CP model that does not rely on this virtual set. Instead, it uses key alignment parameters that allow it to reason directly on the sequences of same-family jobs scheduled on the machines, resulting in a more compact formulation. This new model is further improved by exploiting the problem's structure with tailored search phases and strengthened inference levels of the constraint propagators. The extensive computational experiments on nearly five thousand instances compare the proposed models against existing methods in the literature, including mixed-integer programming formulations, tabu search meta-heuristics, and CP approaches. The results demonstrate the superiority of the proposed models on small-to-medium instances with up to 100 jobs, and their ability to find solutions up to 25\% better than the ones produces by existing methods on large-scale instances with up to 500 jobs, 10 families, and 10 machines.

</details>


### [44] [Artificial Intelligence and Accounting Research: A Framework and Agenda](https://arxiv.org/abs/2511.16055)
*Theophanis C. Stratopoulos,Victor Xiaoqi Wang*

Main category: cs.AI

TL;DR: 本文提出并以二维框架审视AI在会计研究中的影响，揭示生成式AI既提升研究工具，又加剧学术竞争。未来应改革博士生培养，加强AI能力与人类独特优势。


<details>
  <summary>Details</summary>
Motivation: AI技术为会计领域带来新机遇与竞争威胁，学者如何进行战略定位、发挥专业优势，并在AI普及背景下提升研究贡献成为迫切课题。同时，教育体系需应对AI对人才培养的挑战。

Method: 本文提出了一个二维框架，将AI与会计研究分为以会计为中心和以AI为中心，以及基于AI方法和传统方法。通过该框架，分析IJAIS特刊及顶级会计期刊中AI与会计主题的论文，进而探讨学者的战略定位与合作方式，并比较人类与AI在完整研究流程中的能力对比。

Result: 论文识别了当前AI与会计交叉领域的研究格局，指出人类学者的独特价值在于高阶判断与理论深度。AI普及促使研究流程变革，也提出培养AI素养与高阶能力的博士教育改革建议。

Conclusion: 人工智能（AI），尤其是生成式AI（GenAI）和大型语言模型（LLM），正在深刻改变会计研究领域。GenAI虽然提升了研究能力，但也加剧了竞争，使学者在人类判断、创造力和理论深度方面保持优势变得更为重要并需在博士教育中改革培养比人工智能更有优势的能力。

Abstract: Recent advances in artificial intelligence, particularly generative AI (GenAI) and large language models (LLMs), are fundamentally transforming accounting research, creating both opportunities and competitive threats for scholars. This paper proposes a framework that classifies AI-accounting research along two dimensions: research focus (accounting-centric versus AI-centric) and methodological approach (AI-based versus traditional methods). We apply this framework to papers from the IJAIS special issue and recent AI-accounting research published in leading accounting journals to map existing studies and identify research opportunities. Using this same framework, we analyze how accounting researchers can leverage their expertise through strategic positioning and collaboration, revealing where accounting scholars' strengths create the most value. We further examine how GenAI and LLMs transform the research process itself, comparing the capabilities of human researchers and AI agents across the entire research workflow. This analysis reveals that while GenAI democratizes certain research capabilities, it simultaneously intensifies competition by raising expectations for higher-order contributions where human judgment, creativity, and theoretical depth remain valuable. These shifts call for reforming doctoral education to cultivate comparative advantages while building AI fluency.

</details>


### [45] [OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe](https://arxiv.org/abs/2511.16334)
*Kaichen Zhang,Keming Wu,Zuhao Yang,Kairui Hu,Bin Wang,Ziwei Liu,Xingxuan Li,Lidong Bing*

Main category: cs.AI

TL;DR: 作者提出了一个透明可复现的多模态推理训练方法OpenMMReasoner，两阶段策略实现了比主流基线高11.6%的性能提升，全部成果已开源，强调数据和训练设计对推理能力的决定性作用。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大模型推理领域虽然技术进步显著，但缺乏透明、可复现的数据整理和训练方法，严重阻碍了可扩展性研究。作者旨在解决该问题并验证数据质量与训练设计对模型性能的关键作用。

Method: 采用两阶段训练策略：第一阶段通过严格验证构建的870K规模冷启动SFT训练集进行有监督微调，第二阶段利用包含74K样本的RL训练集进行强化学习，进一步提升模型推理能力和稳定性。

Result: 提出了OpenMMReasoner全流程公开，经过大规模评测证明其在多模态推理任务上显著超越现有强基线模型，并开源了全部代码、数据和流程，为社区提供全面参考。

Conclusion: OpenMMReasoner取得了比Qwen2.5-VL-7B-Instruct基线高出11.6%的性能提升，在九个多模态推理基准上表现优异，为多模态大模型研究提供了可复现和透明的方法论。

Abstract: Recent advancements in large reasoning models have fueled growing interest in extending such capabilities to multimodal domains. However, despite notable progress in visual reasoning, the lack of transparent and reproducible data curation and training strategies remains a major barrier to scalable research. In this work, we introduce OpenMMReasoner, a fully transparent two-stage recipe for multimodal reasoning spanning supervised fine-tuning (SFT) and reinforcement learning (RL). In the SFT stage, we construct an 874K-sample cold-start dataset with rigorous step-by-step validation, providing a strong foundation for reasoning capabilities. The subsequent RL stage leverages a 74K-sample dataset across diverse domains to further sharpen and stabilize these abilities, resulting in a more robust and efficient learning process. Extensive evaluations demonstrate that our training recipe not only surpasses strong baselines but also highlights the critical role of data quality and training design in shaping multimodal reasoning performance. Notably, our method achieves a 11.6% improvement over the Qwen2.5-VL-7B-Instruct baseline across nine multimodal reasoning benchmarks, establishing a solid empirical foundation for future large-scale multimodal reasoning research. We open-sourced all our codes, pipeline, and data at https://github.com/EvolvingLMMs-Lab/OpenMMReasoner.

</details>


### [46] [TOFA: Training-Free One-Shot Federated Adaptation for Vision-Language Models](https://arxiv.org/abs/2511.16423)
*Li Zhang,Zhongxuan Han,XiaoHua Feng,Jiaming Zhang,Yuyuan Li,Linbo Jiang,Jianan Lin,Chaochao Chen*

Main category: cs.AI

TL;DR: 提出TOFA：一种无需训练的一次性联邦视觉-语言模型适应方法，不增加沟通和计算负担，通过充分利用多模态信息和自适应融合机制，在多个数据集上有效提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 受限于现有联邦视觉-语言模型自适应方法通信高度频繁、易受攻击且额外训练资源负担重，作者希望通过无训练、单轮通信的方法，实现高效、安全且轻量级的模型自适应，缓解数据异质性等实际痛点。

Method: 设计了一个无需额外训练资源的TOFA框架，通过视觉管道的分层贝叶斯模型和文本管道的全局对齐机制，结合自适应权重校准，实现多模态信息的充分利用和对数据异质性的有效处理。

Result: 实验显示，TOFA能够显著提升联邦场景下视觉-语言模型的自适应能力和任务表现，在多个数据集上实现了高效准确的任务迁移，无需客户端或服务器的额外训练。

Conclusion: 提出的TOFA方法在9个数据集和多种联邦学习场景中能够高效地实现无训练、轻量级的视觉-语言模型自适应，表现出了良好的效果。

Abstract: Efficient and lightweight adaptation of pre-trained Vision-Language Models (VLMs) to downstream tasks through collaborative interactions between local clients and a central server is a rapidly emerging research topic in federated learning. Existing adaptation algorithms are typically trained iteratively, which incur significant communication costs and increase the susceptibility to potential attacks. Motivated by the one-shot federated training techniques that reduce client-server exchanges to a single round, developing a lightweight one-shot federated VLM adaptation method to alleviate these issues is particularly attractive. However, current one-shot approaches face certain challenges in adapting VLMs within federated settings: (1) insufficient exploitation of the rich multimodal information inherent in VLMs; (2) lack of specialized adaptation strategies to systematically handle the severe data heterogeneity; and (3) requiring additional training resource of clients or server. To bridge these gaps, we propose a novel Training-free One-shot Federated Adaptation framework for VLMs, named TOFA. To fully leverage the generalizable multimodal features in pre-trained VLMs, TOFA employs both visual and textual pipelines to extract task-relevant representations. In the visual pipeline, a hierarchical Bayesian model learns personalized, class-specific prototype distributions. For the textual pipeline, TOFA evaluates and globally aligns the generated local text prompts for robustness. An adaptive weight calibration mechanism is also introduced to combine predictions from both modalities, balancing personalization and robustness to handle data heterogeneity. Our method is training-free, not relying on additional training resources on either the client or server side. Extensive experiments across 9 datasets in various federated settings demonstrate the effectiveness of the proposed TOFA method.

</details>


### [47] [SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent](https://arxiv.org/abs/2511.16108)
*Shiyi Cao,Dacheng Li,Fangzhou Zhao,Shuo Yuan,Sumanth R. Hegde,Connor Chen,Charlie Ruan,Tyler Griggs,Shu Liu,Eric Tang,Richard Liaw,Philipp Moritz,Matei Zaharia,Joseph E. Gonzalez,Ion Stoica*

Main category: cs.AI

TL;DR: 该论文提出SkyRL-Agent框架，提高了智能体训练效率和灵活性，并通过工具和异步优化训练了高表现的SA-SWE-32B智能体，兼具低成本与广泛泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为解决现有智能体训练效率低下、工具集成困难及复用性不足等问题，提出一个更高效并易于扩展的训练与评估框架。

Method: 提出异步调度管道与AST搜索工具结合的训练方案，充分利用现有RL训练框架，并对训练流程效率进行优化提升。

Result: SA-SWE-32B通过SkyRL-Agent获得39.4%的Pass@1（远超起点模型），成本减少2倍以上，并表现出优良的跨任务泛化能力，SkyRL-Agent框架被证实在多类任务和训练后端中均具良好适应性。

Conclusion: SkyRL-Agent框架实现了高效的多轮、长时序智能体训练和评估，优化了分布调度及工具集成，并具备良好的兼容性与可扩展性，推动了SA-SWE-32B在软件工程和其它智能体任务上的提升。

Abstract: We introduce SkyRL-Agent, a framework for efficient, multi-turn, long-horizon agent training and evaluation. It provides efficient asynchronous dispatching, lightweight tool integration, and flexible backend interoperability, enabling seamless use with existing RL frameworks such as SkyRL-train, VeRL, and Tinker.
  Using SkyRL-Agent, we train SA-SWE-32B, a software engineering agent trained from Qwen3-32B (24.4% Pass@1) purely with reinforcement learning. We introduce two key components: an optimized asynchronous pipeline dispatcher that achieves a 1.55x speedup over naive asynchronous batching, and a tool-enhanced training recipe leveraging an AST-based search tool to facilitate code navigation, boost rollout Pass@K, and improve training efficiency. Together, these optimizations enable SA-SWE-32B to reach 39.4% Pass@1 on SWE-Bench Verified with more than 2x cost reduction compared to prior models reaching similar performance. Despite being trained solely on SWE tasks, SA-SWE-32B generalizes effectively to other agentic tasks, including Terminal-Bench, BrowseComp-Plus, and WebArena. We further demonstrate SkyRL-Agent's extensibility through case studies on deep research, computer use, and memory agents, each trained using a different training backend.

</details>


### [48] [D-GARA: A Dynamic Benchmarking Framework for GUI Agent Robustness in Real-World Anomalies](https://arxiv.org/abs/2511.16590)
*Sen Chen,Tong Zhao,Yi Bin,Fei Ma,Wenqi Shao,Zheng Wang*

Main category: cs.AI

TL;DR: 该文提出了D-GARA动态基准框架，通过引入Android应用中的真实异常，评测智能体的鲁棒性。实验证明，在异常环境下现有智能体性能下降，强调鲁棒性学习的必要性。D-GARA框架可灵活扩展，促进更广泛的研究。


<details>
  <summary>Details</summary>
Motivation: 现有的GUI智能体训练与评测数据集过于理想化，未能反映实际应用中多变且充满异常的复杂情况，因此亟需有能反映真实世界异常事件影响的评测框架。

Method: 提出了D-GARA动态基准框架，通过在常用Android应用中嵌入、注释真实世界中的常见异常（如权限弹窗、电池警告、更新提示），构建用于评估智能体鲁棒性的动态环境。

Result: 实验表明，在包含多种异常的真实环境下，现有优秀的GUI智能体性能显著降低，凸显鲁棒性训练的重要性。D-GARA框架具有高度可扩展性和模块化，可根据需求扩展新的任务和异常类型。

Conclusion: 现有的GUI智能体在面对真实环境中出现的异常情况时，表现出明显的性能下降，说明提升其鲁棒性十分必要。

Abstract: Developing intelligent agents capable of operating a wide range of Graphical User Interfaces (GUIs) with human-level proficiency is a key milestone on the path toward Artificial General Intelligence. While most existing datasets and benchmarks for training and evaluating GUI agents are static and idealized, failing to reflect the complexity and unpredictability of real-world environments, particularly the presence of anomalies. To bridge this research gap, we propose D-GARA, a dynamic benchmarking framework, to evaluate Android GUI agent robustness in real-world anomalies. D-GARA introduces a diverse set of real-world anomalies that GUI agents commonly face in practice, including interruptions such as permission dialogs, battery warnings, and update prompts. Based on D-GARA framework, we construct and annotate a benchmark featuring commonly used Android applications with embedded anomalies to support broader community research. Comprehensive experiments and results demonstrate substantial performance degradation in state-of-the-art GUI agents when exposed to anomaly-rich environments, highlighting the need for robustness-aware learning. D-GARA is modular and extensible, supporting the seamless integration of new tasks, anomaly types, and interaction scenarios to meet specific evaluation goals.

</details>


### [49] [Multidimensional Rubric-oriented Reward Model Learning via Geometric Projection Reference Constraints](https://arxiv.org/abs/2511.16139)
*Yongnan Jin,Xurui Li,Feng Cao,Liucun Gao,Juanjuan Yao*

Main category: cs.AI

TL;DR: 该文提出了MR-RML多维奖励对齐框架，通过医学标准嵌入、多维奖励及几何约束，显著提升医疗大模型在权威基准上的表现，达到开源最高水平。


<details>
  <summary>Details</summary>
Motivation: 大模型在临床应用中面临三大不足：静态评测与动态认知需求脱节、适应多源/演化医疗标准困难、传统奖励模型无法捕捉复杂医疗质量标准。亟需更精准对齐临床真实需求的模型训练方案。

Method: 1. 构建“维度-场景-学科”三维医疗标准体系，并将其嵌入数据生成与训练优化流程。2. 独立建模多维奖励模型，将多维评价标准内化为奖励函数，提升模型一致性与评估效率。3. 利用几何投影参考约束，将医学认知逻辑转化为数学正则，指导合成数据训练并优化评分梯度。

Result: 在Healthbench医疗基准上，MR-RML模型对基础大模型Qwen-32B提升表现：全子集提升45%，难子集提升85%；以62.7分（全子集）、44.7分（难子集）达到开源SOTA，并优于大多数闭源模型。

Conclusion: 提出的方法MR-RML在医疗领域大幅提升了基础大模型的临床表现，并在权威医疗基准测试中取得了领先结果，超过了开源及大部分闭源模型。

Abstract: The integration of large language models (LLMs) into medical practice holds transformative potential, yet their real-world clinical utility remains limited by critical alignment challenges: (1) a disconnect between static evaluation benchmarks and dynamic clinical cognitive needs, (2) difficulties in adapting to evolving, multi-source medical standards, and (3) the inability of conventional reward models to capture nuanced, multi-dimensional medical quality criteria. To address these gaps, we propose MR-RML (Multidimensional Rubric-oriented Reward Model Learning) via GPRC (Geometric Projection Reference Constraints), a novel alignment framework that integrates medical standards into a structured "Dimensions-Scenarios-Disciplines" matrix to guide data generation and model optimization. MR-RML introduces three core innovations: (1) a "Dimensions-Scenarios-Disciplines" medical standard system that embeds domain standards into the full training pipeline; (2) an independent multi-dimensional reward model that decomposes evaluation criteria, shifting from real-time rubric-based scoring to internalized reward modeling for improved consistency and cost-efficiency; (3) geometric projection reference constraints that transform medical cognitive logic into mathematical regularization, aligning scoring gradients with clinical reasoning and enabling synthetic data-driven training. Through extensive evaluations on the authoritative medical benchmark Healthbench, our method yields substantial performance gains over the base LLM Qwen-32B (45% on the full subset and 85% on Hard subset, respectively). It achieves a SOTA among open-source LLMs with scores of 62.7 (full subset) and 44.7 (hard subset), while also outperforming the majority of closed-source models.

</details>


### [50] [FOOTPASS: A Multi-Modal Multi-Agent Tactical Context Dataset for Play-by-Play Action Spotting in Soccer Broadcast Videos](https://arxiv.org/abs/2511.16183)
*Jeremie Ochin,Raphael Chekroun,Bogdan Stanciulescu,Sotiris Manitsaris*

Main category: cs.AI

TL;DR: 为促进足球比赛视频理解与自动化数据生成，作者提出了首个支持整场多球员战术场景逐球动作检测的数据集FOOTPASS，有助于发展融合视觉与战术知识的新方法，为体育数据分析奠定基础。


<details>
  <summary>Details</summary>
Motivation: 当前的足球视频理解中，如STAD和MOT等任务需要标注结构化事件序列以支持足球分析。但现有动作识别方法不足以自动生成可靠的逐球数据，且通常只能辅助人工标注。然而，战术建模、轨迹预测和性能分析领域已取得进展，这些都依赖于比赛状态与逐球数据。因此，融合战术知识与计算机视觉预测可以推动更自动化和可靠的数据提取。

Method: 介绍了一套新数据集FOOTPASS：一个用于整场足球比赛逐球动作检测的多模态、多主体战术数据集。该数据集支持开发结合视觉任务输出（如跟踪、识别）和长期战术知识的球员动作检测方法，以生成高可靠性逐球数据流。

Result: FOOTPASS成为首个在多模态、多球员战术场景下，针对整场比赛动作检测的基准，有助于发展更可靠、自动化的逐球数据提取方法，并为数据驱动的体育分析提供关键输入。

Conclusion: 结合视觉输出与战术知识实现自动化、可靠的整场足球比赛动作检测成为可能。该数据集推动了足球视频理解领域逐球数据自动化生成的发展，并支持更深入的数据分析与战术评估。

Abstract: Soccer video understanding has motivated the creation of datasets for tasks such as temporal action localization, spatiotemporal action detection (STAD), or multiobject tracking (MOT). The annotation of structured sequences of events (who does what, when, and where) used for soccer analytics requires a holistic approach that integrates both STAD and MOT. However, current action recognition methods remain insufficient for constructing reliable play-by-play data and are typically used to assist rather than fully automate annotation. Parallel research has advanced tactical modeling, trajectory forecasting, and performance analysis, all grounded in game-state and play-by-play data. This motivates leveraging tactical knowledge as a prior to support computer-vision-based predictions, enabling more automated and reliable extraction of play-by-play data. We introduce Footovision Play-by-Play Action Spotting in Soccer Dataset (FOOTPASS), the first benchmark for play-by-play action spotting over entire soccer matches in a multi-modal, multi-agent tactical context. It enables the development of methods for player-centric action spotting that exploit both outputs from computer-vision tasks (e.g., tracking, identification) and prior knowledge of soccer, including its tactical regularities over long time horizons, to generate reliable play-by-play data streams. These streams form an essential input for data-driven sports analytics.

</details>


### [51] [From Performance to Understanding: A Vision for Explainable Automated Algorithm Design](https://arxiv.org/abs/2511.16201)
*Niki van Stein,Anna V. Kononova,Thomas Bäck*

Main category: cs.AI

TL;DR: 本文呼吁可解释的自动化算法设计，通过结合LLM驱动发现、可解释基准测试和问题结构分析，促进更高效和可复用的算法开发，推动领域向理论与实用并重方向发展。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的自动化算法设计主要关注性能却缺乏可解释性，难以理解算法为何有效、哪些部分关键以及设计选择与问题结构的关系，需要更可解释和系统化的方法促进理论进步。

Method: 提出了以三大支柱为基础的愿景：1) 使用大语言模型发掘算法变体；2) 可解释的基准测试，将性能归因于算法组件和超参数；3) 问题类别描述符，将算法行为与问题结构关联。通过此闭环，实现发现、解释与泛化的相互促进。

Result: 结合自动化与理解的可解释自动化算法设计将推动领域由盲目搜索转向可解释、面向特定问题类别的算法设计，提高研究效率、产生可复用理论。

Conclusion: 作者认为下一个重大突破不再是单纯依赖自动化，而是需要结合系统性基准测试，实现可解释的自动化算法设计，以推动领域进步并提炼可复用的科学见解。

Abstract: Automated algorithm design is entering a new phase: Large Language Models can now generate full optimisation (meta)heuristics, explore vast design spaces and adapt through iterative feedback. Yet this rapid progress is largely performance-driven and opaque. Current LLM-based approaches rarely reveal why a generated algorithm works, which components matter or how design choices relate to underlying problem structures. This paper argues that the next breakthrough will come not from more automation, but from coupling automation with understanding from systematic benchmarking. We outline a vision for explainable automated algorithm design, built on three pillars: (i) LLM-driven discovery of algorithmic variants, (ii) explainable benchmarking that attributes performance to components and hyperparameters and (iii) problem-class descriptors that connect algorithm behaviour to landscape structure. Together, these elements form a closed knowledge loop in which discovery, explanation and generalisation reinforce each other. We argue that this integration will shift the field from blind search to interpretable, class-specific algorithm design, accelerating progress while producing reusable scientific insight into when and why optimisation strategies succeed.

</details>


### [52] [ChemLabs on ChemO: A Multi-Agent System for Multimodal Reasoning on IChO 2025](https://arxiv.org/abs/2511.16205)
*Xu Qiang,Shengyuan Bai,Leqing Chen,Zijing Liu,Yu Li*

Main category: cs.AI

TL;DR: 论文提出了国际化学奥赛题库ChemO和一套自动化评测、分层多智能体解题系统，使AI在化学复杂推理任务中超越了顶尖人类水平。


<details>
  <summary>Details</summary>
Motivation: 弥补化学领域在奥赛级AI推理基准上的空白，解决化学多模态符号语言带来的自动评测与推理难题。

Method: 研发了Assessment-Equivalent Reformulation (AER)和Structured Visual Enhancement (SVE)两大机制，将化学视觉输出题转换为可自动化评测格式，并分离模型感知与推理能力，并提出分层多智能体框架ChemLabs进行答题。

Result: 结合SVE机制和多智能体系统，在ChemO基准上获得93.6/100分，显著优于当前多模态模型，达到并超过人类金牌水平。

Conclusion: 提出了ChemO化学奥赛基准，并通过多智能体系统在该基准上取得了突破性成绩，性能超越人类金牌线。

Abstract: Olympiad-level benchmarks in mathematics and physics are crucial testbeds for advanced AI reasoning, but chemistry, with its unique multimodal symbolic language, has remained an open challenge. We introduce ChemO, a new benchmark built from the International Chemistry Olympiad (IChO) 2025. ChemO features two key innovations for automated assessment: Assessment-Equivalent Reformulation (AER), which converts problems requiring visual outputs (e.g., drawing molecules) into computationally tractable formats, and Structured Visual Enhancement (SVE), a diagnostic mechanism to disentangle a model's visual perception capabilities from its core chemical reasoning. To tackle this benchmark, we propose ChemLabs, a hierarchical multi-agent framework that mimics human expert collaboration through specialized agents for problem decomposition, perception, reasoning, and auditing. Experiments on state-of-the-art multimodal models demonstrate that combining SVE with our multi-agent system yields dramatic performance gains. Our top configuration achieves a score of 93.6 out of 100, surpassing an estimated human gold medal threshold and establishing a new state-of-the-art in automated chemical problem-solving. ChemO Dataset: https://huggingface.co/datasets/IDEA-AI4SCI/ChemO

</details>


### [53] [FlipVQA-Miner: Cross-Page Visual Question-Answer Mining from Textbooks](https://arxiv.org/abs/2511.16216)
*Zhen Hao Wong,Jingwen Deng,Hao Liang,Runming He,Chengyu Shen,Wentao Zhang*

Main category: cs.AI

TL;DR: 本论文提出了一种自动管道，通过版面感知OCR和LLM语义解析，从教材PDF高效提取真实QA/VQA样本，有效提升大模型训练数据质量和规模，并开源相关工具。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs训练依赖的高质量人工监督数据极其昂贵，现有数据多采自合成样本，易产生幻觉且多样性有限。教材和习题包含大量高质量QA内容，但由于PDF格式处理难度高，尚未被充分利用。

Method: 通过结合版面感知OCR与大语言模型语义解析，自动从教材和习题材料PDF中抽取具有结构和语义对齐的QA/VQA对。

Result: 在多种教育文档测试下，提出的自动管道能够高效、准确地抽取低噪声的QA和VQA监督样本，明显优于依赖合成数据的现有方案。

Conclusion: 提出的方法能够自动高质量地从教育类文档中抽取QA和VQA监督数据，为大模型训练提供了真实且低噪声的数据来源。

Abstract: The development of Large Language Models (LLMs) increasingly depends on high-quality supervised data, yet existing instruction-tuning and RL datasets remain costly to curate and often rely on synthetic samples that introduce hallucination and limited diversity. At the same time, textbooks and exercise materials contain abundant, high-quality human-authored Question-Answer(QA) content that remains underexploited due to the difficulty of transforming raw PDFs into AI-ready supervision. Although modern OCR and vision-language models can accurately parse document structure, their outputs lack the semantic alignment required for training. We propose an automated pipeline that extracts well-formed QA and visual-QA (VQA) pairs from educational documents by combining layout-aware OCR with LLM-based semantic parsing. Experiments across diverse document types show that the method produces accurate, aligned, and low-noise QA/VQA pairs. This approach enables scalable use of real-world educational content and provides a practical alternative to synthetic data generation for improving reasoning-oriented LLM training. All code and data-processing pipelines are open-sourced at https://github.com/OpenDCAI/DataFlow.

</details>


### [54] [Revisiting Fairness-aware Interactive Recommendation: Item Lifecycle as a Control Knob](https://arxiv.org/abs/2511.16248)
*Yun Lu,Xiaoyu Shi,Hong Xie,Chongjun Xia,Zhenhui Gong,Mingsheng Shang*

Main category: cs.AI

TL;DR: 针对推荐系统物品生命周期三阶段的新发现，提出结合生命周期分析的分层强化学习框架LHRL，有效平衡推荐准确率与公平性，实证获得显著增益，同时具备良好模型兼容与推广能力。


<details>
  <summary>Details</summary>
Motivation: 短视频平台物品生命周期呈现出与传统模型不同的三阶段变化，对推荐系统公平性与用户体验有重要影响；当前方法未能有效利用生命周期特征调和公平与准确性。

Method: 提出LHRL（生命周期感知分层强化学习）框架，包含PhaseFormer（基于STL分解与注意力机制的轻量化编码器实现相位检测）及双层HRL智能体（高层策略施加相位感知公平约束，低层策略优化即时用户参与度）。在真实推荐数据集上进行实验验证。

Result: LHRL对多个实际推荐数据集均有较显著的公平和用户参与度提升，生命周期奖励机制嵌入现有RL模型均能提升推荐效果，展现良好的实用性和推广性。

Conclusion: LHRL框架能够显著提升推荐系统中的公平性和用户参与度，并且生命周期感知奖励机制具备良好的通用性，能为现有多种强化学习推荐模型带来持续性能增强。

Abstract: This paper revisits fairness-aware interactive recommendation (e.g., TikTok, KuaiShou) by introducing a novel control knob, i.e., the lifecycle of items. We make threefold contributions. First, we conduct a comprehensive empirical analysis and uncover that item lifecycles in short-video platforms follow a compressed three-phase pattern, i.e., rapid growth, transient stability, and sharp decay, which significantly deviates from the classical four-stage model (introduction, growth, maturity, decline). Second, we introduce LHRL, a lifecycle-aware hierarchical reinforcement learning framework that dynamically harmonizes fairness and accuracy by leveraging phase-specific exposure dynamics. LHRL consists of two key components: (1) PhaseFormer, a lightweight encoder combining STL decomposition and attention mechanisms for robust phase detection; (2) a two-level HRL agent, where the high-level policy imposes phase-aware fairness constraints, and the low-level policy optimizes immediate user engagement. This decoupled optimization allows for effective reconciliation between long-term equity and short-term utility. Third, experiments on multiple real-world interactive recommendation datasets demonstrate that LHRL significantly improves both fairness and user engagement. Furthermore, the integration of lifecycle-aware rewards into existing RL-based models consistently yields performance gains, highlighting the generalizability and practical value of our approach.

</details>


### [55] [MuISQA: Multi-Intent Retrieval-Augmented Generation for Scientific Question Answering](https://arxiv.org/abs/2511.16283)
*Zhiyuan Li,Haisheng Yu,Guangchuan Guo,Nan Zhou,Jiajun Zhang*

Main category: cs.AI

TL;DR: 论文构建了多意图科学问答基准，并提出通过意图感知检索架构使多意图检索的准确率和证据覆盖明显提升，实验上均优于常规RAG方法。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统多面向单一意图，导致证据覆盖不全。复杂科学问题往往需多跳推理及从多源提取证据，故需提升多意图问题的证据处理能力。

Method: 利用大型语言模型（LLMs）假设潜在答案、分解为意图相关的查询，并分别进行证据检索。检索到的片段通过RRF方法进行聚合和重排序，以均衡多意图覆盖面，减少冗余。

Result: 在MuISQA基准和其他通用RAG数据集上的实验结果显示，该方法在检索准确率和证据覆盖面方面优于传统方法。

Conclusion: 该论文提出了一种意图感知的检索框架，有效提升了多意图科学问题回答任务中的检索准确率和证据覆盖面。

Abstract: Complex scientific questions often entail multiple intents, such as identifying gene mutations and linking them to related diseases. These tasks require evidence from diverse sources and multi-hop reasoning, while conventional retrieval-augmented generation (RAG) systems are usually single-intent oriented, leading to incomplete evidence coverage. To assess this limitation, we introduce the Multi-Intent Scientific Question Answering (MuISQA) benchmark, which is designed to evaluate RAG systems on heterogeneous evidence coverage across sub-questions. In addition, we propose an intent-aware retrieval framework that leverages large language models (LLMs) to hypothesize potential answers, decompose them into intent-specific queries, and retrieve supporting passages for each underlying intent. The retrieved fragments are then aggregated and re-ranked via Reciprocal Rank Fusion (RRF) to balance coverage across diverse intents while reducing redundancy. Experiments on both MuISQA benchmark and other general RAG datasets demonstrate that our method consistently outperforms conventional approaches, particularly in retrieval accuracy and evidence coverage.

</details>


### [56] [Reducing Instability in Synthetic Data Evaluation with a Super-Metric in MalDataGen](https://arxiv.org/abs/2511.16373)
*Anna Luiza Gomes da Silva,Diego Kreutz,Angelo Diniz,Rodrigo Mansilha,Celso Nobre da Fonseca*

Main category: cs.AI

TL;DR: 本文提出并验证了Super-Metric，一种针对Android恶意软件合成数据质量评估的新指标，其综合多种维度和指标后表现出更优的稳定性与评估准确性。


<details>
  <summary>Details</summary>
Motivation: 现有合成数据质量评估指标在Android恶意软件领域存在不稳定与缺乏标准化的问题，急需一种更稳定、一致的评估方法。

Method: 将八项指标、涵盖四个保真度维度，整合为一个加权分数的Super-Metric，并集成到MalDataGen平台。通过十种生成模型和五个平衡数据集的实验进行验证。

Result: Super-Metric表现出比传统指标更高的稳定性与一致性，且与实际分类器表现具有更强相关性。

Conclusion: Super-Metric在Android恶意软件领域中评估合成数据质量方面，比传统指标更加稳定和一致，有更强的分类器性能相关性。

Abstract: Evaluating the quality of synthetic data remains a persistent challenge in the Android malware domain due to instability and the lack of standardization among existing metrics. This work integrates into MalDataGen a Super-Metric that aggregates eight metrics across four fidelity dimensions, producing a single weighted score. Experiments involving ten generative models and five balanced datasets demonstrate that the Super-Metric is more stable and consistent than traditional metrics, exhibiting stronger correlations with the actual performance of classifiers.

</details>


### [57] [CorrectHDL: Agentic HDL Design with LLMs Leveraging High-Level Synthesis as Reference](https://arxiv.org/abs/2511.16395)
*Kangwei Xu,Grace Li Zhang,Ulf Schlichtmann,Bing Li*

Main category: cs.AI

TL;DR: CorrectHDL结合LLM生成能力与传统验证流程，有效提升自动化HDL设计的质量和电路效率，解决了LLM生成HDL的功能错误问题。


<details>
  <summary>Details</summary>
Motivation: LLM生成HDL代码时易出现幻想，导致功能错误，需提升自动化生成电路的正确性和效率。

Method: 将C/C++程序输入给大型语言模型生成HDL代码，通过RAG机制修正语法错误，再用传统高层综合工具生成HLS参考设计，对比仿真行为，迭代修正LLM生成的电路，最终保证功能正确性。

Result: 生成的电路在面积和功耗效率上大大优于传统HLS工具，且功能正确性得到保证，达到了接近人工设计的质量。

Conclusion: 提出的CorrectHDL框架能在保证功能正确性的同时，显著提升电路的面积和功耗效率，结果接近人类工程师设计的电路。

Abstract: Large Language Models (LLMs) have demonstrated remarkable potential in hardware front-end design using hardware description languages (HDLs). However, their inherent tendency toward hallucination often introduces functional errors into the generated HDL designs. To address this issue, we propose the framework CorrectHDL that leverages high-level synthesis (HLS) results as functional references to correct potential errors in LLM-generated HDL designs.The input to the proposed framework is a C/C++ program that specifies the target circuit's functionality. The program is provided to an LLM to directly generate an HDL design, whose syntax errors are repaired using a Retrieval-Augmented Generation (RAG) mechanism. The functional correctness of the LLM-generated circuit is iteratively improved by comparing its simulated behavior with an HLS reference design produced by conventional HLS tools, which ensures the functional correctness of the result but can lead to suboptimal area and power efficiency. Experimental results demonstrate that circuits generated by the proposed framework achieve significantly better area and power efficiency than conventional HLS designs and approach the quality of human-engineered circuits. Meanwhile, the correctness of the resulting HDL implementation is maintained, highlighting the effectiveness and potential of agentic HDL design leveraging the generative capabilities of LLMs and the rigor of traditional correctness-driven IC design flows.

</details>


### [58] [Pharos-ESG: A Framework for Multimodal Parsing, Contextual Narration, and Hierarchical Labeling of ESG Report](https://arxiv.org/abs/2511.16417)
*Yan Chen,Yu Zou,Jialei Zeng,Haoran You,Xiaorui Zhou,Aixi Zhong*

Main category: cs.AI

TL;DR: 该文提出Pharos-ESG框架，能高效解析结构复杂的ESG报告，优于现有文档解析方法，并发布了首个跨区域大规模ESG报告数据集Aurora-ESG。


<details>
  <summary>Details</summary>
Motivation: ESG报告因布局混乱和内容层级隐含，难以大规模、高质量地解析，亟需自动化、高精度框架以服务金融治理分析。

Method: 该研究提出Pharos-ESG框架，包含多模态解析、上下文叙述以及层级标注等模块，结合版面流阅读顺序建模、目录锚点引导的层级切分与多模态信息自然语言整合。

Result: Pharos-ESG在标注基准数据上的解析效果明显优于当前主流专用文档系统与通用多模态模型。同时，发布了覆盖中美港的首个大规模ESG报告数据集Aurora-ESG，推动金融治理与决策中的ESG应用。

Conclusion: Pharos-ESG可以有效地将结构混乱的ESG报告转化为结构化表达形式，并在各项基准测试中优于现有的文档解析和多模态模型。

Abstract: Environmental, Social, and Governance (ESG) principles are reshaping the foundations of global financial gover- nance, transforming capital allocation architectures, regu- latory frameworks, and systemic risk coordination mecha- nisms. However, as the core medium for assessing corpo- rate ESG performance, the ESG reports present significant challenges for large-scale understanding, due to chaotic read- ing order from slide-like irregular layouts and implicit hier- archies arising from lengthy, weakly structured content. To address these challenges, we propose Pharos-ESG, a uni- fied framework that transforms ESG reports into structured representations through multimodal parsing, contextual nar- ration, and hierarchical labeling. It integrates a reading-order modeling module based on layout flow, hierarchy-aware seg- mentation guided by table-of-contents anchors, and a multi- modal aggregation pipeline that contextually transforms vi- sual elements into coherent natural language. The framework further enriches its outputs with ESG, GRI, and sentiment labels, yielding annotations aligned with the analytical de- mands of financial research. Extensive experiments on anno- tated benchmarks demonstrate that Pharos-ESG consistently outperforms both dedicated document parsing systems and general-purpose multimodal models. In addition, we release Aurora-ESG, the first large-scale public dataset of ESG re- ports, spanning Mainland China, Hong Kong, and U.S. mar- kets, featuring unified structured representations of multi- modal content, enriched with fine-grained layout and seman- tic annotations to better support ESG integration in financial governance and decision-making.

</details>


### [59] [From generative AI to the brain: five takeaways](https://arxiv.org/abs/2511.16432)
*Claudius Gros*

Main category: cs.AI

TL;DR: 文章探讨了生成式AI的原理在认知神经科学中的潜在启示，并通过五个具体范例说明机器学习对神经科学的学习价值。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能的发展依赖于清晰的生成性原理，且这些原理已在诸多应用中被验证。因此，研究这些原理在脑科学中的可行性和相关性具有重要意义。

Method: 回顾和讨论了机器学习领域的几项关键进展，并分析其对认知神经科学的潜在联系，包括实例分析等方式。

Result: 提出了五个与神经信息处理系统相关的范例：世界建模的不足、思想过程的生成、注意力机制、神经扩展规律和量化方法，并指出神经科学可从这些范例及机器学习取得的认识中受益。

Conclusion: 神经科学可以从生成式人工智能和机器学习研究中获得大量启发，尤其是关注其生成性原理及其在脑功能中的可能运作。

Abstract: The big strides seen in generative AI are not based on somewhat obscure algorithms, but due to clearly defined generative principles. The resulting concrete implementations have proven themselves in large numbers of applications. We suggest that it is imperative to thoroughly investigate which of these generative principles may be operative also in the brain, and hence relevant for cognitive neuroscience. In addition, ML research led to a range of interesting characterizations of neural information processing systems. We discuss five examples, the shortcomings of world modelling, the generation of thought processes, attention, neural scaling laws, and quantization, that illustrate how much neuroscience could potentially learn from ML research.

</details>


### [60] [PersonaDrift: A Benchmark for Temporal Anomaly Detection in Language-Based Dementia Monitoring](https://arxiv.org/abs/2511.16445)
*Joy Lai,Alex Mihailidis*

Main category: cs.AI

TL;DR: 本论文提出了PersonaDrift基准，用于评估模型追踪痴呆症患者沟通行为漂移的能力，发现个性化建模对检测语义和情感等长期变化尤为重要。


<details>
  <summary>Details</summary>
Motivation: 当前大多数计算工具未针对痴呆症患者随时间推移的沟通行为漂移进行设计。照护者虽能主观感知这些变化，但缺乏系统、自动化和个性化的检测手段，因此有必要开发和评估能长期跟踪沟通行为变化的工具。

Method: 本文提出了PersonaDrift——一个基于合成交互数据的基准，用于评估机器学习与统计方法对痴呆症患者沟通进展变化的检测能力。PersonaDrift通过模拟根据照护者访谈构建的合成用户，在60天内的数字提醒系统使用日志，并引入平淡情感和偏题回复两种渐进变化。测试了统计异常检测、上下文嵌入的序列模型以及监督分类方法。

Result: 简单统计模型在低方差用户中能够检测到情感平淡变化，但检测语义漂移则需时间建模与个性化基线。无论检测哪一类行为变化，个性化分类器的表现均优于通用模型。

Conclusion: 该研究表明，在检测痴呆症患者沟通行为进展性变化时，个性化分类器的表现优于通用模型，尤其是在处理语义漂移和情感平淡等长期变化时更为有效。

Abstract: People living with dementia (PLwD) often show gradual shifts in how they communicate, becoming less expressive, more repetitive, or drifting off-topic in subtle ways. While caregivers may notice these changes informally, most computational tools are not designed to track such behavioral drift over time. This paper introduces PersonaDrift, a synthetic benchmark designed to evaluate machine learning and statistical methods for detecting progressive changes in daily communication, focusing on user responses to a digital reminder system. PersonaDrift simulates 60-day interaction logs for synthetic users modeled after real PLwD, based on interviews with caregivers. These caregiver-informed personas vary in tone, modality, and communication habits, enabling realistic diversity in behavior. The benchmark focuses on two forms of longitudinal change that caregivers highlighted as particularly salient: flattened sentiment (reduced emotional tone and verbosity) and off-topic replies (semantic drift). These changes are injected progressively at different rates to emulate naturalistic cognitive trajectories, and the framework is designed to be extensible to additional behaviors in future use cases. To explore this novel application space, we evaluate several anomaly detection approaches, unsupervised statistical methods (CUSUM, EWMA, One-Class SVM), sequence models using contextual embeddings (GRU + BERT), and supervised classifiers in both generalized and personalized settings. Preliminary results show that flattened sentiment can often be detected with simple statistical models in users with low baseline variability, while detecting semantic drift requires temporal modeling and personalized baselines. Across both tasks, personalized classifiers consistently outperform generalized ones, highlighting the importance of individual behavioral context.

</details>


### [61] [Utilizing Large Language Models for Zero-Shot Medical Ontology Extension from Clinical Notes](https://arxiv.org/abs/2511.16548)
*Guanchen Wu,Yuzhang Xie,Huanwei Wu,Zhe He,Hui Shao,Xiao Hu,Carl Yang*

Main category: cs.AI

TL;DR: 本文提出基于大语言模型的CLOZE框架，能从临床笔记中自动抽取医学实体并扩展现有本体，无需额外标注或训练，准确高效且保护隐私，可显著提升本体的覆盖面与实用性。


<details>
  <summary>Details</summary>
Motivation: 尽管临床笔记包含丰富、上下文相关的医学信息，但其作为扩展医学本体的直接数据源研究较少。因此，急需开发一种能够自动、高效、隐私保护地利用临床笔记扩展本体的工具。

Method: 提出了一种基于大语言模型（LLMs）的零样本（zero-shot）医学实体抽取与本体集成框架CLOZE。该方法实现了医学实体和复杂层次关系的自动识别与本体扩展，且不需额外训练或标注数据，同时通过自动移除受保护健康信息（PHI）实现隐私保护。

Result: 实验结果表明，CLOZE 能够准确抽取并整合新的医学实体与层级关系，具有良好的可扩展性和隐私保护能力，有望广泛支持生物医学研究与临床信息学等多种下游应用。

Conclusion: CLOZE 框架能够高效、准确、可扩展且保护隐私地将临床笔记中的医学实体自动集成进现有医学本体，扩展其覆盖范围并增强其实用性。

Abstract: Integrating novel medical concepts and relationships into existing ontologies can significantly enhance their coverage and utility for both biomedical research and clinical applications. Clinical notes, as unstructured documents rich with detailed patient observations, offer valuable context-specific insights and represent a promising yet underutilized source for ontology extension. Despite this potential, directly leveraging clinical notes for ontology extension remains largely unexplored. To address this gap, we propose CLOZE, a novel framework that uses large language models (LLMs) to automatically extract medical entities from clinical notes and integrate them into hierarchical medical ontologies. By capitalizing on the strong language understanding and extensive biomedical knowledge of pre-trained LLMs, CLOZE effectively identifies disease-related concepts and captures complex hierarchical relationships. The zero-shot framework requires no additional training or labeled data, making it a cost-efficient solution. Furthermore, CLOZE ensures patient privacy through automated removal of protected health information (PHI). Experimental results demonstrate that CLOZE provides an accurate, scalable, and privacy-preserving ontology extension framework, with strong potential to support a wide range of downstream applications in biomedical research and clinical informatics.

</details>


### [62] [Consciousness in Artificial Intelligence? A Framework for Classifying Objections and Constraints](https://arxiv.org/abs/2511.16582)
*Andres Campero,Derek Shiller,Jaan Aru,Jonathan Simon*

Main category: cs.AI

TL;DR: 本文提出了用于系统化分析数字AI意识可能性挑战的分类学框架，并通过文献案例展示，其有助于澄清相关讨论和概念。


<details>
  <summary>Details</summary>
Motivation: 现有讨论数字意识相关的挑战往往混淆不同层级和强度，亟需一种系统工具来厘清各种观点，为讨论与研究提供更明晰的结构。

Method: 建立分类学框架，并将其应用于科学与哲学文献中的14个典型案例，按照粒度与挑战强度分类。

Result: 将挑战分为三个强度等级和与Marr层级相对应的分析维度，有效区分了关于计算功能主义和数字意识挑战的不同方式。

Conclusion: 提出了一个分类学框架，有助于厘清和分析针对数字人工智能系统意识可能性的不同层次和强度的挑战。

Abstract: We develop a taxonomical framework for classifying challenges to the possibility of consciousness in digital artificial intelligence systems. This framework allows us to identify the level of granularity at which a given challenge is intended (the levels we propose correspond to Marr's levels) and to disambiguate its degree of force: is it a challenge to computational functionalism that leaves the possibility of digital consciousness open (degree 1), a practical challenge to digital consciousness that suggests improbability without claiming impossibility (degree 2), or an argument claiming that digital consciousness is strictly impossible (degree 3)? We apply this framework to 14 prominent examples from the scientific and philosophical literature. Our aim is not to take a side in the debate, but to provide structure and a tool for disambiguating between challenges to computational functionalism and challenges to digital consciousness, as well as between different ways of parsing such challenges.

</details>


### [63] [You Only Forward Once: An Efficient Compositional Judging Paradigm](https://arxiv.org/abs/2511.16600)
*Tianlong Zhang,Hongwei Xue,Shilin Yan,Di Wu,Chen Xu,Yunyun Yang*

Main category: cs.AI

TL;DR: YOFO方法让大语言模型能极快且可解释地判断多需求，比现有方法更高效、更智能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在作为评判者时存在评分粒度与生成能力冲突，以及逐步生成分析速度太慢等问题。

Method: YOFO通过接受结构化需求模板，以单步推理为每项需求生成二元决策，从最终分词的logits中读取判断结果，显著提升速度并保持高解释性。

Result: YOFO方法获得了数量级的推理速度提升，在标准推荐数据集上达到了最先进的结果，支持依赖关系判断，并可受益于事后链式思考。

Conclusion: YOFO方法通过一次前向传播并结合模板条件，实现了高效且可解释的多项需求判断，并在推荐任务上实现了最优表现。

Abstract: Multimodal large language models (MLLMs) show strong potential as judges. However, existing approaches face a fundamental trade-off: adapting MLLMs to output a single score misaligns with the generative nature of MLLMs and limits fine-grained requirement understanding, whereas autoregressively generating judging analyses is prohibitively slow in high-throughput settings. Observing that judgment reduces to verifying whether inputs satisfy a set of structured requirements, we propose YOFO, a template-conditioned method that judges all requirements in a single forward pass. Built on an autoregressive model, YOFO accepts a structured requirement template and, in one inference step, produces a binary yes/no decision for each requirement by reading the logits of the final token associated with that requirement. This design yields orders-of-magnitude speedups while preserving interpretability. Extensive experiments show that YOFO not only achieves state-of-the-art results on standard recommendation datasets, but also supports dependency-aware analysis-where subsequent judgments are conditioned on previous ones-and further benefits from post-hoc CoT.

</details>


### [64] [Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization](https://arxiv.org/abs/2511.16602)
*Yi Zhang,Che Liu,Xiancong Ren,Hanchu Ni,Yingji Zhang,Shuai Zhang,Zeyuan Ding,Jiayu Hu,Haozhe Shan,Junbo Qi,Yan Bai,Dengjie Li,Jiachen Luo,Yidong Wang,Yong Dai,Zenglin Xu,Bin Shen,Qifan Wang,Jian Tang,Xiaozhu Ju*

Main category: cs.AI

TL;DR: 为解决数据稀缺和算法低效等问题，作者提出DPPO框架，通过元认知训练方式提升学习效率，并在大规模模型上取得显著性能提升，已开源相关模型和代码，推动具身智能领域进步。


<details>
  <summary>Details</summary>
Motivation: 当前通用且多样化的具身智能系统面临两大主要挑战：一是具身数据瓶颈，即真实世界数据稀缺且成本高昂；二是现有方法的算法效率低下，资源消耗大。

Method: 提出了一种名为Deliberate Practice Policy Optimization（DPPO）的元认知“Metaloop”训练框架。该方法在训练过程中自动在有监督微调（能力扩展）与强化学习（技能精炼）之间动态切换，实现自动识别模型弱点和精确分配计算资源，从而最大化利用有限稀疏数据的学习效率。理论上，DPPO可形式化为统一的偏好学习框架。

Result: 采用DPPO框架训练的视觉-语言具身模型Pelican-VL 1.0相较基础模型性能提升了20.3%，并在100B参数规模下优于其它开源模型10.6%。

Conclusion: 论文首次系统性地提出并开源解决数据与资源瓶颈的方法和模型，为社区高效构建通用、强大的具身智能体提供了支持。

Abstract: Developing a universal and versatile embodied intelligence system presents two primary challenges: the critical embodied data bottleneck, where real-world data is scarce and expensive, and the algorithmic inefficiency of existing methods, which are resource-prohibitive. To address these limitations, we introduce Deliberate Practice Policy Optimization (DPPO), a metacognitive ``Metaloop'' training framework that dynamically alternates between supervised fine-tuning (competence expansion) and reinforcement learning (skill refinement). This enables automatic weakness identification and targeted resource allocation, specifically designed to maximize learning efficiency from sparse, finite data. Theoretically, DPPO can be formalised as a unified preference-learning framework. Empirically, training a vision-language embodied model with DPPO, referred to as Pelican-VL 1.0, yields a 20.3% performance improvement over the base model and surpasses open-source models at the 100B-parameter scale by 10.6%. We are open-sourcing both the models and code, providing the first systematic framework that alleviates the data and resource bottleneck and enables the community to build versatile embodied agents efficiently.

</details>


### [65] [MedBayes-Lite: Bayesian Uncertainty Quantification for Safe Clinical Decision Support](https://arxiv.org/abs/2511.16625)
*Elias Hossain,Md Mehedi Hasan Nipu,Maleeha Sheikh,Rajib Rana,Subash Neupane,Niloofar Yousefi*

Main category: cs.AI

TL;DR: MedBayes-Lite通过贝叶斯机制增强transformer在医疗AI中的不确定性表达，无需额外训练或重构，大幅降低模型自信过高并提升诊断安全性。


<details>
  <summary>Details</summary>
Motivation: 当前transformer在医疗领域预测中表现虽强，但对不确定案例往往过度自信，缺乏可校准的不确定性度量，影响临床决策安全，亟需一种可靠且高效的不确定性增强方案。

Method: 不改变现有transformer结构或参数的情况下，嵌入轻量级贝叶斯机制，包括Monte Carlo dropout实现贝叶斯嵌入校准、不确定性加权注意力、以及基于置信度的决策调整。

Result: MedBayes-Lite在MedQA、PubMedQA、MIMIC-III等基准测试均显著提升预测的校准与可信度，过度自信减少32-48%，在模拟临床场景下预防41%的诊断错误。

Conclusion: MedBayes-Lite能有效提升医疗AI模型在临床场景中的可靠性和不确定性传播能力，显著降低模型过度自信的问题，提升了可解释性并减少诊断错误。

Abstract: We propose MedBayes-Lite, a lightweight Bayesian enhancement for transformer-based clinical language models designed to produce reliable, uncertainty-aware predictions. Although transformers show strong potential for clinical decision support, they remain prone to overconfidence, especially in ambiguous medical cases where calibrated uncertainty is critical. MedBayes-Lite embeds uncertainty quantification directly into existing transformer pipelines without any retraining or architectural rewiring, adding no new trainable layers and keeping parameter overhead under 3 percent. The framework integrates three components: (i) Bayesian Embedding Calibration using Monte Carlo dropout for epistemic uncertainty, (ii) Uncertainty-Weighted Attention that marginalizes over token reliability, and (iii) Confidence-Guided Decision Shaping inspired by clinical risk minimization. Across biomedical QA and clinical prediction benchmarks (MedQA, PubMedQA, MIMIC-III), MedBayes-Lite consistently improves calibration and trustworthiness, reducing overconfidence by 32 to 48 percent. In simulated clinical settings, it can prevent up to 41 percent of diagnostic errors by flagging uncertain predictions for human review. These results demonstrate its effectiveness in enabling reliable uncertainty propagation and improving interpretability in medical AI systems.

</details>


### [66] [Enhancing Forex Forecasting Accuracy: The Impact of Hybrid Variable Sets in Cognitive Algorithmic Trading Systems](https://arxiv.org/abs/2511.16657)
*Juan C. King,Jose M. Amigo*

Main category: cs.AI

TL;DR: 作者开发了融合基本面与技术面变量的AI高频交易系统，并在EUR-USD汇率对中比较分析其各自预测与盈利表现，结果展示了其中一种特征类型的优势。


<details>
  <summary>Details</summary>
Motivation: 鉴于现有外汇高频交易系统对EUR-USD的预测和盈利表现有限，亟需探索整合多元基本面与技术面特征的AI模型，以提升交易决策的准确性、稳定性及收益性。

Method: 论文通过集成欧元区与美国关键宏观经济变量（如GDP和失业率），以及技术指标、振荡器、斐波那契水平和价格背离等多种输入特征，构建AI算法交易系统，并采用标准机器学习评价指标及历史回测模拟交易盈利与风控表现。

Result: 该AI算法在历史数据回测中展现出不同特征类别在盈利和风险控制上的优劣，通过对比分析发现某类别特征能够带来更高的预测准确率和更可靠的交易回报。

Conclusion: 论文结论显示，在EUR-USD外汇高频环境下，某一类别（基本面或技术面）输入特征能够更好地提升交易信号盈利能力与预测可靠性，并通过比较分析给出具体优势类别。

Abstract: This paper presents the implementation of an advanced artificial intelligence-based algorithmic trading system specifically designed for the EUR-USD pair within the high-frequency environment of the Forex market. The methodological approach centers on integrating a holistic set of input features: key fundamental macroeconomic variables (for example, Gross Domestic Product and Unemployment Rate) collected from both the Euro Zone and the United States, alongside a comprehensive suite of technical variables (including indicators, oscillators, Fibonacci levels, and price divergences). The performance of the resulting algorithm is evaluated using standard machine learning metrics to quantify predictive accuracy and backtesting simulations across historical data to assess trading profitability and risk. The study concludes with a comparative analysis to determine which class of input features, fundamental or technical, provides greater and more reliable predictive capacity for generating profitable trading signals.

</details>


### [67] [Cognitive Foundations for Reasoning and Their Manifestation in LLMs](https://arxiv.org/abs/2511.16660)
*Priyanka Kargupta,Shuyue Stella Li,Haocheng Wang,Jinu Lee,Shan Chen,Orevaoghene Ahia,Dean Light,Thomas L. Griffiths,Max Kleiman-Weiner,Jiawei Han,Asli Celikyilmaz,Yulia Tsvetkov*

Main category: cs.AI

TL;DR: 本文通过建立认知要素体系并分析大量推理过程，揭示出人类与大模型在推理结构上的本质不同。提出可行的推理引导方法，显著提升模型复杂任务能力，为未来模型发展与认知理论检验提供了新思路和资源。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在解决复杂问题时展现强大能力，却往往在更简单的任务上出错，暗示其推理机制与人类截然不同。为揭示差异、理解模型不足，并寻找改进方向，亟需用认知科学视角体系化分析模型推理过程。

Method: 该研究首先综合认知科学文献，建立了涵盖28个认知要素的分类体系。随后，作者提出了细粒度认知评估框架，并对来自17种模型跨文本、视觉、音频模态的17万条推理过程（reasoning traces）及54个人类思考过程进行分析。同时，通过对1598篇相关论文的元分析检测当前研究重心。最后，尝试引入推理引导对模型进行结构化支持。

Result: 1）实证表明，人类和模型的推理过程结构性不同，特别是在结构不明确的问题上差异极大；2）当前研究多关注易量化的行为，忽视元认知控制，而后者与推理成功密切相关；3）通过认知引导，复杂任务成功率最高提升60%；4）公开数据和方法，为进一步跨学科改进模型推理能力及大规模人类认知理论检验奠定基础。

Conclusion: 人类和大型语言模型（LLM）在推理方式上存在本质性结构差异。人类倾向于采用分层嵌套和元认知监控，而模型更依赖浅层的顺向链推理。模型拥有与成功相关的行为组合，但无法自动调动。通过引入认知引导，可以显著提升模型在复杂问题上的表现。

Abstract: Large language models solve complex problems yet fail on simpler variants, suggesting they achieve correct outputs through mechanisms fundamentally different from human reasoning. We synthesize cognitive science research into a taxonomy of 28 cognitive elements spanning computational constraints, meta-cognitive controls, knowledge representations, and transformation operations, then analyze their behavioral manifestations in reasoning traces. We propose a fine-grained cognitive evaluation framework and conduct the first large-scale analysis of 170K traces from 17 models across text, vision, and audio modalities, alongside 54 human think-aloud traces, which we make publicly available. Our analysis reveals systematic structural differences: humans employ hierarchical nesting and meta-cognitive monitoring while models rely on shallow forward chaining, with divergence most pronounced on ill-structured problems. Meta-analysis of 1,598 LLM reasoning papers reveals the research community concentrates on easily quantifiable behaviors (sequential organization: 55%, decomposition: 60%) while neglecting meta-cognitive controls (self-awareness: 16%, evaluation: 8%) that correlate with success. Models possess behavioral repertoires associated with success but fail to deploy them spontaneously. Leveraging these patterns, we develop test-time reasoning guidance that automatically scaffold successful structures, improving performance by up to 60% on complex problems. By bridging cognitive science and LLM research, we establish a foundation for developing models that reason through principled cognitive mechanisms rather than brittle spurious reasoning shortcuts or memorization, opening new directions for both improving model capabilities and testing theories of human cognition at scale.

</details>
